{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnivariateNeuralNetwork_with_NYCT.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f790rydIve_",
        "colab_type": "code",
        "outputId": "4d6b8a6b-d93b-4c67-a2a4-2de8cfe08eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMZJzz67FLEt",
        "colab_type": "text"
      },
      "source": [
        "# Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzcloO8dFIdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getScaledTrainTextDataset(dataset_scaled, trainRate=0.3):\n",
        "    print('Shape: ',dataset_scaled.shape)\n",
        "    train_size = int(len(dataset_scaled)*trainRate)\n",
        "    test_size = len(dataset_scaled) - train_size\n",
        "    print('Trainsize:',train_size, ' - Testsize:',test_size)\n",
        "    train_start_index,train_end_index = 0,train_size\n",
        "    test_start_index,test_end_index = train_size,len(dataset_scaled)\n",
        "    train = dataset_scaled[0:train_size]\n",
        "    test = dataset_scaled[train_size:] \n",
        "    return train,test\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_XY_lookback_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\ta = dataset[i:(i+look_back)]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "def create_XY_lookback_dataset_multistepOutput(dataset, look_back=1, look_forward = 1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1-look_forward):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back:i+look_back+look_forward, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "def calculateRMSE(testPredict,trainY,testY,inverse_transform=True, verbose= 1):\n",
        "    \n",
        "    if inverse_transform:\n",
        "        testPredict_inverse = scaler.inverse_transform(testPredict)\n",
        "        testY_inverse = scaler.inverse_transform([testY])  \n",
        "    else:\n",
        "        testPredict_inverse = testPredict\n",
        "        testY_inverse = testY\n",
        "        \n",
        "    # calculate root mean squared error\n",
        "    testScore = math.sqrt(mean_squared_error(testY_inverse[0], testPredict_inverse[:,0]))\n",
        "    if verbose == 1:\n",
        "        print('Test Score: %.2f RMSE' % (testScore))\n",
        "        print('Persistent Model Testscore small:',global_testPredict_small, ' - Persistent Model Testscore big:', global_testPredict_big)\n",
        "        \n",
        "    return  testScore\n",
        "\n",
        "def calculateRMSE_MultipleOutput(trainPredict,testPredict,trainY,testY,inverse_transform=True, verbose= 1):\n",
        "    \n",
        "    if inverse_transform:\n",
        "        trainPredict_inverse = scaler.inverse_transform(trainPredict)\n",
        "        trainY_inverse = scaler.inverse_transform(trainY)\n",
        "        testPredict_inverse = scaler.inverse_transform(testPredict)\n",
        "        testY_inverse = scaler.inverse_transform(testY)  \n",
        "    else:\n",
        "        trainPredict_inverse = trainPredict\n",
        "        trainY_inverse = trainY\n",
        "        testPredict_inverse = testPredict\n",
        "        testY_inverse = testY\n",
        "        \n",
        "    # calculate root mean squared error\n",
        "    trainScore = math.sqrt(mean_squared_error(trainY_inverse[0], trainPredict_inverse[:,0]))\n",
        "    testScore = math.sqrt(mean_squared_error(testY_inverse[0], testPredict_inverse[:,0]))\n",
        "    if verbose == 1:\n",
        "        print('Train Score: %.2f RMSE' % (trainScore))\n",
        "        print('Test Score: %.2f RMSE' % (testScore))\n",
        "        print('Persistent Model Testscore small:',global_testPredict_small, ' - Persistent Model Testscore big:', global_testPredict_big)\n",
        "        \n",
        "    return trainScore, testScore\n",
        "\n",
        "def plotErrorPrediction(dataset_scaled, testPredict, trainPredict, ShowTestError=True, inverse_transform=True):\n",
        "    if inverse_transform:\n",
        "        trainPredict_inverse = scaler.inverse_transform(trainPredict)\n",
        "        testPredict_inverse = scaler.inverse_transform(testPredict)\n",
        "    else:\n",
        "        trainPredict_inverse = trainPredict\n",
        "        testPredict_inverse = testPredict\n",
        "\n",
        "    # shift train predictions for plotting\n",
        "    trainPredictPlot = numpy.zeros_like(dataset_scaled)\n",
        "    trainPredictPlot[:, :] = numpy.nan\n",
        "    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict_inverse\n",
        "    # shift test predictions for plotting\n",
        "    testPredictPlot = numpy.empty_like(dataset_scaled)\n",
        "    testPredictPlot[:, :] = numpy.nan\n",
        "    testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict_inverse    \n",
        "    \n",
        "    error_test = dataset-testPredictPlot\n",
        "    error_test[np.isnan(error_test)] = 0.\n",
        "    # error_test[error_training<2000] = 0.\n",
        "    error_test = np.abs(error_test)\n",
        "    import seaborn as sns\n",
        "    sns.distplot(error_test[error_test!=0])\n",
        "    print(pandas.DataFrame(error_test[error_test!=0]).describe())\n",
        "    return error_test, trainPredictPlot,testPredictPlot\n",
        "\n",
        "def plotErrorPredictionValidation(dataset_scaled, validationPredict, testPredict, trainPredict, ShowTestError=True, inverse_transform=True):\n",
        "    if inverse_transform:\n",
        "        trainPredict_inverse = scaler.inverse_transform(trainPredict)\n",
        "        testPredict_inverse = scaler.inverse_transform(testPredict)\n",
        "    else:\n",
        "        trainPredict_inverse = trainPredict\n",
        "        testPredict_inverse = testPredict\n",
        "\n",
        "    # shift train predictions for plotting\n",
        "    trainPredictPlot = numpy.zeros_like(dataset_scaled)\n",
        "    trainPredictPlot[:, :] = numpy.nan\n",
        "    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict_inverse\n",
        "    # shift test predictions for plotting\n",
        "    testPredictPlot = numpy.empty_like(dataset_scaled)\n",
        "    testPredictPlot[:, :] = numpy.nan\n",
        "    testPredictPlot[len(trainPredict)+(look_back*2)+1+len(validationPredict):len(dataset)-1, :] = testPredict_inverse    \n",
        "    \n",
        "    error_test = dataset-testPredictPlot\n",
        "    error_test[np.isnan(error_test)] = 0.\n",
        "    # error_test[error_training<2000] = 0.\n",
        "    error_test = np.abs(error_test)\n",
        "    import seaborn as sns\n",
        "    sns.distplot(error_test[error_test!=0])\n",
        "    print(pandas.DataFrame(error_test[error_test!=0]).describe())\n",
        "    return error_test, trainPredictPlot,testPredictPlot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0CLQa1EJCiz",
        "colab_type": "text"
      },
      "source": [
        "# MLP with NYCT Result\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1ScBUYuJESi",
        "colab_type": "code",
        "outputId": "5004b1b7-14b9-4641-e26b-6f3cd6769e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "seed(42)\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class MLP_AnomalyDetection:\n",
        "    def __init__(self,path, window_width,  n_epochs, train_rate):\n",
        "\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "\n",
        "        self.df = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back)]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back])\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        set_random_seed(42)\n",
        "        seed(42)\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Dense(100, activation='relu', input_dim=self.window_width))\n",
        "        self.model.add(Dense(50, activation='relu', input_dim=self.window_width))\n",
        "        self.model.add(Dense(1))\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=0)\n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "\n",
        "        # xgb = XGBRegressor()\n",
        "        # xgb.fit(self.train_X.reshape(-1,1),self.train_y.reshape(-1,1))\n",
        "\n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "        # rmse = sqrt(mean_squared_error(self.test, self.predictions))\n",
        "        # self.errors = np.absolute(self.test - np.array(self.predictions))\n",
        "        # print('Prediction Test RMSE: %.3f' % rmse)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMSE: %.3f' % rmse)        \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test_y, color='green',  linewidth=0.5,label='True Values')\n",
        "        pyplot.plot(self.predictions, color='blue',  linewidth=0.5,label='Predictions')\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5, label='Errors')\n",
        "        pyplot.legend()\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "mlp = MLP_AnomalyDetection('drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',30,10,0.3)\n",
        "mlp.fit()\n",
        "mlp.get_roc_auc(verbose=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)\n",
        "\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "mlp.model.predict(mlp.test_X)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Inference Time: ',diff)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7909231284433591\n",
            "Time:  0:00:18.979555\n",
            "Inference Time:  0:00:00.561702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osK9dMWOWatq",
        "colab_type": "text"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBwhCTnnWbuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "seed(42)\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class CNN_AnomalyDetection:\n",
        "    def __init__(self,path, window_width,  n_epochs, train_rate):\n",
        "\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "\n",
        "        self.df = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back)]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back])\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],1,self.train_X.shape[1]))\n",
        "        self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],1, self.test_X.shape[1]))\n",
        "\n",
        "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Conv1D(filters=8, kernel_size=1, activation='relu', input_shape=(1, self.window_width),data_format='channels_first', padding='same'))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Conv1D(filters=16, kernel_size=1, activation='relu', input_shape=(1, self.window_width),data_format='channels_first', padding='same'))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(1, self.window_width),data_format='channels_first', padding='same'))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Flatten())\n",
        "        self.model.add(Dense(40, activation='relu'))\n",
        "        self.model.add(Dense(1))\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=0)\n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "        \n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMSE: %.3f' % rmse)        \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test_y, color='green',  linewidth=0.5,label='True Values')\n",
        "        pyplot.plot(self.predictions, color='blue',  linewidth=0.5,label='Predictions')\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5, label='Errors')\n",
        "        pyplot.legend()\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# mlp = CNN_AnomalyDetection('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_9.csv',30,50,0.3)\n",
        "# mlp.fit()\n",
        "# mlp.plot()\n",
        "# mlp.get_roc_auc(verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0DPR5ziS-fX",
        "colab_type": "text"
      },
      "source": [
        "Evaluation with NYCT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfdoXksWM279",
        "colab_type": "code",
        "outputId": "2881c80f-1930-48ee-ec7d-42643c071c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "# cnn = CNN_AnomalyDetection( 'drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',50,80,0.3)\n",
        "# cnn.fit()\n",
        "# cnn.get_roc_auc(plot=False,verbose=False)\n",
        "cnn.model.predict(cnn.test_X)\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time:  0:00:00.678285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M94ojQrZpOI",
        "colab_type": "text"
      },
      "source": [
        "# CNN with BatchNormalization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WExGKTgnZrw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Conv1D, Conv2D, Flatten, BatchNormalization, Activation,MaxPooling1D\n",
        "import keras.layers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class CNNBatch_AnomalyDetection:\n",
        "    def __init__(self,path, window_width,  n_epochs, train_rate):\n",
        "\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "\n",
        "        self.df = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back)]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back])\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "        print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],1,self.train_X.shape[1]))\n",
        "        self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],1, self.test_X.shape[1]))\n",
        "\n",
        "        channel_pos = 'channels_first'\n",
        "        inp_shape = Input((1, self.window_width),name='input1')\n",
        "        x = Conv1D(32, kernel_size=1, padding = 'same', input_shape=(1, self.window_width),data_format=channel_pos,name='conv2d_Prep')(inp_shape)\n",
        "        x = BatchNormalization(axis=1,name='batch_normalization_prep')(x)\n",
        "        x_a1 = Activation('relu',name='activation_prep')(x)\n",
        "        activated_x = x_a1\n",
        "\n",
        "        nr = 1 *2 -1\n",
        "        x = Conv1D(32, kernel_size=1, name = 'conv2d_'+str(nr), padding='same',data_format=channel_pos)(activated_x)\n",
        "        x = BatchNormalization(axis=1, name = 'batch_normalization_'+str(nr))(x)\n",
        "        activated_x = Activation('relu',name='activation_'+str(nr+1))(x)\n",
        "        activated_x = Flatten()(activated_x)\n",
        "        activated_x = Dense(50)(activated_x)\n",
        "        output = Dense(1)(activated_x)\n",
        "\n",
        "        from keras.models import Model\n",
        "        self.model = Model(inp_shape,output )\n",
        "\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        self.history =self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=2)\n",
        "        \n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        print('Prediction Test RMSE: %.3f' % rmse)        \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test_y, color='green',  linewidth=0.5,label='True Values')\n",
        "        pyplot.plot(self.predictions, color='blue',  linewidth=0.5,label='Predictions')\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5, label='Errors')\n",
        "        pyplot.legend()\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index - self.train_size - self.window_width]\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "\n",
        "# mlp = CNNBatch_AnomalyDetection('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_4.csv',30,100,0.66)\n",
        "# mlp.fit()\n",
        "# mlp.plot()\n",
        "# mlp.get_roc_auc(verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4m7hRW0P_3h",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation with NYCT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag088CwFQAqB",
        "colab_type": "code",
        "outputId": "a4203296-ecae-4216-c505-881603ae0917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mlp = CNNBatch_AnomalyDetection('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_4.csv',30,100,0.3)\n",
        "# mlp.fit()\n",
        "# mlp.plot()\n",
        "# mlp.get_roc_auc(verbose=False)\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "# cnn = CNNBatch_AnomalyDetection( 'drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',50,50,0.3)# 50 epoch -> 0.711\n",
        "# cnn.fit()\n",
        "# cnn.get_roc_auc(plot=False,verbose=False)\n",
        "cnn.model.predict(cnn.test_X)\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time:  0:00:00.766170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKXqW7rqcX5a",
        "colab_type": "text"
      },
      "source": [
        "# CNN Residual Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL9C3IDPcrNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Conv1D, Conv2D, Flatten, BatchNormalization, Activation,MaxPooling1D\n",
        "import keras.layers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class CNNResidual_AnomalyDetection:\n",
        "    def __init__(self,path, window_width,  n_epochs, train_rate):\n",
        "\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "\n",
        "        self.df = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back)]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back])\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "        print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],1,self.train_X.shape[1]))\n",
        "        self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],1, self.test_X.shape[1]))\n",
        "\n",
        "        channel_pos = 'channels_first'\n",
        "        inp_shape = Input((1, self.window_width),name='input1')\n",
        "        x = Conv1D(256, kernel_size=3, padding = 'same', input_shape=(1, self.window_width),data_format=channel_pos,name='conv2d_Prep')(inp_shape)\n",
        "        x = BatchNormalization(axis=1,name='batch_normalization_prep')(x)\n",
        "        x_a1 = Activation('relu',name='activation_prep')(x)\n",
        "        activated_x = x_a1\n",
        "\n",
        "        #     activated_x, x\n",
        "        nr = 1 *2 -1\n",
        "        x = Conv1D(256, kernel_size=3, name = 'conv2d_'+str(nr), padding='same',data_format=channel_pos)(activated_x)\n",
        "        x = BatchNormalization(axis=1, name = 'batch_normalization_'+str(nr))(x)\n",
        "        x = Activation('relu',name = 'activation_'+str(nr))(x)\n",
        "        x = Conv1D(256, kernel_size=3, name = 'conv2d_'+str(nr+1),padding = 'same',data_format=channel_pos)(x)\n",
        "        x = BatchNormalization(axis=1, name = 'batch_normalization_'+str(nr+1))(x)\n",
        "        x = keras.layers.add([x,activated_x],name='add_' + str(1))\n",
        "        activated_x = Activation('relu',name='activation_'+str(nr+1))(x)\n",
        "        activated_x = Flatten()(activated_x)\n",
        "        activated_x = Dense(50)(activated_x)\n",
        "        output = Dense(1)(activated_x)\n",
        "\n",
        "        from keras.models import Model\n",
        "        self.model = Model(inp_shape,output )\n",
        "\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        self.history =self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=2)\n",
        "        \n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        print('Prediction Test RMSE: %.3f' % rmse)        \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test_y, color='green',  linewidth=0.5,label='True Values')\n",
        "        pyplot.plot(self.predictions, color='blue',  linewidth=0.5,label='Predictions')\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5, label='Errors')\n",
        "        pyplot.legend()\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index - self.train_size - self.window_width]\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F_TyqcLSBBN",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation with NYCT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WrPX4TTSAYa",
        "colab_type": "code",
        "outputId": "39273f49-f2e3-4d37-9de9-bec2923ea5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# mlp = CNNBatch_AnomalyDetection('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_4.csv',30,100,0.3)\n",
        "# mlp.fit()\n",
        "# mlp.plot()\n",
        "# mlp.get_roc_auc(verbose=False)\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "cnn = CNNResidual_AnomalyDetection( 'drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',100,50,0.3)\n",
        "cnn.fit()\n",
        "cnn.get_roc_auc(plot=False,verbose=False)\n",
        "\n",
        "# cnn.model.predict(cnn.test_X)        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)\n",
        "\n",
        "# mlp = CNNResidual_AnomalyDetection('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_4.csv',30,100,0.66)\n",
        "# mlp.fit()\n",
        "# mlp.plot()\n",
        "# mlp.get_roc_auc(verbose=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Persistent Model RMSE: 1715.096\n",
            "Train.len: 3095  - Test.len: 7224\n",
            "TrainX.shape: (2994, 100)  - TestX.shape: (7123, 100)  - TrainY.shape: (2994,)  - TestY.shape: (7123,)\n",
            "Epoch 1/50\n",
            " - 11s - loss: 93.6439\n",
            "Epoch 2/50\n",
            " - 2s - loss: 0.2801\n",
            "Epoch 3/50\n",
            " - 2s - loss: 0.2320\n",
            "Epoch 4/50\n",
            " - 2s - loss: 0.2228\n",
            "Epoch 5/50\n",
            " - 2s - loss: 0.2842\n",
            "Epoch 6/50\n",
            " - 2s - loss: 0.2335\n",
            "Epoch 7/50\n",
            " - 2s - loss: 0.1707\n",
            "Epoch 8/50\n",
            " - 2s - loss: 1.9422\n",
            "Epoch 9/50\n",
            " - 2s - loss: 2.3903\n",
            "Epoch 10/50\n",
            " - 2s - loss: 1.2343\n",
            "Epoch 11/50\n",
            " - 2s - loss: 0.6780\n",
            "Epoch 12/50\n",
            " - 2s - loss: 1.8427\n",
            "Epoch 13/50\n",
            " - 2s - loss: 0.4720\n",
            "Epoch 14/50\n",
            " - 2s - loss: 1.4123\n",
            "Epoch 15/50\n",
            " - 2s - loss: 1.9209\n",
            "Epoch 16/50\n",
            " - 2s - loss: 1.7671\n",
            "Epoch 17/50\n",
            " - 2s - loss: 0.3861\n",
            "Epoch 18/50\n",
            " - 2s - loss: 0.4054\n",
            "Epoch 19/50\n",
            " - 2s - loss: 0.4381\n",
            "Epoch 20/50\n",
            " - 2s - loss: 0.2974\n",
            "Epoch 21/50\n",
            " - 2s - loss: 1.1745\n",
            "Epoch 22/50\n",
            " - 2s - loss: 2.2926\n",
            "Epoch 23/50\n",
            " - 2s - loss: 0.3055\n",
            "Epoch 24/50\n",
            " - 2s - loss: 0.1216\n",
            "Epoch 25/50\n",
            " - 2s - loss: 0.4525\n",
            "Epoch 26/50\n",
            " - 2s - loss: 0.2921\n",
            "Epoch 27/50\n",
            " - 2s - loss: 0.0590\n",
            "Epoch 28/50\n",
            " - 2s - loss: 0.2313\n",
            "Epoch 29/50\n",
            " - 2s - loss: 0.5467\n",
            "Epoch 30/50\n",
            " - 2s - loss: 0.1673\n",
            "Epoch 31/50\n",
            " - 2s - loss: 0.2212\n",
            "Epoch 32/50\n",
            " - 2s - loss: 0.4294\n",
            "Epoch 33/50\n",
            " - 2s - loss: 1.3331\n",
            "Epoch 34/50\n",
            " - 2s - loss: 0.4155\n",
            "Epoch 35/50\n",
            " - 2s - loss: 0.0706\n",
            "Epoch 36/50\n",
            " - 2s - loss: 0.0474\n",
            "Epoch 37/50\n",
            " - 2s - loss: 0.0367\n",
            "Epoch 38/50\n",
            " - 2s - loss: 0.1002\n",
            "Epoch 39/50\n",
            " - 2s - loss: 0.2642\n",
            "Epoch 40/50\n",
            " - 2s - loss: 0.2048\n",
            "Epoch 41/50\n",
            " - 2s - loss: 0.0603\n",
            "Epoch 42/50\n",
            " - 2s - loss: 0.0584\n",
            "Epoch 43/50\n",
            " - 2s - loss: 0.0753\n",
            "Epoch 44/50\n",
            " - 2s - loss: 0.0576\n",
            "Epoch 45/50\n",
            " - 2s - loss: 0.0821\n",
            "Epoch 46/50\n",
            " - 2s - loss: 0.0727\n",
            "Epoch 47/50\n",
            " - 2s - loss: 0.1582\n",
            "Epoch 48/50\n",
            " - 2s - loss: 0.1571\n",
            "Epoch 49/50\n",
            " - 2s - loss: 0.2668\n",
            "Epoch 50/50\n",
            " - 2s - loss: 0.0977\n",
            "Prediction Test RMSE: 0.320\n",
            "AUC:  0.717059273837873\n",
            "Time:  0:01:47.318578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0Ny3VqddNme",
        "colab_type": "text"
      },
      "source": [
        "# Wavenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RucXuglRdUSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Conv1D, Conv2D, Flatten, BatchNormalization, Activation,MaxPooling1D\n",
        "import keras.layers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class Wavenet_AnomalyDetection:\n",
        "    def __init__(self,path, window_width,  n_epochs, train_rate):\n",
        "\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "\n",
        "        self.df = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back)]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back])\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "        print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],1,self.train_X.shape[1]))\n",
        "        self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],1, self.test_X.shape[1]))\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Conv1D(filters=24, kernel_size=2, activation='relu', input_shape=(1, self.window_width),data_format='channels_first', padding='same', dilation_rate=1))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Conv1D(filters=24, kernel_size=2, activation='relu', input_shape=(1, self.window_width),data_format='channels_first', padding='same', dilation_rate=2))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Conv1D(filters=24, kernel_size=2, activation='relu', input_shape=(1, self.window_width),data_format='channels_first', padding='same', dilation_rate = 4))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Conv1D(filters=24, kernel_size=2, activation='relu', input_shape=(1, self.window_width),data_format='channels_first', padding='same', dilation_rate = 8))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Flatten())\n",
        "        self.model.add(Dense(50, activation='relu'))\n",
        "        self.model.add(Dense(1))\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        self.history =self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=0)\n",
        "        \n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        print('Prediction Test RMSE: %.3f' % rmse)        \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test_y, color='green',  linewidth=0.5,label='True Values')\n",
        "        pyplot.plot(self.predictions, color='blue',  linewidth=0.5,label='Predictions')\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5, label='Errors')\n",
        "        pyplot.legend()\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "# mlp = Wavenet_AnomalyDetection('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_10.csv',30,100,0.3)\n",
        "# mlp.fit()\n",
        "# mlp.plot()\n",
        "# mlp.get_roc_auc(verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mkd1eBSwZR3",
        "colab_type": "text"
      },
      "source": [
        "0.AUC:  0.9979231568016613"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3AZ79hwxqC_",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation with NYCT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VFyMOXjxrTm",
        "colab_type": "code",
        "outputId": "726d8b5a-a5a3-49c0-9866-c21f29528350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# import os\n",
        "# import datetime\n",
        "# startTime = datetime.datetime.now()\n",
        "\n",
        "# dfs = [pd.DataFrame(columns=['filename', 'auc']), pd.DataFrame(columns=['filename', 'auc']),pd.DataFrame(columns=['filename', 'auc']),pd.DataFrame(columns=['filename', 'auc'])]\n",
        "# files = []\n",
        "# import glob\n",
        "# folders = ['A1Benchmark']\n",
        "# for j,folder in enumerate(folders):\n",
        "#     for i,file in enumerate(glob.glob('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/'+ folder + '/*.csv')):\n",
        "#         lstm = Wavenet_AnomalyDetection( file,30, 100,0.3)\n",
        "#         lstm.fit()\n",
        "#         print(file,end=' - ')\n",
        "#         dfs[j].loc[i] = [os.path.basename(file),lstm.get_roc_auc(plot=False,verbose=False)]\n",
        "\n",
        "# endTime = datetime.datetime.now()\n",
        "# diff = endTime - startTime\n",
        "# print('Time: ',diff.seconds)\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "cnn = Wavenet_AnomalyDetection( 'drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',50,24,0.3)\n",
        "cnn.fit()\n",
        "cnn.get_roc_auc(plot=False,verbose=False)\n",
        "\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "cnn.model.predict(cnn.test_X)        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Inference Time: ',diff)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Persistent Model RMSE: 1715.096\n",
            "Train.len: 3095  - Test.len: 7224\n",
            "TrainX.shape: (3044, 50)  - TestX.shape: (7173, 50)  - TrainY.shape: (3044,)  - TestY.shape: (7173,)\n",
            "Prediction Test RMSE: 0.156\n",
            "AUC:  0.7618006728586497\n",
            "Time:  0:00:32.617373\n",
            "Inference Time:  0:00:00.757158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixiv7FRV512s",
        "colab_type": "code",
        "outputId": "f11140bb-564e-4bea-88f4-07bf056612ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "dfs[0].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>59.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.824843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.159040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.257466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.762306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.878600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.941318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.994610</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             auc\n",
              "count  59.000000\n",
              "mean    0.824843\n",
              "std     0.159040\n",
              "min     0.257466\n",
              "25%     0.762306\n",
              "50%     0.878600\n",
              "75%     0.941318\n",
              "max     0.994610"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj32uENHeHmv",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNgqzR4XeIpR",
        "colab_type": "code",
        "outputId": "c8206946-e416-4326-b663-1b35c2d84aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Conv1D, Conv2D, Flatten, BatchNormalization, Activation,MaxPooling1D, LSTM\n",
        "import keras.layers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class LSTM_AnomalyDetection:\n",
        "    def __init__(self,path, window_width,  n_epochs, train_rate):\n",
        "\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "\n",
        "        self.df = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back)]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back])\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "        print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.train_X.shape[1],1))\n",
        "        self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0], self.test_X.shape[1],1))\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(LSTM(4, batch_input_shape=(1, self.window_width, 1), stateful=True, return_sequences=True))\n",
        "        self.model.add(LSTM(4, batch_input_shape=(1, self.window_width, 1), stateful=True))\n",
        "        self.model.add(Dense(1))\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        for i in range(self.n_epochs):\n",
        "            print('Epoch',i, '/',self.n_epochs)\n",
        "            self.model.fit(self.train_X, self.train_y, epochs=1, batch_size=1, verbose=1, shuffle=False)\n",
        "            self.model.reset_states()\n",
        "        # self.history =self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=2)\n",
        "        \n",
        "        self.predictions = self.model.predict(self.test_X, batch_size = 1)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        print('Prediction Test RMSE: %.3f' % rmse)        \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test_y, color='green',  linewidth=0.5,label='True Values')\n",
        "        pyplot.plot(self.predictions, color='blue',  linewidth=0.5,label='Predictions')\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5, label='Errors')\n",
        "        pyplot.legend()\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index - self.train_size - self.window_width]\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "\n",
        "lstm = LSTM_AnomalyDetection('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_4.csv',30,1,0.66)\n",
        "lstm.fit()\n",
        "lstm.plot()\n",
        "lstm.get_roc_auc(verbose=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Persistent Model RMSE: 867.478\n",
            "Train.len: 938  - Test.len: 484\n",
            "TrainX.shape: (907, 30)  - TestX.shape: (453, 30)  - TrainY.shape: (907,)  - TestY.shape: (453,)\n",
            "Epoch 0 / 1\n",
            "Epoch 1/1\n",
            "907/907 [==============================] - 68s 75ms/step - loss: 0.0276\n",
            "Prediction Test RMSE: 1.755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAACwgAAAEvCAYAAABb8Af1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAAAAgA3yH68jZ/bt5tw/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 3600x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8549668874172186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3yjl2boV4BK",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_WHR5iOCr0T",
        "colab_type": "text"
      },
      "source": [
        "### Results of NYCT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXaBB8rlV472",
        "colab_type": "code",
        "outputId": "b2d4cc78-f929-4e8a-a299-b84e5e17aa8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "cnn = LSTM_AnomalyDetection( 'drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',100,1,0.3)\n",
        "cnn.fit()\n",
        "cnn.get_roc_auc(plot=False,verbose=False)\n",
        "\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Persistent Model RMSE: 1715.096\n",
            "Train.len: 3095  - Test.len: 7224\n",
            "TrainX.shape: (2994, 100)  - TestX.shape: (7123, 100)  - TrainY.shape: (2994,)  - TestY.shape: (7123,)\n",
            "Epoch 0 / 1\n",
            "Epoch 1/1\n",
            "2994/2994 [==============================] - 1047s 350ms/step - loss: 0.2012\n",
            "Prediction Test RMSE: 0.414\n",
            "AUC:  0.8008320993998537\n",
            "Time:  2153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3_lzYn44raS",
        "colab_type": "code",
        "outputId": "edc2ed42-2269-4264-ae56-1abc3d5615aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "cnn = LSTM_AnomalyDetection( 'drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',100,2,0.3)\n",
        "cnn.fit()\n",
        "cnn.get_roc_auc(plot=False,verbose=False)\n",
        "\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Persistent Model RMSE: 1715.096\n",
            "Train.len: 3095  - Test.len: 7224\n",
            "TrainX.shape: (2994, 100)  - TestX.shape: (7123, 100)  - TrainY.shape: (2994,)  - TestY.shape: (7123,)\n",
            "Epoch 0 / 2\n",
            "Epoch 1/1\n",
            "2994/2994 [==============================] - 1033s 345ms/step - loss: 0.1755\n",
            "Epoch 1 / 2\n",
            "Epoch 1/1\n",
            "2994/2994 [==============================] - 1028s 343ms/step - loss: 0.0410\n",
            "Prediction Test RMSE: 0.217\n",
            "AUC:  0.8404287819509306\n",
            "Time:  3159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffA1N_alf5R6",
        "colab_type": "text"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlQ-Zjnwf7Ln",
        "colab_type": "code",
        "outputId": "7d06d656-ee38-4c36-c424-4d37600d5915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Conv1D, Conv2D, Flatten, BatchNormalization, Activation,MaxPooling1D, LSTM, GRU\n",
        "import keras.layers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class GRU_AnomalyDetection:\n",
        "    def __init__(self,path, window_width,  n_epochs, train_rate):\n",
        "\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "\n",
        "        self.df = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back)]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back])\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.train_X.shape[1],1))\n",
        "        self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0], self.test_X.shape[1],1))\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(GRU(4, batch_input_shape=(1, self.window_width, 1), stateful=True, return_sequences=True))\n",
        "        self.model.add(GRU(4, batch_input_shape=(1, self.window_width, 1), stateful=True))\n",
        "        self.model.add(Dense(1))\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        for i in range(self.n_epochs):\n",
        "            print('Epoch',i, '/',self.n_epochs, end=',')\n",
        "            self.model.fit(self.train_X, self.train_y, epochs=1, batch_size=1, verbose=0, shuffle=False)\n",
        "            self.model.reset_states()\n",
        "        # self.history =self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=2)\n",
        "        \n",
        "        self.predictions = self.model.predict(self.test_X, batch_size = 1)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMSE: %.3f' % rmse)        \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test_y, color='green',  linewidth=0.5,label='True Values')\n",
        "        pyplot.plot(self.predictions, color='blue',  linewidth=0.5,label='Predictions')\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5, label='Errors')\n",
        "        pyplot.legend()\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# gru = GRU_AnomalyDetection('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_4.csv',30,4,0.66)\n",
        "# gru.fit()\n",
        "# gru.plot()\n",
        "# gru.get_roc_auc(verbose=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4VNTqoiWgPT",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation with NYCT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9wVKOz1Whgn",
        "colab_type": "code",
        "outputId": "86d3a831-dbc6-4d8f-f3e2-beaaa1443c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "cnn = GRU_AnomalyDetection( 'drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',30,4,0.3)\n",
        "cnn.fit()\n",
        "cnn.get_roc_auc(plot=False,verbose=False)\n",
        "\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Persistent Model RMSE: 1715.096\n",
            "Train.len: 3095  - Test.len: 7224\n",
            "TrainX.shape: (3064, 30)  - TestX.shape: (7193, 30)  - TrainY.shape: (3064,)  - TestY.shape: (7193,)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 0 / 4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "3064/3064 [==============================] - 244s 80ms/step - loss: 0.0619\n",
            "Epoch 1 / 4\n",
            "Epoch 1/1\n",
            "3064/3064 [==============================] - 243s 79ms/step - loss: 0.0290\n",
            "Epoch 2 / 4\n",
            "Epoch 1/1\n",
            "3064/3064 [==============================] - 242s 79ms/step - loss: 0.0286\n",
            "Epoch 3 / 4\n",
            "Epoch 1/1\n",
            "3064/3064 [==============================] - 247s 81ms/step - loss: 0.0273\n",
            "Prediction Test RMSE: 0.232\n",
            "AUC:  0.797842010357729\n",
            "Time:  1241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR-I4uKHvypu",
        "colab_type": "code",
        "outputId": "4b1a20d1-e29a-4ce7-930a-00524394bf6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "cnn = GRU_AnomalyDetection( 'drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',30,4,0.3)\n",
        "cnn.fit()\n",
        "cnn.get_roc_auc(plot=False,verbose=False)\n",
        "\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Persistent Model RMSE: 1715.096\n",
            "Train.len: 3095  - Test.len: 7224\n",
            "TrainX.shape: (3064, 30)  - TestX.shape: (7193, 30)  - TrainY.shape: (3064,)  - TestY.shape: (7193,)\n",
            "Epoch 0 / 4\n",
            "Epoch 1/1\n",
            "3064/3064 [==============================] - 363s 119ms/step - loss: 0.1065\n",
            "Epoch 1 / 4\n",
            "Epoch 1/1\n",
            "3064/3064 [==============================] - 362s 118ms/step - loss: 0.0295\n",
            "Epoch 2 / 4\n",
            "Epoch 1/1\n",
            "3064/3064 [==============================] - 362s 118ms/step - loss: 0.0276\n",
            "Epoch 3 / 4\n",
            "Epoch 1/1\n",
            "3064/3064 [==============================] - 363s 118ms/step - loss: 0.0250\n",
            "Prediction Test RMSE: 0.262\n",
            "AUC:  0.5255270891423965\n",
            "Time:  1839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mty5nf_ICGkh",
        "colab_type": "code",
        "outputId": "93e87496-0809-4147-dc28-e7186afdd9ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "startTime = datetime.datetime.now()\n",
        "cnn.model.predict(cnn.test_X, batch_size = 1)\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time:  386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vfu5RS2GT0C",
        "colab_type": "code",
        "outputId": "b001bdf7-4715-415e-ac2b-7d47bd31f029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "startTime = datetime.datetime.now()\n",
        "cnn.model.predict(cnn.test_X, batch_size = 1)\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time:  0:06:25.979220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pZW8rYLgYaZ",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly9PXSP4gZzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Conv1D, Conv2D, Flatten, BatchNormalization, Activation,MaxPooling1D, LSTM, GRU\n",
        "import keras.layers\n",
        "from keras import regularizers, Model\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class AutoEncoder_AnomalyDetection:\n",
        "    def __init__(self,path, window_width,  n_epochs, train_rate):\n",
        "\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "\n",
        "        self.df = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back)]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back])\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "        print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.train_X.shape[1],1))\n",
        "        self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0], self.test_X.shape[1]),1)\n",
        "\n",
        "\n",
        "\n",
        "        learning_rate = 1e-3\n",
        "        input_layer = Input(shape=( 1,))\n",
        "        encoder = Dense(64, activation=\"relu\")(input_layer)\n",
        "        encoder = Dense(32, activation=\"relu\")(encoder)\n",
        "        encoder = Dense(16, activation=\"relu\")(encoder)\n",
        "        decoder = Dense(16, activation=\"relu\")(encoder)\n",
        "        decoder = Dense(32, activation=\"relu\")(decoder)\n",
        "        decoder = Dense(64, activation=\"relu\")(decoder)\n",
        "        decoder = Dense(1, activation=\"linear\")(decoder)\n",
        "        self.model = Model(inputs=input_layer, outputs=decoder)\n",
        "        self.model.compile(metrics=['accuracy'],\n",
        "                            loss='mean_squared_error',\n",
        "                            optimizer='adam')\n",
        "        channel_pos = 'channels_first'\n",
        "\n",
        "\n",
        "        history = self.model.fit(self.train_y, self.train_y, epochs=self.n_epochs, verbose=0)\n",
        "\n",
        "        self.predictions = self.model.predict(self.test_y)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        print('Prediction Test RMSE: %.3f' % rmse)        \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test_y, color='green',  linewidth=0.5,label='True Values')\n",
        "        pyplot.plot(self.predictions, color='blue',  linewidth=0.5,label='Predictions')\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5, label='Errors')\n",
        "        pyplot.legend()\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index - self.train_size - self.window_width]\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "\n",
        "# ae = AutoEncoder_AnomalyDetection('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_1.csv',30,100,0.66)\n",
        "# ae.fit()\n",
        "# ae.plot()\n",
        "# ae.get_roc_auc(verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNQ343KXwPJt",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation with NYCT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vh_Y4RxwQdx",
        "colab_type": "code",
        "outputId": "7f85cbbc-5aa4-481d-a5d4-e1ab81265804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "cnn = AutoEncoder_AnomalyDetection( 'drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',100,100,0.3)\n",
        "cnn.fit()\n",
        "cnn.get_roc_auc(plot=False,verbose=False)\n",
        "\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Persistent Model RMSE: 1715.096\n",
            "Train.len: 3095  - Test.len: 7224\n",
            "TrainX.shape: (2994, 100)  - TestX.shape: (7123, 100)  - TrainY.shape: (2994,)  - TestY.shape: (7123,)\n",
            "Prediction Test RMSE: 0.001\n",
            "AUC:  0.5712048047029863\n",
            "Time:  78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VyFAaFX2ePv",
        "colab_type": "code",
        "outputId": "b8c332bb-6a1d-4c6b-b471-c8c375b9264d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "cnn = AutoEncoder_AnomalyDetection( 'drive/My Drive/MT/Experiments/Univariate/NYC_Taxi/nyc_taxi.csv',100,200,0.3)\n",
        "cnn.fit()\n",
        "cnn.get_roc_auc(plot=False,verbose=False)\n",
        "\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Persistent Model RMSE: 1715.096\n",
            "Train.len: 3095  - Test.len: 7224\n",
            "TrainX.shape: (2994, 100)  - TestX.shape: (7123, 100)  - TrainY.shape: (2994,)  - TestY.shape: (7123,)\n",
            "Prediction Test RMSE: 0.001\n",
            "AUC:  0.6393921012364058\n",
            "Time:  145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX1KzoeQ_zPj",
        "colab_type": "code",
        "outputId": "7b007c5b-6801-4b01-efe7-796180c08ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "cnn.model.predict(cnn.test_y)\n",
        "\n",
        "        \n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time:  0:00:00.540601\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
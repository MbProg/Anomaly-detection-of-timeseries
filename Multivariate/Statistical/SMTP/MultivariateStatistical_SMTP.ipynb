{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultivariateStatistical_SMTP (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiZqVLRQmOjR",
        "colab_type": "code",
        "outputId": "789a065f-1b31-4ad7-8186-ab9f69d15f4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-T9hj2spAZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUQOyXtFlSRh",
        "colab_type": "text"
      },
      "source": [
        "# Create Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNzWcZj2lMLn",
        "colab_type": "code",
        "outputId": "421609d5-704e-4cdf-e659-6b89eeaefe13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima_process import arma_generate_sample\n",
        "n = int(3000)\n",
        "# alpha1 = 0.666, alpha2 = -.333\n",
        "alphas = np.array([.1])\n",
        "betas = np.array([0.])\n",
        "\n",
        "# Python requires us to specify the zero-lag value which is 1\n",
        "# Also note that the alphas for the AR model must be negated\n",
        "# We also set the betas for the MA equal to 0 for an AR(p) model\n",
        "# For more information see the examples at statsmodels.org\n",
        "ar = np.r_[1, -alphas]\n",
        "ma = np.r_[1, betas]\n",
        "# # AR(2)\n",
        "# ar2 = arma_generate_sample(ar=ar, ma=ma, nsample=n) \n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.plot( ar2)\n",
        "\n",
        "T_1 =  arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_2 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_3 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_4 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_5 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "M =[[1 , 0 , 0 , 0 , 1],\n",
        "[0 , 1 , 0 , 0 , 1],\n",
        "[0 , 0 , 1 , 0 , 1],\n",
        "[0 , 0 , 0 , 1 , 1],\n",
        "[1 , -1 , 0 , 0 , 1]]\n",
        "delta = np.zeros((n,1))\n",
        "delta_anomal = np.zeros((n,1))\n",
        "delta_anomal[300:320]   = np.ones((20,1))\n",
        "delta_anomal[600:610]   = np.full((10,1),-0.7)\n",
        "delta_anomal[1300:1320] = np.full((20,1),2)\n",
        "delta_anomal[2100:2150] = np.full((50,1),-1.5)\n",
        "\n",
        "# delta_anomal[41:50] = np.ones((9,1))\n",
        "N = np.concatenate((T_1,T_2,T_3,T_4,delta), axis=1)\n",
        "N_anomal =  np.concatenate((T_1,T_2,T_3,T_4,delta_anomal), axis=1)\n",
        "B = N@M\n",
        "B_anomal = N_anomal@M\n",
        "\n",
        "T_1 = B[:,0]\n",
        "T_2 = B[:,1]\n",
        "T_3 = B[:,2]\n",
        "T_4 = B[:,3]\n",
        "T_5 = B[:,4]\n",
        "\n",
        "\n",
        "T_1_anomal = B_anomal[:,0]\n",
        "T_2_anomal = B_anomal[:,1]\n",
        "T_3_anomal = B_anomal[:,2]\n",
        "T_4_anomal = B_anomal[:,3]\n",
        "T_5_anomal = B_anomal[:,4]\n",
        "\n",
        "MD_T = np.concatenate((T_1.reshape((-1,1)),T_2.reshape((-1,1)),T_3.reshape((-1,1)),T_4.reshape((-1,1)),T_5.reshape((-1,1))),axis=1)\n",
        "MD_T_anomaly = np.concatenate((T_1_anomal.reshape((-1,1)),T_2_anomal.reshape((-1,1)),T_3_anomal.reshape((-1,1)),T_4_anomal.reshape((-1,1)),T_5_anomal.reshape((-1,1))),axis=1)\n",
        "MD_T.shape,MD_T_anomaly.shape\n",
        "\n",
        "labels = np.zeros((n,1))\n",
        "labels[300:320]     = 1\n",
        "labels[600:610]     = 1\n",
        "labels[1300:1320]   = 1\n",
        "labels[2100:2150]   = 1\n",
        "df_synthetic = pd.DataFrame(np.concatenate((MD_T_anomaly,labels), axis = 1))\n",
        "df_synthetic.columns =  np.r_[np.array(['V'+str(i) for i in range(1,6)]),['is_anomaly']]\n",
        "df_synthetic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>is_anomaly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.003236</td>\n",
              "      <td>1.444995</td>\n",
              "      <td>0.274004</td>\n",
              "      <td>1.812345</td>\n",
              "      <td>3.528108</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.879928</td>\n",
              "      <td>-0.811228</td>\n",
              "      <td>0.493447</td>\n",
              "      <td>0.209959</td>\n",
              "      <td>0.772106</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.505797</td>\n",
              "      <td>0.257667</td>\n",
              "      <td>0.660034</td>\n",
              "      <td>-1.244442</td>\n",
              "      <td>-0.832537</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.700667</td>\n",
              "      <td>1.188726</td>\n",
              "      <td>-0.662376</td>\n",
              "      <td>-0.165581</td>\n",
              "      <td>2.061435</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.871438</td>\n",
              "      <td>0.256516</td>\n",
              "      <td>1.158229</td>\n",
              "      <td>-0.589161</td>\n",
              "      <td>-0.045855</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>-0.151023</td>\n",
              "      <td>1.145555</td>\n",
              "      <td>-0.842697</td>\n",
              "      <td>-1.021247</td>\n",
              "      <td>-0.869412</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>0.733111</td>\n",
              "      <td>0.303462</td>\n",
              "      <td>-0.081679</td>\n",
              "      <td>-1.787530</td>\n",
              "      <td>-0.832635</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>-0.665960</td>\n",
              "      <td>0.820531</td>\n",
              "      <td>0.707747</td>\n",
              "      <td>1.214123</td>\n",
              "      <td>2.076440</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>-1.134289</td>\n",
              "      <td>-0.956345</td>\n",
              "      <td>0.338015</td>\n",
              "      <td>-2.560313</td>\n",
              "      <td>-4.312932</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>1.215608</td>\n",
              "      <td>1.100671</td>\n",
              "      <td>0.684088</td>\n",
              "      <td>-0.359813</td>\n",
              "      <td>2.640553</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            V1        V2        V3        V4        V5  is_anomaly\n",
              "0    -0.003236  1.444995  0.274004  1.812345  3.528108         0.0\n",
              "1     0.879928 -0.811228  0.493447  0.209959  0.772106         0.0\n",
              "2    -0.505797  0.257667  0.660034 -1.244442 -0.832537         0.0\n",
              "3     1.700667  1.188726 -0.662376 -0.165581  2.061435         0.0\n",
              "4    -0.871438  0.256516  1.158229 -0.589161 -0.045855         0.0\n",
              "...        ...       ...       ...       ...       ...         ...\n",
              "2995 -0.151023  1.145555 -0.842697 -1.021247 -0.869412         0.0\n",
              "2996  0.733111  0.303462 -0.081679 -1.787530 -0.832635         0.0\n",
              "2997 -0.665960  0.820531  0.707747  1.214123  2.076440         0.0\n",
              "2998 -1.134289 -0.956345  0.338015 -2.560313 -4.312932         0.0\n",
              "2999  1.215608  1.100671  0.684088 -0.359813  2.640553         0.0\n",
              "\n",
              "[3000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1qjOn4Tlcb5",
        "colab_type": "text"
      },
      "source": [
        "# Average AR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN8adxUtldiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "import sys\n",
        "\n",
        "class AR_Compact:\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "\n",
        "    def create_persistence(self):\n",
        "        predictions = list()\n",
        "        for x in self.test_X:\n",
        "            yhat = self.model_persistence(x)\n",
        "            predictions.append(yhat)\n",
        "        rmse = sqrt(mean_squared_error(self.test_y, predictions))\n",
        "        # print('Train shape', self.train_X.shape, ' - Test shape:' , self.test_X.shape)\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)     \n",
        "        \n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe, train_rate) -> 'AR_Compact':\n",
        "    \treturn cls(dataframe, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, file: str, train_rate) -> 'AR_Compact':\n",
        "    \tdf = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, train_rate)\n",
        "\n",
        "    \n",
        "    def __init__(self,df, train_rate):\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "        self.train, self.test = self.dataframe.values[1:self.train_size], self.dataframe.values[self.train_size:]\n",
        "        self.train_X, self.train_y = self.train[:,0], self.train[:,1]\n",
        "        self.test_X, self.test_y = self.test[:,0], self.test[:,1]     \n",
        "        # self.create_persistence()\n",
        "\n",
        "        # X = (self.dataframe['t+1'] - self.dataframe['t']).values\n",
        "        X = series.values\n",
        "\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]\n",
        "\n",
        "          \n",
        "    def fit(self, verbose=False):\n",
        "        self.model = AR(self.train)\n",
        "        self.model_fit = self.model.fit()\n",
        "        self.window = self.model_fit.k_ar\n",
        "        self.coef = self.model_fit.params  \n",
        "        if verbose:      \n",
        "            print('Lag: %s' % self.model_fit.k_ar)\n",
        "            print('Coefficients: %s' % self.model_fit.params)\n",
        "\n",
        "    \n",
        "    def predict(self):\n",
        "        self.history = self.train[len(self.train)-self.window:]\n",
        "        self.history = [self.history[i] for i in range(len(self.history))]\n",
        "        self.predictions = list()\n",
        "        for t in range(len(self.test)):\n",
        "            length = len(self.history)\n",
        "            lag = [self.history[i] for i in range(length-self.window,length)]\n",
        "            yhat = self.coef[0]\n",
        "            for d in range(self.window):\n",
        "                yhat += self.coef[d+1] * lag[self.window-d-1]\n",
        "            obs = self.test[t]\n",
        "            self.predictions.append(yhat)\n",
        "            self.history.append(obs)        \n",
        "        # for i in range(len(predictions)):\n",
        "        #     print('predicted=%f, expected=%f' % (predictions[i], test[i]))\n",
        "        # rmse = sqrt(mean_squared_error(self.test, self.predictions))\n",
        "        self.errors = np.absolute(self.test - np.array(self.predictions))\n",
        "        # print('Prediction Test RMSE: %.3f' % rmse)\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        df_test = pd.DataFrame(self.df.iloc[self.train_size:].values)\n",
        "\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test,color ='blue', linewidth=0.5)\n",
        "        pyplot.plot(self.predictions, color='green',  linewidth=0.5)\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5)\n",
        "        pyplot.plot(df_test[df_test[1]==1.].index, df_test[df_test[1]==1.].iloc[:,0].values,'ro')\n",
        "        pyplot.show()\n",
        "\n",
        "    # def plot(self):\n",
        "    #     # plot predicted error\n",
        "    #     indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "    #     pyplot.figure(figsize=(50,5))\n",
        "    #     pyplot.plot(self.test, color='green',  linewidth=0.5,label='True Values')\n",
        "    #     pyplot.plot(self.predictions, color='blue',  linewidth=0.5,label='Predictions')\n",
        "    #     pyplot.plot(self.errors, color = 'red',  linewidth=0.5, label='Errors')\n",
        "    #     pyplot.plot(self.df[self.df['is_anomaly']==1].index[indices] - self.train_size, self.test[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size -1], linestyle=\"\",marker=\".\", label='Anomalies')\n",
        "    #     pyplot.legend()\n",
        "    #     pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# ar_model = AR_Compact('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A4Benchmark/A4Benchmark-TS18.csv', 0.3)\n",
        "# ar_model.fit()\n",
        "# ar_model.predict()\n",
        "# ar_model.plot()\n",
        "# ar_model.get_roc_auc(verbose=True)\n",
        "\n",
        "def concatenate_errors(ar_univariates, dimension):\n",
        "    pci_ = ar_univariates[0]\n",
        "    errors = np.zeros((len(pci_.errors),dimension))\n",
        "    errors[:,0] = pci_.errors.T\n",
        "    # for i in range(1,5):\n",
        "    for i in range(1,dimension):\n",
        "        errors[:,0:i+1] = np.c_[errors[:,:i],ar_univariates[i].errors.reshape(-1,1)]\n",
        "    return np.min(errors,axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ovFq-dllhjj",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIZfpvbeSvGQ",
        "colab_type": "text"
      },
      "source": [
        "### Results SD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJb2L9Wmliw6",
        "colab_type": "code",
        "outputId": "8ea6db40-b41e-4191-9b1a-cd89b44dad58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "dimension = 5\n",
        "# df = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "ar_univariates = []\n",
        "for i in range (5):\n",
        "    print(i)\n",
        "    df_univariate = pd.DataFrame(np.c_[df_synthetic.iloc[:,i].values,df_synthetic.iloc[:,-1].values])\n",
        "    df_univariate.columns = ['V1','is_anomaly']\n",
        "    ar = AR_Compact.from_DataFrame(df_univariate,0.3)\n",
        "    # ar.getAndReadAnaomaliesByPCI(plot=False)\n",
        "    ar.fit()\n",
        "    ar.predict()\n",
        "    ar_univariates.append(ar)\n",
        "\t\n",
        "errors = concatenate_errors(ar_univariates)\n",
        "ar_full = AR_Compact.from_DataFrame(df_synthetic,0.3)\n",
        "ar_full.errors = errors\n",
        "ar_full.get_roc_auc(verbose=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.microseconds/1000, 'ms')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.5113027210884354\n",
            "Time:  278.339 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT4GDOYOSqQr",
        "colab_type": "text"
      },
      "source": [
        "### Results SMTP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-Vlp8JDllvo",
        "colab_type": "code",
        "outputId": "d42579e0-3cdb-4308-d7eb-aad1cac0ac69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "dimension = 2\n",
        "# df = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "ar_univariates = []\n",
        "df_stmp = read_csv('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv', header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "df_stmp.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "for i in range (dimension):\n",
        "    print(i)\n",
        "    df_univariate = pd.DataFrame(np.c_[df_stmp.iloc[:,i].values,df_stmp.iloc[:,-1].values])\n",
        "    df_univariate.columns = ['V1','is_anomaly']\n",
        "    ar = AR_Compact.from_DataFrame(df_univariate,0.3)\n",
        "    # ar.getAndReadAnaomaliesByPCI(plot=False)\n",
        "    ar.fit()\n",
        "    ar.predict()\n",
        "    ar_univariates.append(ar)\n",
        "\t\n",
        "errors = concatenate_errors(ar_univariates,dimension)\n",
        "ar_full = AR_Compact.from_DataFrame(df_stmp,0.3)\n",
        "ar_full.errors = errors\n",
        "ar_full.get_roc_auc(verbose=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.6055392396036628\n",
            "Time:  0:00:21.916244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1kDf2JRqRBb",
        "colab_type": "text"
      },
      "source": [
        "#Average MA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bvK6jZsqSNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "import sys\n",
        "\n",
        "class MA_Average:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe, train_rate) -> 'MA':\n",
        "    \treturn cls(dataframe, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, file: str, train_rate) -> 'MA':\n",
        "    \tdf = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, train_rate)\n",
        "\n",
        "    \n",
        "    def __init__(self,df, train_rate):\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        X = self.dataframe.values\n",
        "        self.train_size = int(len(X) * train_rate)\n",
        "\n",
        "        self.train, self.test = self.dataframe.values[1:self.train_size], self.dataframe.values[self.train_size:]\n",
        "        self.train_X, self.train_y = self.train[:,0], self.train[:,1]\n",
        "        self.test_X, self.test_y = self.test[:,0], self.test[:,1]     \n",
        "        # self.create_persistence()\n",
        "\n",
        "        # X = (self.dataframe['t+1'] - self.dataframe['t']).values\n",
        "        X = series.values\n",
        "\n",
        "        # persistence model on training set\n",
        "        self.train_pred = [x for x in self.train_X]\n",
        "        # calculate residuals\n",
        "        self.train_resid = [self.train_y[i]-self.train_pred[i] for i in range(len(self.train_pred))]\n",
        "\n",
        "    # def __init__(self, path, train_rate):\n",
        "\n",
        "    #     self.df = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "    #     self.df = self.df.reset_index(drop=True)\n",
        "    #     self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "    #     series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "    #     self.values = DataFrame(series.values)\n",
        "    #     self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "    #     self.dataframe.columns = ['t', 't+1']\n",
        "    #     X = self.dataframe.values\n",
        "\n",
        "    #     self.train_size = int(len(X) * train_rate)    \n",
        "\n",
        "    #     train, test = X[1:self.train_size], X[self.train_size:]\n",
        "    #     self.train_X, self.train_y = train[:,0], train[:,1]\n",
        "    #     self.test_X, self.test_y = test[:,0], test[:,1]        \n",
        "    #     # persistence model on training set\n",
        "    #     self.train_pred = [x for x in self.train_X]\n",
        "    #     # calculate residuals\n",
        "    #     self.train_resid = [self.train_y[i]-self.train_pred[i] for i in range(len(self.train_pred))]\n",
        "\n",
        "    def fit(self, verbose=False):\n",
        "        self.model = AR(self.train_resid)\n",
        "        self.model_fit = self.model.fit()\n",
        "        self.window = self.model_fit.k_ar\n",
        "        self.coef = self.model_fit.params        \n",
        "        if verbose:\n",
        "            print(self.coef)\n",
        "\n",
        "    def predict(self):\n",
        "        # walk forward over time steps in test\n",
        "        self.history = self.train_resid[len(self.train_resid)-self.window:]\n",
        "        self.history = [self.history[i] for i in range(len(self.history))]\n",
        "        self.predictions = list()\n",
        "        for t in range(len(self.test_y)):\n",
        "            # persistence\n",
        "            yhat = self.test_X[t]\n",
        "            error = self.test_y[t] - yhat\n",
        "            # predict error\n",
        "            length = len(self.history)\n",
        "            lag = [self.history[i] for i in range(length-self.window,length)]\n",
        "            pred_error = self.coef[0]\n",
        "            for d in range(self.window):\n",
        "                pred_error += self.coef[d+1] * lag[self.window-d-1]\n",
        "            # correct the prediction\n",
        "            yhat = yhat + pred_error\n",
        "            self.predictions.append(yhat)\n",
        "            self.history.append(error)\n",
        "            # print('predicted=%f, expected=%f' % (yhat, test_y[t]))\n",
        "        rmse = sqrt(mean_squared_error(self.test_y, self.predictions))\n",
        "        self.errors = np.absolute(self.test_y - np.array(self.predictions))\n",
        "        # print('Prediction Test RMSE: %.3f' % rmse)\n",
        "\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        df_test = pd.DataFrame(self.df.iloc[self.train_size:].values)\n",
        "\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test_y,color ='blue', linewidth=0.5)\n",
        "        pyplot.plot(self.predictions, color='green',  linewidth=0.5)\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5)\n",
        "        pyplot.plot(df_test[df_test[1]==1.].index, df_test[df_test[1]==1.].iloc[:,0].values,'ro')\n",
        "        pyplot.show()\n",
        "\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index - self.train_size ]\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "# ar_model = AR_Compact('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A4Benchmark/A4Benchmark-TS18.csv', 0.3)\n",
        "# ar_model.fit()\n",
        "# ar_model.predict()\n",
        "# ar_model.plot()\n",
        "# ar_model.get_roc_auc(verbose=True)\n",
        "\n",
        "def concatenate_errors(ar_univariates, dimension):\n",
        "    pci_ = ar_univariates[0]\n",
        "    errors = np.zeros((len(pci_.errors),dimension))\n",
        "    errors[:,0] = pci_.errors.T\n",
        "    # for i in range(1,5):\n",
        "    for i in range(1,dimension):\n",
        "        errors[:,0:i+1] = np.c_[errors[:,:i],ar_univariates[i].errors.reshape(-1,1)]\n",
        "    return np.min(errors,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIjMhQGIqgPC",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yT0Qdu8S2_s",
        "colab_type": "text"
      },
      "source": [
        "### Results SMTP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r6PxddmqhAx",
        "colab_type": "code",
        "outputId": "3afbbbb8-06ad-4212-e345-8f3f2af2c3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "dimension = 2\n",
        "# df = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "ar_univariates = []\n",
        "df_stmp = read_csv('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv', header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "df_stmp.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "for i in range (dimension):\n",
        "    print(i)\n",
        "    df_univariate = pd.DataFrame(np.c_[df_stmp.iloc[:,i].values,df_stmp.iloc[:,-1].values])\n",
        "    df_univariate.columns = ['V1','is_anomaly']\n",
        "    ar = MA_Average.from_DataFrame(df_univariate,0.3)\n",
        "    # ar.getAndReadAnaomaliesByPCI(plot=False)\n",
        "    ar.fit()\n",
        "    ar.predict()\n",
        "    ar_univariates.append(ar)\n",
        "\t\n",
        "errors = concatenate_errors(ar_univariates,dimension)\n",
        "ar_full = MA_Average.from_DataFrame(df_stmp,0.3)\n",
        "ar_full.errors = errors\n",
        "ar_full.get_roc_auc(verbose=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOZ2NnRCuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8203699707251164\n",
            "Time:  0:00:04.403444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MNfMVrOqskw",
        "colab_type": "text"
      },
      "source": [
        "# Average XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5BJcGe4qurb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class XGBRegressor_Average_AnomalyDetection:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, train_rate) -> 'XGBRegressor_AnomalyDetection':\n",
        "    \treturn cls(dataframe, window_width, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, window_width, train_rate) -> 'XGBRegressor_AnomalyDetection':\n",
        "    \tdf = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df,window_width, train_rate)\n",
        "         \n",
        "    def __init__(self,df, window_width, train_rate):\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "        self.window_width = window_width\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "        # train_labeled, test_labeled = self.dataframe.values[1:self.train_size], self.dataframe.values[self.train_size:]\n",
        "        # self.train_X, self.train_y = train_labeled[:,0], train_labeled[:,1]\n",
        "        # self.test_X, self.test_y = test_labeled[:,0], test_labeled[:,1]     \n",
        "        # self.create_persistence()\n",
        "\n",
        "        # X = series.values\n",
        "        # self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "\n",
        "    def __build_sets(self):\n",
        "        train_labeled, test_labeled = self.dataframe.values[1:self.train_size], self.dataframe.values[self.train_size:]\n",
        "        self.train_X, self.train_y = train_labeled[:,0], train_labeled[:,1]\n",
        "        self.test_X, self.test_y = test_labeled[:,0], test_labeled[:,1]   \n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = []\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors.append(X[i:i+self.window_width])\n",
        "        return vectors\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        xgb = XGBRegressor()\n",
        "        xgb.fit(self.train_X.reshape(-1,1),self.train_y.reshape(-1,1))\n",
        "\n",
        "        self.predictions = xgb.predict(self.test_X.reshape(-1,1))\n",
        "        rmse = sqrt(mean_squared_error(self.test, self.predictions))\n",
        "        self.errors = np.absolute(self.test - np.array(self.predictions))\n",
        "#         print('Prediction Test RMSE: %.3f' % rmse)\n",
        "    \n",
        "\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        df_test = pd.DataFrame(self.df.iloc[self.train_size:].values)\n",
        "\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test)\n",
        "        pyplot.plot(self.predictions, color='blue')\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5)\n",
        "        pyplot.plot(df_test[df_test[1]==1.].index, df_test[df_test[1]==1.].iloc[:,0].values,'ro')\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# ar_model = AR_Compact('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A4Benchmark/A4Benchmark-TS18.csv', 0.3)\n",
        "# ar_model.fit()\n",
        "# ar_model.predict()\n",
        "# ar_model.plot()\n",
        "# ar_model.get_roc_auc(verbose=True)\n",
        "\n",
        "\n",
        "def concatenate_errors(ar_univariates, dimension):\n",
        "    pci_ = ar_univariates[0]\n",
        "    errors = np.zeros((len(pci_.errors),dimension))\n",
        "    errors[:,0] = pci_.errors.T\n",
        "    # for i in range(1,5):\n",
        "    for i in range(1,dimension):\n",
        "        errors[:,0:i+1] = np.c_[errors[:,:i],ar_univariates[i].errors.reshape(-1,1)]\n",
        "    return np.min(errors,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnkT4RJ8q8QW",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2qwbsWlS_MA",
        "colab_type": "text"
      },
      "source": [
        "### Results SMTP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbe5ZYE7q7ZZ",
        "colab_type": "code",
        "outputId": "c6d13f09-6cb7-44bc-d2f2-71a312cb313f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "dimension = 2\n",
        "# df = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "ar_univariates = []\n",
        "df_stmp = read_csv('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv', header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "df_stmp.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "for i in range (dimension):\n",
        "    print(i)\n",
        "    df_univariate = pd.DataFrame(np.c_[df_stmp.iloc[:,i].values,df_stmp.iloc[:,-1].values])\n",
        "    df_univariate.columns = ['V1','is_anomaly']\n",
        "    ar = XGBRegressor_Average_AnomalyDetection.from_DataFrame(df_univariate,100,0.3)\n",
        "    # ar.getAndReadAnaomaliesByPCI(plot=False)\n",
        "    ar.fit()\n",
        "    ar_univariates.append(ar)\n",
        "\t\n",
        "errors = concatenate_errors(ar_univariates,dimension)\n",
        "ar_full = XGBRegressor_Average_AnomalyDetection.from_DataFrame(df_stmp,100,0.3)\n",
        "ar_full.errors = errors\n",
        "ar_full.get_roc_auc(verbose=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[08:28:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "1\n",
            "[08:28:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLyKSJ/4XHeobZP+9x48AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.9058854714006906\n",
            "Time:  0:00:01.338873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuam-lbPrUvW",
        "colab_type": "text"
      },
      "source": [
        "# Average OCSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJuBg4WIrWT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class OneClassSVM_Average_AnomalyDetection:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, nu, train_rate) -> 'OneClassSVM_AnomalyDetection':\n",
        "    \treturn cls(dataframe, window_width, nu, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, window_width, nu, train_rate) -> 'OneClassSVM_AnomalyDetection':\n",
        "    \tdf = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df,window_width, nu, train_rate)\n",
        "     \n",
        "    def __init__(self,df, window_width, nu, train_rate):\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "        self.nu = nu\n",
        "        self.window_width = window_width\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "        # train_labeled, test_labeled = self.dataframe.values[1:self.train_size], self.dataframe.values[self.train_size:]\n",
        "        # self.train_X, self.train_y = train_labeled[:,0], train_labeled[:,1]\n",
        "        # self.test_X, self.test_y = test_labeled[:,0], test_labeled[:,1]     \n",
        "        # self.create_persistence()\n",
        "\n",
        "        # X = series.values\n",
        "        # self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "\n",
        "    def __build_sets(self):\n",
        "        train_labeled, test_labeled = self.dataframe.values[1:self.train_size], self.dataframe.values[self.train_size:]\n",
        "        self.train_X, self.train_y = train_labeled[:,0], train_labeled[:,1]\n",
        "        self.test_X, self.test_y = test_labeled[:,0], test_labeled[:,1]   \n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = []\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors.append(X[i:i+self.window_width])\n",
        "        return vectors\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        self.errors = np.zeros_like(self.test)\n",
        "        # compute anomalies\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "        # history = self.getWindowedVectors(self.train)\n",
        "\n",
        "        for i,_ in enumerate(self.test[:-self.window_width+1]):\n",
        "            sys.stdout.write('\\r'+str(i)+':'+str(len(self.test) - self.window_width))\n",
        "\n",
        "            window = self.test[i:i+self.window_width]\n",
        "            window2D = np.zeros((len(window),2))\n",
        "            window2D[:,1] = window\n",
        "            clf=OneClassSVM(nu=self.nu)\n",
        "            clf.fit(window2D)\n",
        "            error = clf.decision_function(window2D) \n",
        "            error[error>0] = 0\n",
        "            self.errors[i:i+self.window_width] += error*-10\n",
        "\n",
        "\n",
        "        # normalize anomaly score\n",
        "        self.errors[:-self.window_width+1] /= self.window_width\n",
        "        for i,error in enumerate(self.test[-self.window_width+1:]):\n",
        "            self.errors[-self.window_width + 1 + i] /=self.window_width-(i+1)\n",
        "\n",
        "        # self.errors_original = self.errors\n",
        "        # scalar = preprocessing.MinMaxScaler((0,1)).fit(self.errors.reshape(-1,1))\n",
        "        # self.errors = scalar.transform(self.errors.reshape(-1,1))*10\n",
        "\n",
        "\n",
        "    def plot(self):\n",
        "        df_test = pd.DataFrame(self.df.iloc[self.train_size:].values)\n",
        "\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test)\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5)\n",
        "        pyplot.plot(df_test[df_test[1]==1.].index, df_test[df_test[1]==1.].iloc[:,0].values,'ro')\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "# iforest = OneClassSVM_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_1.csv',30,0.7,0.3)\n",
        "# iforest.fit()\n",
        "# iforest.plot()\n",
        "# iforest.get_roc_auc(verbose=False)\n",
        "\n",
        "def concatenate_errors(ar_univariates):\n",
        "    pci_ = ar_univariates[0]\n",
        "    errors = np.zeros((len(pci_.errors),dimension))\n",
        "    errors[:,0] = pci_.errors.T\n",
        "    # for i in range(1,5):\n",
        "    for i in range(1,2):\n",
        "        errors[:,0:i+1] = np.c_[errors[:,:i],ar_univariates[i].errors.reshape(-1,1)]\n",
        "    return np.min(errors,axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO7zvQIJdB4A",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzM8JiToVugy",
        "colab_type": "text"
      },
      "source": [
        "### Results SMTP\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQFH-NKmdDK_",
        "colab_type": "code",
        "outputId": "eed12660-11de-4f4f-adbb-d410955486cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "def concatenate_errors(ar_univariates, dimension):\n",
        "    pci_ = ar_univariates[0]\n",
        "    errors = np.zeros((len(pci_.errors),dimension))\n",
        "    errors[:,0] = pci_.errors.T\n",
        "    # for i in range(1,5):\n",
        "    for i in range(1,dimension):\n",
        "        errors[:,0:i+1] = np.c_[errors[:,:i],ar_univariates[i].errors.reshape(-1,1)]\n",
        "    return np.mean(errors,axis=1)\n",
        "\n",
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "dimension = 2\n",
        "# df = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "ar_univariates = []\n",
        "df_stmp = read_csv('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv', header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "df_stmp.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "# df = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "ar_univariates = []\n",
        "for i in range (dimension):\n",
        "    print(i)\n",
        "    df_univariate = pd.DataFrame(np.c_[df_stmp.iloc[:,i].values,df_stmp.iloc[:,-1].values])\n",
        "    df_univariate.columns = ['V1','is_anomaly']\n",
        "    ar = OneClassSVM_Average_AnomalyDetection.from_DataFrame(df_univariate,30,0.7,0.3)\n",
        "    # ar.getAndReadAnaomaliesByPCI(plot=False)\n",
        "    ar.fit()\n",
        "    ar_univariates.append(ar)\n",
        "\t\n",
        "errors = concatenate_errors(ar_univariates,dimension)\n",
        "ar_full = OneClassSVM_Average_AnomalyDetection.from_DataFrame(df_stmp,30,0.7,0.3)\n",
        "ar_full.errors = errors\n",
        "ar_full.get_roc_auc(verbose=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.total_seconds(), 'ms')\n",
        "\n",
        "# iforest = XGBRegressor_AnomalyDetection('Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_4.csv',30,0.7,0.66)\n",
        "# iforest.fit()\n",
        "# iforest.plot()\n",
        "# iforest.get_roc_auc(verbose=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "66580:665801\n",
            "66580:66580"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7670920282239904\n",
            "Time:  103.846792 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUEm3jVqsHUK",
        "colab_type": "text"
      },
      "source": [
        "#VAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lgsNyAYsIjS",
        "colab_type": "code",
        "outputId": "62669553-3c18-407b-efbb-dd4913ac0367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "seed(42)\n",
        "from statsmodels.tsa.api import VAR, DynamicVAR\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class VAR_AnomalyDetection:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, train_rate, distance_function) -> 'Projection_AnomalyDetection':\n",
        "    \treturn cls(dataframe, window_width, dimension, train_rate, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, window_width, dimension, train_rate, distance_function) -> 'Projection_AnomalyDetection':\n",
        "    \tdf = read_csv(path, header=0, index_col=None, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df,window_width, dimension, train_rate, distance_function)\n",
        "         \n",
        "    # def __init__(self,path, window_width, dimension, train_rate):\n",
        "\n",
        "    #     self.dimension = dimension\n",
        "    #     self.n_epochs = n_epochs\n",
        "    #     self.window_width = window_width\n",
        "        \n",
        "    #     self.n_filters = n_filters\n",
        "    #     self.kernel_size = kernel_size\n",
        "    #     self.n_dense = n_dense\n",
        "\n",
        "    #     self.df = read_csv(path, header=0, index_col=None, parse_dates=True,squeeze=True)\n",
        "    #     self.df = self.df.reset_index(drop=True)\n",
        "    #     self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "    #     self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "    #     self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "        \n",
        "    #     self.X_origin = self.df.iloc[:,:dimension].values\n",
        "    #     self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "    #     df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "    #     self.values = df_sensors\n",
        "    #     self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "    #     self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,10)]),np.array(['V'+str(i)+'_t+1' for i in range(1,10)]),['is_anomaly']]\n",
        "\n",
        "    #     # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "    #     # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "    #     self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "    def __init__(self,dataframe, window_width, dimension, train_rate, distance_function):\n",
        "\n",
        "        self.df = dataframe\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "        self.distance_function = distance_function\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "        self.train_size = int(len(self.values) * train_rate)   \n",
        " \n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        self.X = self.dataframe.iloc[:,:-1].values\n",
        "        self.Y = self.dataframe.iloc[:,-1].values\n",
        "        self.train, self.test = self.X[1:self.train_size], self.X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.train[:,:self.dimension], self.train[:,self.dimension: -1]\n",
        "        self.test_X, self.test_y = self.test[:,:self.dimension], self.test[:,self.dimension: -1]\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        # self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        # self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        # self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        # self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.standardize_dataframe()\n",
        "        self.create_persistence()\n",
        "        self.build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "\n",
        "        self.compute_Errors_RMSE()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self, verbose=False):\n",
        "        self.model = VAR(self.train_X)\n",
        "        self.model_fit = self.model.fit(self.window_width)\n",
        "        self.window = self.model_fit.k_ar\n",
        "        self.coef = self.model_fit.params  \n",
        "        # if verbose:      \n",
        "        #     print('Lag: %s' % self.model_fit.k_ar)\n",
        "        #     print('Coefficients: %s' % self.model_fit.params)\n",
        "        self.history = self.train_X[len(self.train_X)-self.window:]\n",
        "        self.history = [self.history[i] for i in range(len(self.history))]\n",
        "        self.predictions = list()\n",
        "        for t in range(len(self.test_X)):\n",
        "            length = len(self.history)\n",
        "            lag = [self.history[i] for i in range(length-self.window,length)]\n",
        "            self.yhat = self.model_fit.forecast(lag,1)\n",
        "            # yhat = self.coef[0]\n",
        "            # for d in range(self.window):\n",
        "            #     yhat += self.coef[d+1] * lag[self.window-d-1]\n",
        "            obs = self.test_X[t]\n",
        "            self.predictions.append(self.yhat[0])\n",
        "            self.history.append(obs)        \n",
        "        # for i in range(len(predictions)):\n",
        "        #     print('predicted=%f, expected=%f' % (predictions[i], test[i]))\n",
        "        # rmse = sqrt(mean_squared_error(self.test, self.predictions))\n",
        "        self.error_vect = np.absolute(self.test_X - np.array(self.predictions))\n",
        "        # Calculate Mahalonbis distance \n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "\n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "                \n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def getchange(self, V_0,V_1):\n",
        "        Matrix = V_1.T@V_0@V_0.T@V_1\n",
        "        eigenvalues = np.linalg.eig(Matrix)[0]\n",
        "        lambda_min = np.min(eigenvalues)\n",
        "        return np.sqrt(max((1-lambda_min),0))\n",
        "        \n",
        "    def get_projected_Dataframe(self):\n",
        "        changes_anomaly = np.empty((len(self.X_origin)-self.window_width-1,2))\n",
        "        for i in range(len(self.X_origin)-self.window_width-1):\n",
        "            W_0 = self.X_origin[i:i+self.window_width]\n",
        "            W_1 = self.X_origin[i+1:i+self.window_width+1]\n",
        "            changes_anomaly[i] = [self.getchange(W_0,W_1),self.Y_origin[i]]         \n",
        "        return pd.DataFrame(changes_anomaly)\n",
        "\n",
        "\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16,32], [16,32,48,64],  [32,64,12,24],[128,128,128,128],[64,64,64,64],[256,256,256,256],[128,256,512,1024]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "# best_auc = [0,0]\n",
        "# histories = []\n",
        "# for f in filters:\n",
        "#     for k in kernelsizes:\n",
        "#         for d in dense:\n",
        "\n",
        "#             cnn = WaveNet_AnomalyDetection('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',30,9,20,0.3,f,k,d)\n",
        "#             hist = cnn.fit()\n",
        "#             histories.append(((f,k,d), hist))\n",
        "#             # cnn.plot()\n",
        "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#             if best_auc[1] < auc:\n",
        "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#                 best_auc = [(f,k,d),auc]\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16,32], [16,32,48,64],  [32,64,12,24],[128,128,128,128],[64,64,64,64],[256,256,256,256],[128,256,512,1024]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "\n",
        "# for epochs in [50,60,70,80,100,150,200]:\n",
        "#     # cnn = LSTM_AnomalyDetection('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',30,9,20,0.3,[4,4],k,d)\n",
        "#     cnn = LSTM_AnomalyDetection(dataframe=df,window_width=13,dimension=5,n_epochs=epochs,train_rate=0.3,n_filters=[7,7])\n",
        "#     # cnn.reset_dataframe(df,5,13, 0.3)\n",
        "#     cnn.fit()\n",
        "#     # # cnn.plot()\n",
        "#     auc = cnn.get_roc_auc(verbose=False,plot=True)\n",
        "#     print(best_auc)\n",
        "#     # 0.59 40 EPochs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r6-qHRqsbZD",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TZ2kFnvToH9",
        "colab_type": "text"
      },
      "source": [
        "### Results SMTP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwOuRW9HsMeH",
        "colab_type": "code",
        "outputId": "af84ed7c-5e58-419e-dcd8-d52f8c297a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "var = VAR_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',2,3,0.3,'mahalanobis')\n",
        "var.standardize_dataframe()\n",
        "var.create_persistence()\n",
        "var.build_sets()\n",
        "var.compute_anomalyScores()\n",
        "auc =var.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print(diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8669780250713105\n",
            "0:00:02.429761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHN6s1xHsork",
        "colab_type": "text"
      },
      "source": [
        "# VARMAX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmGdPhyWsqFp",
        "colab_type": "code",
        "outputId": "c8705d22-19ba-4c23-d23e-31155bf9a3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "seed(42)\n",
        "from statsmodels.tsa.api import VAR, DynamicVAR\n",
        "from statsmodels.tsa.statespace.varmax import VARMAX\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class VARMAX_AnomalyDetection:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, train_rate, distance_function) -> 'Projection_AnomalyDetection':\n",
        "    \treturn cls(dataframe, window_width, dimension, train_rate, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, window_width, dimension, train_rate, distance_function) -> 'Projection_AnomalyDetection':\n",
        "    \tdf = read_csv(path, header=0, index_col=None, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df,window_width, dimension, train_rate, distance_function)\n",
        "         \n",
        "    # def __init__(self,path, window_width, dimension, train_rate):\n",
        "\n",
        "    #     self.dimension = dimension\n",
        "    #     self.n_epochs = n_epochs\n",
        "    #     self.window_width = window_width\n",
        "        \n",
        "    #     self.n_filters = n_filters\n",
        "    #     self.kernel_size = kernel_size\n",
        "    #     self.n_dense = n_dense\n",
        "\n",
        "    #     self.df = read_csv(path, header=0, index_col=None, parse_dates=True,squeeze=True)\n",
        "    #     self.df = self.df.reset_index(drop=True)\n",
        "    #     self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "    #     self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "    #     self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "        \n",
        "    #     self.X_origin = self.df.iloc[:,:dimension].values\n",
        "    #     self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "    #     df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "    #     self.values = df_sensors\n",
        "    #     self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "    #     self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,10)]),np.array(['V'+str(i)+'_t+1' for i in range(1,10)]),['is_anomaly']]\n",
        "\n",
        "    #     # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "    #     # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "    #     self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "    def __init__(self,dataframe, window_width, dimension, train_rate, distance_function):\n",
        "\n",
        "        self.df = dataframe\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "        self.distance_function = distance_function\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "        self.train_size = int(len(self.values) * train_rate)   \n",
        " \n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        self.X = self.dataframe.iloc[:,:-1].values\n",
        "        self.Y = self.dataframe.iloc[:,-1].values\n",
        "        self.train, self.test = self.X[1:self.train_size], self.X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.train[:,:self.dimension], self.train[:,self.dimension: -1]\n",
        "        self.test_X, self.test_y = self.test[:,:self.dimension], self.test[:,self.dimension: -1]\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        # self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        # self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        # self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        # self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.standardize_dataframe()\n",
        "        self.create_persistence()\n",
        "        self.build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "\n",
        "        self.compute_Errors_RMSE()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self, verbose=False):\n",
        "        # model = VARMAX(data, order=(1, 1))\n",
        "        # model_fit = model.fit(disp=False)\n",
        "        # make prediction\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "        self.model = VARMAX(self.train_X, order=(self.window_width,2))\n",
        "        self.model_fit = self.model.fit(maxiter=5, disp=False)\n",
        "        # self.model = VAR(self.train_X)\n",
        "        # self.model_fit = self.model.fit(self.window_width)\n",
        "        # self.coef = self.model_fit.params  \n",
        "        # if verbose:      \n",
        "        #     print('Lag: %s' % self.model_fit.k_ar)\n",
        "        #     print('Coefficients: %s' % self.model_fit.params)\n",
        "        self.history = self.train_X[len(self.train_X)-self.window_width:]\n",
        "        self.history = [self.history[i] for i in range(len(self.history))]\n",
        "        self.predictions = list()\n",
        "        print('start')\n",
        "        for t in range(len(self.test_X)):\n",
        "            length = len(self.history)\n",
        "            warnings.filterwarnings(\"ignore\")\n",
        "            lag = [self.history[i] for i in range(length-self.window_width,length)]\n",
        "            self.yhat = self.model_fit.forecast(1)\n",
        "\n",
        "            obs = self.test_X[t]\n",
        "            self.predictions.append(self.yhat[0])\n",
        "            self.history.append(obs)        \n",
        "            sys.stdout.write('\\r'+str(t)+':'+str(len(self.test_X)))\n",
        "\n",
        "        # for i in range(len(predictions)):\n",
        "        #     print('predicted=%f, expected=%f' % (predictions[i], test[i]))\n",
        "        # rmse = sqrt(mean_squared_error(self.test, self.predictions))\n",
        "        self.error_vect = np.absolute(self.test_X - np.array(self.predictions))\n",
        "        # Calculate Mahalonbis distance \n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "\n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "                \n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def getchange(self, V_0,V_1):\n",
        "        Matrix = V_1.T@V_0@V_0.T@V_1\n",
        "        eigenvalues = np.linalg.eig(Matrix)[0]\n",
        "        lambda_min = np.min(eigenvalues)\n",
        "        return np.sqrt(max((1-lambda_min),0))\n",
        "        \n",
        "    def get_projected_Dataframe(self):\n",
        "        changes_anomaly = np.empty((len(self.X_origin)-self.window_width-1,2))\n",
        "        for i in range(len(self.X_origin)-self.window_width-1):\n",
        "            W_0 = self.X_origin[i:i+self.window_width]\n",
        "            W_1 = self.X_origin[i+1:i+self.window_width+1]\n",
        "            changes_anomaly[i] = [self.getchange(W_0,W_1),self.Y_origin[i]]         \n",
        "        return pd.DataFrame(changes_anomaly)\n",
        "\n",
        "\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16,32], [16,32,48,64],  [32,64,12,24],[128,128,128,128],[64,64,64,64],[256,256,256,256],[128,256,512,1024]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "# best_auc = [0,0]\n",
        "# histories = []\n",
        "# for f in filters:\n",
        "#     for k in kernelsizes:\n",
        "#         for d in dense:\n",
        "\n",
        "#             cnn = WaveNet_AnomalyDetection('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',30,9,20,0.3,f,k,d)\n",
        "#             hist = cnn.fit()\n",
        "#             histories.append(((f,k,d), hist))\n",
        "#             # cnn.plot()\n",
        "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#             if best_auc[1] < auc:\n",
        "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#                 best_auc = [(f,k,d),auc]\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16,32], [16,32,48,64],  [32,64,12,24],[128,128,128,128],[64,64,64,64],[256,256,256,256],[128,256,512,1024]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "\n",
        "# for epochs in [50,60,70,80,100,150,200]:\n",
        "#     # cnn = LSTM_AnomalyDetection('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',30,9,20,0.3,[4,4],k,d)\n",
        "#     cnn = LSTM_AnomalyDetection(dataframe=df,window_width=13,dimension=5,n_epochs=epochs,train_rate=0.3,n_filters=[7,7])\n",
        "#     # cnn.reset_dataframe(df,5,13, 0.3)\n",
        "#     cnn.fit()\n",
        "#     # # cnn.plot()\n",
        "#     auc = cnn.get_roc_auc(verbose=False,plot=True)\n",
        "#     print(best_auc)\n",
        "#     # 0.59 40 EPochs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2LPyZcqtS7z",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NscTkolWTtGn",
        "colab_type": "text"
      },
      "source": [
        "### Results SMTP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8ofZ33ktT-6",
        "colab_type": "code",
        "outputId": "b26ea44f-0770-4e15-f738-74b2a17f3653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "var = VARMAX_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',4,3,0.3,'mahalanobis')\n",
        "# var = VAR_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',2,3,0.3,'mahalanobis')\n",
        "var.standardize_dataframe()\n",
        "var.create_persistence()\n",
        "var.build_sets()\n",
        "var.compute_anomalyScores()\n",
        "auc =var.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print(diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "3171:66610"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixeGS06zXkY7",
        "colab_type": "text"
      },
      "source": [
        "# PCI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hccHlB-eWpdR",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation and results SMTP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0t_Rz0kXlHZ",
        "colab_type": "code",
        "outputId": "d258b0b4-6ebd-4821-c62a-5fa5ef747264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import numpy as np\n",
        "import statistics\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import read_csv\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "class PCI:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension) -> 'PCI':\n",
        "    \treturn cls(dataframe, dimension, window_width)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension) -> 'PCI':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, dimension, window_width)\n",
        "     \n",
        "    def __init__(self,dataframe, dimension, window_width):\n",
        "        self.window_width = window_width\n",
        "        self.dimension = dimension\n",
        "\n",
        "        self.df = dataframe\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        # split into train and test sets\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "\n",
        "        series = self.df.iloc[:,0]\n",
        "        self.X = series.values\n",
        "\n",
        "        self.test = self.X\n",
        "\n",
        "    def getWindow_Mean(self, sqlResult, row_index, column_index, window_width):\n",
        "        '''\n",
        "        sqlResult: The data from mysql database starting with the timestamp field\n",
        "        row_index: The record we want to analyze if it contains anomalies\n",
        "        column_index: the field in the sqlresult we want to analyze for the currenct record\n",
        "        window_width: the amount of data we bundle to compute mean and std \n",
        "        This function gets all the data that are window_width * 0.5 before and after the current data point and \n",
        "        then it computes the std and mean of it. Then it looks if they are more than 3*std away from the mean\n",
        "        '''\n",
        "        lst_field = []\n",
        "        lst_timestamp = []\n",
        "        for counter,x in enumerate(sqlResult):\n",
        "            lst_field.append(x)\n",
        "            lst_timestamp.append(counter)\n",
        "\n",
        "        index_begin = max(0,int(row_index-window_width/2))\n",
        "        index_end = min(len(lst_field),int(row_index+window_width/2))-1\n",
        "        sliced_lst_field = lst_field[index_begin:index_end]\n",
        "        sliced_lst_timestamp = lst_timestamp[index_begin:index_end]\n",
        "        mean=statistics.mean(sliced_lst_field)\n",
        "        std = statistics.stdev(sliced_lst_field)\n",
        "        lst_ad_field = []\n",
        "        lst_ad_timestamp = []\n",
        "        lst_ad_timestamp_range = []\n",
        "        for counter,elem in enumerate(sliced_lst_field):\n",
        "            if abs(elem - mean) > 3*(std):\n",
        "                lst_ad_field.append(elem)\n",
        "                lst_ad_timestamp.append(sliced_lst_timestamp[counter])\n",
        "                lst_ad_timestamp_range.append((lst_timestamp[index_begin],lst_timestamp[index_end-1]))\n",
        "        return lst_ad_timestamp,lst_ad_field, set(lst_ad_timestamp_range)\n",
        "\n",
        "    def getWindowedAnomalies(self, sql_result,show_range=False):\n",
        "        '''\n",
        "        sqlResult: The data from mysql database starting with the timestamp field\n",
        "        window_width: the amount of data we bundle to compute mean and std \n",
        "        show_range: If anomlay is detected for a data point, it marks the range of data that has been analyzed gray\n",
        "        This functions iterates over the whole data in sql_result and detects anomalies that have a value more than 3*std away from mean\n",
        "        it only analyzed this data for the second field in sql_result. The first field must contain the timestamp\n",
        "        '''\n",
        "        glb_lst_ad_timestamp, glb_lst_ad_field, glb_lst_ad_range_begin, glb_lst_ad_range_end = [],[], [],[]\n",
        "        lst_timestamp = []\n",
        "        lst_field = []\n",
        "        sliced_sqlResult = []\n",
        "        for counter, row in enumerate(sql_result):\n",
        "            lst_timestamp.append(counter)\n",
        "            lst_field.append(row)\n",
        "\n",
        "            lst_ad_timestamp, lst_ad_field, lst_ad_range = self.getWindow_Mean(sql_result,counter,1,self.window_width)\n",
        "            glb_lst_ad_timestamp += lst_ad_timestamp\n",
        "            glb_lst_ad_field += lst_ad_field\n",
        "            if show_range:\n",
        "                for ad_range in lst_ad_range:\n",
        "                    glb_lst_ad_range_begin.append(ad_range[0])\n",
        "                    glb_lst_ad_range_end.append(ad_range[1])\n",
        "\n",
        "        plt.figure(figsize=(18,5))\n",
        "        plt.plot(lst_timestamp, lst_field)\n",
        "\n",
        "        for counter,_ in enumerate(glb_lst_ad_range_begin):\n",
        "            plt.axvspan(glb_lst_ad_range_begin[counter], glb_lst_ad_range_end[counter], color='gray', alpha=0.1)\n",
        "\n",
        "        plt.plot(glb_lst_ad_timestamp, glb_lst_ad_field, linestyle=\"\",marker=\".\")\n",
        "        plt.show()\n",
        "\n",
        "    def calculatePCI(self, sql_result,index, k, BothSidedWindow= True):\n",
        "        '''\n",
        "        sqlResult: The data from mysql database starting with the timestamp field\n",
        "        index: The record we want to analyze if it contains anomalies\n",
        "        k: the k parameter from the paper\n",
        "        BothSideWindow: if true we look left and right of the datapoint, otherwise just left of the datapoint \n",
        "        This function implements completely the algorith proposed in the mentioned paper. Instead of using Students t-Test\n",
        "        I implemented a similar approach using Z-table of normal distribution\n",
        "        '''\n",
        "        lst_values = []\n",
        "        start = 0\n",
        "        end = 0\n",
        "        if BothSidedWindow:\n",
        "            start =max(0,index-k)\n",
        "            end = min(len(sql_result), index+k)-1\n",
        "        else:\n",
        "            start = max(0,index - 2*k)\n",
        "            end = min(len(sql_result),index)\n",
        "        v_i_zaehler = 0\n",
        "        v_i_nenner = 0\n",
        "        for counter,i in enumerate(range(start,end )):\n",
        "            if i == index:\n",
        "                continue\n",
        "            lst_values.append(sql_result[i])\n",
        "            w = 0\n",
        "            if i<index:\n",
        "                w = counter+1\n",
        "            else:\n",
        "                w = 2*k - counter \n",
        "            v_i_zaehler += sql_result[i]*w\n",
        "            v_i_nenner +=w\n",
        "        # if we cannot predict, just return the value\n",
        "        if v_i_zaehler == 0 or len(lst_values)<2: \n",
        "            return (sql_result[index]-1,sql_result[index]+1)\n",
        "        \n",
        "        v_index = v_i_zaehler/v_i_nenner\n",
        "        std = statistics.stdev(lst_values)\n",
        "\n",
        "        t_student=0\n",
        "        # the higher k the closer z to 0.5 - max = 120\n",
        "        # 0.5 + ((120-min(k,120))/120)*0.4999999999\n",
        "        percentile = 0.5 + ((120-min(k,120))/120)*0.4999999999\n",
        "        z = scipy.stats.norm.ppf(percentile)\n",
        "        delta = z * std* np.sqrt(1+1/2*k)\n",
        "        PCI = (v_index - delta,v_index+delta)\n",
        "        return PCI\n",
        "\n",
        "    def plotAnomaliesByPCI(self, sql_result, plot = True):\n",
        "        '''\n",
        "        sqlResult: The data from mysql database starting with the timestamp field\n",
        "        Calculate Anomalies by PCI as described in the paper and plot it\n",
        "        '''\n",
        "        lst_timestamp = []\n",
        "        lst_field = []\n",
        "        lst_PCI_up = []\n",
        "        lst_PCI_down = []\n",
        "        lst_ad_timestamp =[]\n",
        "        lst_ad_value = []\n",
        "        self.lst_anomalyScores = []\n",
        "        for counter, row in enumerate(sql_result):\n",
        "            PCI = self.calculatePCI(sql_result,counter,self.window_width,True)\n",
        "            lst_timestamp.append(counter)\n",
        "            lst_field.append(row)\n",
        "            lst_PCI_up.append(PCI[1])\n",
        "            lst_PCI_down.append(PCI[0])\n",
        "            if PCI[0]!=0:\n",
        "                self.lst_anomalyScores.append(abs(row/PCI[0]))\n",
        "            else:\n",
        "                self.lst_anomalyScores.append(min(2,row))\n",
        "\n",
        "            if row>PCI[1] or row<PCI[0]:\n",
        "                lst_ad_value.append(row)\n",
        "                lst_ad_timestamp.append(counter)\n",
        "        if plot:\n",
        "            plt.figure(figsize=(50,5))\n",
        "            plt.plot(lst_timestamp, lst_field, color='green',  linewidth=0.5,label='True Values')\n",
        "            plt.plot(self.lst_anomalyScores, color = 'red',  linewidth=0.5, label='Errors')\n",
        "            plt.plot(lst_timestamp, lst_PCI_up, color = 'gray',  linewidth=0.5, label='Upper bound')\n",
        "            plt.plot(lst_timestamp, lst_PCI_down, color = 'gray',  linewidth=0.5, label='lower bound')\n",
        "            plt.plot(lst_ad_timestamp, lst_ad_value, linestyle=\"\",marker=\".\", label='Anomalies')\n",
        "            pyplot.legend()\n",
        "            plt.show()    \n",
        "\n",
        "\n",
        "        self.errors = np.array(self.lst_anomalyScores)\n",
        "\n",
        "\n",
        "    def getAndReadAnaomaliesByPCI(self, plot = True):\n",
        "        myresult = self.test\n",
        "        self.plotAnomaliesByPCI(myresult, plot)\n",
        "        # self.getWindowedAnomalies(myresult,show_range=True)\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "def concatenate_errors(pci_univariates,dimesion):\n",
        "    pci_ = pci_univariates[0]\n",
        "    errors = np.zeros((len(pci_.errors),dimension))\n",
        "    errors[:,0] = pci_.errors.T\n",
        "    # for i in range(1,5):\n",
        "    for i in range(1,dimesion):\n",
        "        errors[:,0:i+1] = np.c_[errors[:,:i],pci_univariates[i].errors.reshape(-1,1)]\n",
        "    return np.max(errors,axis=1)\n",
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "dimension = 2\n",
        "# df = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "pci_univariates = []\n",
        "\n",
        "df_stmp = read_csv('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv', header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "df_stmp.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "for i in range (dimension):\n",
        "    df_univariate = pd.DataFrame(np.c_[df_stmp.iloc[:,i].values,df_stmp.iloc[:,-1].values])\n",
        "    df_univariate.columns = ['V1','is_anomaly']\n",
        "    pci = PCI.from_DataFrame(df_univariate,1,100)\n",
        "    pci.getAndReadAnaomaliesByPCI(plot=False)\n",
        "    pci_univariates.append(pci)\n",
        "\t\n",
        "errors = concatenate_errors(pci_univariates,dimension)\n",
        "pci_full = PCI.from_DataFrame(df_stmp,dimension,100)\n",
        "pci_full.errors = errors\n",
        "pci_full.get_roc_auc(verbose=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff, 'ms')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7996102890691775\n",
            "Time:  0:00:01.362363 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
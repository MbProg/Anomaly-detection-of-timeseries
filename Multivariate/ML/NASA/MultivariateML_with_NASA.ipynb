{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultivariateML with NASA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOTHyyQ0OeQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cMwM2bSOfws",
        "colab_type": "code",
        "outputId": "5ec238c7-d5b4-48d6-f1e6-6ecf605160bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd4DMD8mR5Ty",
        "colab_type": "text"
      },
      "source": [
        "# Generate synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poArBOs0BIB0",
        "colab_type": "code",
        "outputId": "ecaf1ff5-d4d8-4a8a-fe05-0ebb21504d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima_process import arma_generate_sample\n",
        "n = int(3000)\n",
        "# alpha1 = 0.666, alpha2 = -.333\n",
        "alphas = np.array([.1])\n",
        "betas = np.array([0.])\n",
        "\n",
        "# Python requires us to specify the zero-lag value which is 1\n",
        "# Also note that the alphas for the AR model must be negated\n",
        "# We also set the betas for the MA equal to 0 for an AR(p) model\n",
        "# For more information see the examples at statsmodels.org\n",
        "ar = np.r_[1, -alphas]\n",
        "ma = np.r_[1, betas]\n",
        "# # AR(2)\n",
        "# ar2 = arma_generate_sample(ar=ar, ma=ma, nsample=n) \n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.plot( ar2)\n",
        "\n",
        "T_1 =  arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_2 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_3 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_4 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_5 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "M =[[1 , 0 , 0 , 0 , 1],\n",
        "[0 , 1 , 0 , 0 , 1],\n",
        "[0 , 0 , 1 , 0 , 1],\n",
        "[0 , 0 , 0 , 1 , 1],\n",
        "[1 , -1 , 0 , 0 , 1]]\n",
        "delta = np.zeros((n,1))\n",
        "delta_anomal = np.zeros((n,1))\n",
        "delta_anomal[300:320]   = np.ones((20,1))\n",
        "delta_anomal[600:610]   = np.full((10,1),-0.7)\n",
        "delta_anomal[1300:1320] = np.full((20,1),2)\n",
        "delta_anomal[2100:2150] = np.full((50,1),-1.5)\n",
        "\n",
        "# delta_anomal[41:50] = np.ones((9,1))\n",
        "N = np.concatenate((T_1,T_2,T_3,T_4,delta), axis=1)\n",
        "N_anomal =  np.concatenate((T_1,T_2,T_3,T_4,delta_anomal), axis=1)\n",
        "B = N@M\n",
        "B_anomal = N_anomal@M\n",
        "\n",
        "T_1 = B[:,0]\n",
        "T_2 = B[:,1]\n",
        "T_3 = B[:,2]\n",
        "T_4 = B[:,3]\n",
        "T_5 = B[:,4]\n",
        "\n",
        "\n",
        "T_1_anomal = B_anomal[:,0]\n",
        "T_2_anomal = B_anomal[:,1]\n",
        "T_3_anomal = B_anomal[:,2]\n",
        "T_4_anomal = B_anomal[:,3]\n",
        "T_5_anomal = B_anomal[:,4]\n",
        "\n",
        "MD_T = np.concatenate((T_1.reshape((-1,1)),T_2.reshape((-1,1)),T_3.reshape((-1,1)),T_4.reshape((-1,1)),T_5.reshape((-1,1))),axis=1)\n",
        "MD_T_anomaly = np.concatenate((T_1_anomal.reshape((-1,1)),T_2_anomal.reshape((-1,1)),T_3_anomal.reshape((-1,1)),T_4_anomal.reshape((-1,1)),T_5_anomal.reshape((-1,1))),axis=1)\n",
        "MD_T.shape,MD_T_anomaly.shape\n",
        "\n",
        "labels = np.zeros((n,1))\n",
        "labels[300:320]     = 1\n",
        "labels[600:610]     = 1\n",
        "labels[1300:1320]   = 1\n",
        "labels[2100:2150]   = 1\n",
        "df_synthetic = pd.DataFrame(np.concatenate((MD_T_anomaly,labels), axis = 1))\n",
        "df_synthetic.columns =  np.r_[np.array(['V'+str(i) for i in range(1,6)]),['is_anomaly']]\n",
        "df_synthetic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>is_anomaly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.106033</td>\n",
              "      <td>-0.574796</td>\n",
              "      <td>-0.625170</td>\n",
              "      <td>-0.854381</td>\n",
              "      <td>-5.160379</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.352173</td>\n",
              "      <td>0.209658</td>\n",
              "      <td>0.267954</td>\n",
              "      <td>-0.750221</td>\n",
              "      <td>-1.624782</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.879502</td>\n",
              "      <td>-0.799794</td>\n",
              "      <td>0.011365</td>\n",
              "      <td>-0.560125</td>\n",
              "      <td>-0.469051</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.401890</td>\n",
              "      <td>-0.560127</td>\n",
              "      <td>1.275989</td>\n",
              "      <td>0.288648</td>\n",
              "      <td>-0.397380</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.716682</td>\n",
              "      <td>-0.675887</td>\n",
              "      <td>0.920035</td>\n",
              "      <td>-0.515589</td>\n",
              "      <td>-0.988123</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>0.033164</td>\n",
              "      <td>-0.001892</td>\n",
              "      <td>3.345461</td>\n",
              "      <td>1.010613</td>\n",
              "      <td>4.387345</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>-0.077752</td>\n",
              "      <td>-0.532995</td>\n",
              "      <td>-0.212790</td>\n",
              "      <td>-0.500596</td>\n",
              "      <td>-1.324132</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>-1.190825</td>\n",
              "      <td>-1.460590</td>\n",
              "      <td>-0.144262</td>\n",
              "      <td>0.825633</td>\n",
              "      <td>-1.970045</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>0.447017</td>\n",
              "      <td>-0.400606</td>\n",
              "      <td>0.625112</td>\n",
              "      <td>0.352931</td>\n",
              "      <td>1.024453</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>-0.621831</td>\n",
              "      <td>-0.147969</td>\n",
              "      <td>0.143183</td>\n",
              "      <td>-1.055274</td>\n",
              "      <td>-1.681890</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            V1        V2        V3        V4        V5  is_anomaly\n",
              "0    -3.106033 -0.574796 -0.625170 -0.854381 -5.160379         0.0\n",
              "1    -1.352173  0.209658  0.267954 -0.750221 -1.624782         0.0\n",
              "2     0.879502 -0.799794  0.011365 -0.560125 -0.469051         0.0\n",
              "3    -1.401890 -0.560127  1.275989  0.288648 -0.397380         0.0\n",
              "4    -0.716682 -0.675887  0.920035 -0.515589 -0.988123         0.0\n",
              "...        ...       ...       ...       ...       ...         ...\n",
              "2995  0.033164 -0.001892  3.345461  1.010613  4.387345         0.0\n",
              "2996 -0.077752 -0.532995 -0.212790 -0.500596 -1.324132         0.0\n",
              "2997 -1.190825 -1.460590 -0.144262  0.825633 -1.970045         0.0\n",
              "2998  0.447017 -0.400606  0.625112  0.352931  1.024453         0.0\n",
              "2999 -0.621831 -0.147969  0.143183 -1.055274 -1.681890         0.0\n",
              "\n",
              "[3000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PZ9KXMnSAAr",
        "colab_type": "text"
      },
      "source": [
        "# OCSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsQLF1wlSCdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class OneClassSVM_AnomalyDetection_MV:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, nu, train_rate, distance_function) -> 'OneClassSVM_AnomalyDetection_MV':\n",
        "    \treturn cls(dataframe, dimension, window_width, nu, train_rate, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension, nu, train_rate, distance_function) -> 'OneClassSVM_AnomalyDetection_MV':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, dimension, window_width, nu, train_rate, distance_function)\n",
        "     \n",
        "    def __init__(self,dataframe, dimension, window_width, nu, train_rate, distance_function):\n",
        "        self.distance_function = distance_function\n",
        "        self.nu = nu\n",
        "        self.df = dataframe\n",
        "        self.window_width = window_width\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "\t\t\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return np.array(dataX), np.array(dataY)\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def __build_sets(self):\n",
        "\t\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        # self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        self.errors = np.zeros_like(self.test[:,0])\n",
        "        # compute anomalies\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "        for i,_ in enumerate(self.test[:-self.window_width+1]):\n",
        "            sys.stdout.write('\\r'+str(i)+':'+str(len(self.test) - self.window_width))\n",
        "\n",
        "            window = self.test[i:i+self.window_width]\n",
        "            clf=OneClassSVM(nu=self.nu)\n",
        "            clf.fit(window)\n",
        "            error = clf.decision_function(window) \n",
        "            error[error>0] = 0\n",
        "            self.errors[i:i+self.window_width] += error*-10\n",
        "\n",
        "\n",
        "        # normalize anomaly score\n",
        "        self.errors[:-self.window_width+1] /= self.window_width\n",
        "        for i,error in enumerate(self.test[-self.window_width+1:]):\n",
        "            self.errors[-self.window_width + 1 + i] /=self.window_width-(i+1)\n",
        "\n",
        "        # self.errors_original = self.errors\n",
        "        # scalar = preprocessing.MinMaxScaler((0,1)).fit(self.errors.reshape(-1,1))\n",
        "        # self.errors = scalar.transform(self.errors.reshape(-1,1))*10\n",
        "\n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "\n",
        "# iforest = OneClassSVM_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',None,30,3,0.7,0.3)\n",
        "# iforest.fit()\n",
        "# auc = iforest.get_roc_auc(verbose=False,plot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u80EmlqNSGMw",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYwLjK0DSG7d",
        "colab_type": "code",
        "outputId": "5dbce02a-3331-426d-eace-c953e430d802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# dataframe,window_width, dimension, nu, train_rate\n",
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "ocsvm = OneClassSVM_AnomalyDetection_MV.from_DataFrame(df_synthetic,350,5,0.9,0.3, 'mahalanobis')\n",
        "ocsvm.fit()\n",
        "auc = ocsvm.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1750:1750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEckQ/x+oOvwwMTJAPwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8324217687074831\n",
            "Time:  18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC6UeC-jip7n",
        "colab_type": "text"
      },
      "source": [
        "### Results for NASA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FBBoen8OPaC",
        "colab_type": "code",
        "outputId": "80d09bf4-937a-4d97-bba3-ccacbec4d32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "# dataframe,window_width, dimension, nu, train_rate\n",
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "ocsvm = OneClassSVM_AnomalyDetection_MV.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,350,9,0.9,0.3, 'mahalanobis')\n",
        "ocsvm.fit()\n",
        "auc = ocsvm.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34018:34018"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAZMUlEQVR4nO3dbYxc133f8e9/nvZ5uct9ICmSEmWL\nksy6BaxsFNdGahd2C0kvKAQpEgkwGhuCBbhVUNRGABUplEB50aZGUyCAWodBDNcpYkVJgYRAaOhF\notRAYLqi40YwJdOmZYq7FMVd7vPuPM/8+2Lu7g6Xu9y7uzNz78z+PsBC9945c+evC/K3h2fOPdfc\nHRER6XyJqAsQEZHWUOCLiBwQCnwRkQNCgS8ickAo8EVEDggFvojIAbFj4JvZ181s2sx+uM3rZma/\nb2ZXzewtM3us8WWKiMh+henhfwN44h6vPwmcDn6eB/7H/ssSEZFG2zHw3f07wNw9mjwNfNNrLgJD\nZnasUQWKiEhjpBpwjuPAZN3+VHDs5uaGZvY8tX8F0NfX93OPPvpoAz5eJBruUAnuVHd33MGD41C/\n7zhQDdpU3al67XjVoVJ1KtXgPAR3vgfvZf18wWt1x+967Y79tXP4Fm3X9n3Tfv1573xNwhvuzXBi\nuKdp5//+979/293H9vLeRgR+aO5+DjgHMDEx4ZcuXWrlx0uHKpar5IoVVotlssXK+nauWCFbt11/\nLBu0zRYr5EsVKlWnXHHK1SqVqlOq1EJ4836xUqVYDn4q1X3XngD60kkGe1IkzEiYkUwYCYNEItg3\nw4zguJFIGEljfTtR/1r9++v27a42m95vhm367KTZXW3Wa0psnH/t823TZ6eTCVJJI5VIkE4aXakk\nfV1J0sm7BxbM6raxu4/Zna/deezuc7DVOdbb2RbH7v35W9YZ7Nim13vSSYZ6M3e/uUHM7L29vrcR\ngX8DOFm3fyI4Jh3O3SkEwbcegnX7hU37te3K+va93lssVync47W17XypwuxqMXTNZtCbTtKTSdHX\nlaQnnaQ7nSSdrIVVXzpFMmGkErX9VDKxsZ0wMqkEmWSSTCrBQHeKvkxyvc3Gf2ttU4mNwMukEsFn\nJehOJ+lKJ+o+W5PlpDUaEfjngRfM7FXgF4BFd79rOEcaz91ZLpSZWS4wu1KkWK5Sqqz91HqnpYpT\nqlQpV6oUK065UqVcdYrlKuVqlXKl1mstV5yVQpnFXGmLwK1sGcylSuP+wb8epqkEmWTiju2uYLs7\nnWCwOxW8llxvN9qfYag3Q28mGfyktt3uTifu6OGJHCQ7Br6ZfQv4NDBqZlPAbwFpAHf/GnABeAq4\nCmSBLzSr2E63lC9xazHP31+fJ1essJSvBfBSrsRSvhRsl1kplFktlFnOl/c1rJBMGOmkkQ56or2Z\nFEO96fWgHexOrYftnSGcXN/u2iKg17dTCbqSCbrSd76nvl1XKkE6mSCZUAiLNNuOge/uz+7wugP/\ntmEVdZh8qcI7N5e4vVJkfrXI7GqR+WyR2ZUiy/nS+njyzEqBybncXe/vzSQ51JNmsDvNYE+KY4e6\n6e9O0d+Vor87xUhfhvGBbkb6M3SlakMTa2On6WSCdCJBOhUMK6yNqQYhn1DIihwoLf3StlO4O7Or\nRRaypfUe+GKuxEK2yGKu1itfzJX4++vzXJ/Lrs/AWNOdTnC4N8NgT5reTJK+rhRjA1386sRJ7h/p\nY7Q/wyNHBhjsSWt8V0Qa5sAHfrFcZXo5z2qhsj5Usloo14ZXlgp8sJRnvi7c14J9tVjZ9pz9XSkO\n9aQZ6c/wqz9/kk89PMaxQ90c7ssw0tdFTybZwv9DEZGaAxP47s6tpQLXZle5dnuV/3ttjos/nWV6\nuUC5uv2Xj7WQzjDUm+a+oW4+cmyQQz217bGBLgZ70gz1pDkU/KhXLiJx1dGBPzmX5X997z3+z5UZ\n3pvNkitt9MozyQS/eHqUX3psgPsP99LflaavK0l/V4reTIrBntowS1dKvXER6QwdGfhXp1f4z9/+\nEW9cmQbgEx8e4ZMPjXJqtI9TI72cGunjvqEezQwRkQOl4wL/m9+9xn+68CMyqQRf+MQpnvvFBzl2\nqHm3OYuItIuOCvy/+dEtXvrLy/yj+wb5o1/7eY4e6o66JBGR2OiowH/jRzMkE8b//tIn6E5r7F1E\npF5HTSd5++YSP/fAsMJeRGQLHRP47s6VD5Z55MhA1KWIiMRSxwT+9HKBlUKZ00f6oy5FRCSWOibw\nL7+/CMCjRwcjrkREJJ46JvCn5msLjz042hdxJSIi8dQxgX97uUDCakshiIjI3Tom8GdWChzu69Ld\nsyIi2+icwF8uMtqv3r2IyHY6J/BXCowNdEVdhohIbHVM4E8v5RnrV+CLiGynIwJ/KV/i5mKeD49r\nDr6IyHY6IvCvz2YB+PCYpmSKiGynMwJ/rhb4Jw/3RlyJiEh8KfBFRA6Ijgn8od40g93pqEsREYmt\njgj86aW8nmolIrKDjgj8hWyJ4V717kVE7qUjAn8+W2RIgS8ick8dEfjZYoX+ro56WqOISMN1TOD3\n6LGGIiL31PaBnytWWMyVGNGyCiIi99T2gT85X5uD/8CI5uCLiNxL2wf+1LxuuhIRCaMDAr/2aMMT\nw5qHLyJyL20f+JNzWbpSCS2NLCKyg7YP/Kn5HMeHezDTow1FRO6l7QN/cj7LiWGN34uI7CRU4JvZ\nE2Z2xcyumtmLW7x+v5m9YWY/MLO3zOypxpd6t3Klyo8/WOHRowOt+DgRkba2Y+CbWRJ4BXgSOAM8\na2ZnNjX7j8Br7v4x4Bngvze60K1MzucoVqo8pCddiYjsKEwP/3Hgqru/6+5F4FXg6U1tHBgMtg8B\n7zeuxO29O7MC6ElXIiJhhAn848Bk3f5UcKzebwOfM7Mp4ALw61udyMyeN7NLZnZpZmZmD+Xe6adB\n4H9oVD18EZGdNOpL22eBb7j7CeAp4I/N7K5zu/s5d59w94mxsbF9f+hPbq0w2t/FcF9m3+cSEel0\nYQL/BnCybv9EcKzec8BrAO7+XaAbGG1Egffy3lyWD41qOEdEJIwwgf8mcNrMHjSzDLUvZc9vanMd\n+AyAmX2EWuDvf8xmB4vZEsN9WgdfRCSMHQPf3cvAC8DrwDvUZuNcNrOXzexs0OwrwBfN7B+AbwGf\nd3dvVtFBXby/mGNsQHfYioiEEeqpIe5+gdqXsfXHXqrbfhv4ZGNLu7fp5QLL+TKnxzUHX0QkjLa9\n0/Znt1cBLYssIhJW2wb+e7O1wP/wmKZkioiE0baBPzWfI5kwxgc1hi8iEkbbBv5Pbq3wwEgvXSk9\ny1ZEJIy2DfzJ+SynRjQHX0QkrLYN/Jnlgh56IiKyC20Z+JWqM7ta1Bx8EZFdaMvAn88WqVRdgS8i\nsgttGfgzywUABb6IyC60ZeDfXlHgi4jsVlsG/txqEYDhXi2LLCISVlsG/mqhAsBAd6ilgEREhDYN\n/OV8CYC+LgW+iEhYbRn4Nxfz9GWS9GV0l62ISFhtGfg3FnKcGO7FzKIuRUSkbbRn4M/nOD7cE3UZ\nIiJtpS0D//3FHPcNdUddhohIW2m7wF8tlFnIlrhvSD18EZHdaLvAv7mYA+C4Al9EZFfaLvBvLOQB\n1MMXEdml9gv8efXwRUT2ou0C//2F4NGGWkdHRGRX2jLwjw52k0q2XekiIpFqu9S8saApmSIie9F2\ngV+bg6/xexGR3WqrwK9UnZsLeX1hKyKyB20V+LdXCpSrzjEFvojIrrVV4K8/2rBfM3RERHarrQJ/\n7UlXI/160pWIyG61VeAvBQ8+OdSTjrgSEZH2016BnysDerShiMhetFfgq4cvIrJnbRX4HwSPNuxJ\n69GGIiK71VaB/+Nbyzx0ZECPNhQR2YNQgW9mT5jZFTO7amYvbtPmV8zsbTO7bGZ/0tgya658sMwj\nR/qbcWoRkY6347efZpYEXgH+BTAFvGlm59397bo2p4H/AHzS3efNbLzRhc4sF5hdLfLo0cFGn1pE\n5EAI08N/HLjq7u+6exF4FXh6U5svAq+4+zyAu083tszacA7AI0cHGn1qEZEDIUzgHwcm6/angmP1\nHgYeNrO/M7OLZvbEVicys+fN7JKZXZqZmdlVoZNzWQDuP9y7q/eJiEhNo760TQGngU8DzwJ/aGZD\nmxu5+zl3n3D3ibGxsV19wI2FHAmDo4e0NLKIyF6ECfwbwMm6/RPBsXpTwHl3L7n7z4AfU/sF0DA3\n5msPPknrwSciInsSJj3fBE6b2YNmlgGeAc5vavMX1Hr3mNkotSGedxtYJzcWchwf1iqZIiJ7tWPg\nu3sZeAF4HXgHeM3dL5vZy2Z2Nmj2OjBrZm8DbwC/4e6zjSz0xkJO6+CLiOxDqEVp3P0CcGHTsZfq\nth34cvDTcJWq88FiXj18EZF9aIsB8etzWcpV54GRvqhLERFpW20R+LdXag8+OaYZOiIie9YegR88\n6epwnx58IiKyV20R+DNBD39sQI82FBHZq7YI/OmlAgmDkT4FvojIXrVF4M8sFxjt7yKZ0LLIIiJ7\n1RaBP72c13COiMg+tUngFxhX4IuI7EtbBP7McoHxAU3JFBHZj9gHfqXq3F4pMD6oHr6IyH7EPvCX\n8yWqDsO9moMvIrIfsQ/8lUIZgP6uUMv+iIjINmIf+DPBXbZDvemIKxERaW+xD/yfTK8AcPqInmUr\nIrIfsQ/8a7dXSSZMz7IVEdmn2Af+e7NZ7j/cq7tsRUT2KfaBPzWf5YQefCIism+xD/zJ+RwnNZwj\nIrJvsQ781UKZudWievgiIg0Q68C/sZAD4MSwevgiIvsV68CfnMsCqIcvItIAsQ7892Zrga8pmSIi\n+xfrwL82u8pAd4oRPctWRGTfYh341+eynBzuxUxz8EVE9ivWgX/t9ioPjvZFXYaISEeIbeBXqs6N\nhRwnDusLWxGRRoht4M8sFyhVXFMyRUQaJLaBf2spD8DRQT3aUESkEWIf+Ef0aEMRkYaIb+AHDz45\noh6+iEhDxDbwp5fyJAzNwRcRaZDYBv6tpTyj/V2kkrEtUUSkrcQ2TW8tFTScIyLSQDEO/Ly+sBUR\naaDYBv7McoFx9fBFRBomVOCb2RNmdsXMrprZi/do98tm5mY2sZ+iiuUqs6tFjgwo8EVEGmXHwDez\nJPAK8CRwBnjWzM5s0W4A+HfA9/Zb1MzK2pRMDemIiDRKmB7+48BVd3/X3YvAq8DTW7T7HeB3gfx+\ni9q46Uo9fBGRRgkT+MeBybr9qeDYOjN7DDjp7n91rxOZ2fNmdsnMLs3MzGzbbu1JV/cNaeE0EZFG\n2feXtmaWAH4P+MpObd39nLtPuPvE2NjYtu2m5mvPsn1gRAuniYg0SpjAvwGcrNs/ERxbMwB8FPhb\nM7sGfBw4v58vbqeX8gx0p+hOJ/d6ChER2SRM4L8JnDazB80sAzwDnF970d0X3X3U3U+5+yngInDW\n3S/ttai5bInRfn1hKyLSSDsGvruXgReA14F3gNfc/bKZvWxmZ5tR1EK2yGBPuhmnFhE5sFJhGrn7\nBeDCpmMvbdP20/stamo+x0eODez3NCIiUid2d9pWq86N+Rwn9aQrEZGGil3g31rOU6xUOXFYgS8i\n0kixC/zJudqUzPsV+CIiDRXDwK/ddHVyWDddiYg0UuwC/73ZVZIJ47gCX0SkoWIX+Au5EgPdKbpS\nuulKRKSRYhf4NxfzHNZzbEVEGi52gX97pcBxLZomItJwsQv86aUCY1pWQUSk4WIV+MVylfcXc5qD\nLyLSBLEK/BsLOdw1B19EpBliFfiagy8i0jyxCvzrQeDfrwefiIg0XKwC//2FHKmEcWRAz7IVEWm0\nWAX+fLbIcF+GRMKiLkVEpOPEKvCX8mUGukMt0S8iIrsUq8CfWylyuFd32YqINEOsAn96Oc/YgG66\nEhFphtgEvrszOZ/jpObgi4g0RWwCfyFboliucnRQM3RERJohNoF/azkPwBEFvohIU8Qn8JcKAIwP\nagxfRKQZYhT4QQ9fN12JiDRFbAJ/Ogh89fBFRJojPoG/XOBQT5rutB5tKCLSDLEJ/FtLeY6ody8i\n0jQxCvwC4xq/FxFpmtgE/vRSXuP3IiJNFIvAr1ad6eWC5uCLiDRRLAJ/LlukXHXGtY6OiEjTxCLw\nb68EN11pDF9EpGliEfgzy7XAH+3X0sgiIs0Si8BfW1ZBY/giIs0Ti8B/b3aVZMI4PtwTdSkiIh0r\nVOCb2RNmdsXMrprZi1u8/mUze9vM3jKzvzazB3ZTxO2VAsO9GdLJWPz+ERHpSDsmrJklgVeAJ4Ez\nwLNmdmZTsx8AE+7+T4A/B/7LboqYWS5q/F5EpMnCdKkfB666+7vuXgReBZ6ub+Dub7h7Nti9CJzY\nTRE3F3McO6TxexGRZgoT+MeBybr9qeDYdp4Dvr3VC2b2vJldMrNLMzMz68dXC2UGutMhShERkb1q\n6KC5mX0OmAC+utXr7n7O3SfcfWJsbGz9+GKuRH93qpGliIjIJmFS9gZwsm7/RHDsDmb2WeA3gU+5\neyFsAauFMvPZEseHNENHRKSZwvTw3wROm9mDZpYBngHO1zcws48BfwCcdffp3RRwc7H24BMFvohI\nc+0Y+O5eBl4AXgfeAV5z98tm9rKZnQ2afRXoB/7MzP6fmZ3f5nR3mV1Zu8tW6+iIiDRTqIFzd78A\nXNh07KW67c/utYC51SIAI5qWKSLSVJHf6TQbBP7hPgW+iEgzRR74az384V4FvohIM0Ue+AvZEv1d\nKTKpyEsREelokafsfLbIoR7ddCUi0myRB/4Hi3ktqyAi0gKRB/70cp4xPdpQRKTpIg/82dWi5uCL\niLRApIFfqlRZyJY0B19EpAUiDfybC7VlFY7q0YYiIk0XaeD/dGYFgIfG+6MsQ0TkQIg08Oeza8sq\naAxfRKTZIg38pVwJgEGthS8i0nSRBv5irgzAoG68EhFpukgDf2Ylz6GeNOlk5LNDRUQ6XrSBv1xg\nXDddiYi0RKSBP71cYHxQgS8i0grRBv5SgfEBzcEXEWkFDemIiBwQkQV+peoUK1UtnCYi0iKRBX6p\n4gCMa1kFEZGWiCzwy9UqgIZ0RERaJLrAD3r4o1opU0SkJSLv4R/uUw9fRKQVIgx8J5kwhnu1rIKI\nSCtEFvjVqtOXSWJmUZUgInKgRDotc7hP4/ciIq0S6ZDOiAJfRKRlIp2lowefiIi0TqSzdDQlU0Sk\ndSId0jmsIR0RkZaJdPG04V4FvohIq0Qa+CMa0hERaZlIA/+IFk4TEWmZSAP/xFBvlB8vInKgRBr4\nhzWkIyLSMqEC38yeMLMrZnbVzF7c4vUuM/vT4PXvmdmpHT/YjP6u1O4rFhGRPdkx8M0sCbwCPAmc\nAZ41szObmj0HzLv7Q8B/A353xw/WEjoiIi0Vpof/OHDV3d919yLwKvD0pjZPA/8z2P5z4DO2w6po\nCSW+iEhLhRlTOQ5M1u1PAb+wXRt3L5vZIjAC3K5vZGbPA88HuwUz++Feiu5Ao2y6VgeYrsUGXYsN\nuhYbHtnrG1s6iO7u54BzAGZ2yd0nWvn5caVrsUHXYoOuxQZdiw1mdmmv7w0zpHMDOFm3fyI4tmUb\nM0sBh4DZvRYlIiKNFybw3wROm9mDZpYBngHOb2pzHvi1YPtfAX/j7t64MkVEZL92HNIJxuRfAF4H\nksDX3f2ymb0MXHL388AfAX9sZleBOWq/FHZybh91dxpdiw26Fht0LTboWmzY87UwdcRFRA6GSO+0\nFRGR1lHgi4gcEE0P/GYsy9CuQlyLL5vZ22b2lpn9tZk9EEWdrbDTtahr98tm5mbWsVPywlwLM/uV\n4M/GZTP7k1bX2Coh/o7cb2ZvmNkPgr8nT0VRZ7OZ2dfNbHq7e5Ws5veD6/SWmT0W6sTu3rQfal/y\n/hT4EJAB/gE4s6nNvwG+Fmw/A/xpM2uK6ifktfjnQG+w/aWDfC2CdgPAd4CLwETUdUf45+I08ANg\nONgfj7ruCK/FOeBLwfYZ4FrUdTfpWvwz4DHgh9u8/hTwbcCAjwPfC3PeZvfwm7IsQ5va8Vq4+xvu\nng12L1K756EThflzAfA71NZlyreyuBYLcy2+CLzi7vMA7j7d4hpbJcy1cGAw2D4EvN/C+lrG3b9D\nbcbjdp4Gvuk1F4EhMzu203mbHfhbLctwfLs27l4G1pZl6DRhrkW956j9Bu9EO16L4J+oJ939r1pZ\nWATC/Ll4GHjYzP7OzC6a2RMtq661wlyL3wY+Z2ZTwAXg11tTWuzsNk+AFi+tIOGY2eeACeBTUdcS\nBTNLAL8HfD7iUuIiRW1Y59PU/tX3HTP7x+6+EGlV0XgW+Ia7/1cz+6fU7v/5qLtXoy6sHTS7h69l\nGTaEuRaY2WeB3wTOunuhRbW12k7XYgD4KPC3ZnaN2hjl+Q794jbMn4sp4Ly7l9z9Z8CPqf0C6DRh\nrsVzwGsA7v5doJvawmoHTag82azZga9lGTbseC3M7GPAH1AL+04dp4UdroW7L7r7qLufcvdT1L7P\nOOvue140KsbC/B35C2q9e8xslNoQz7utLLJFwlyL68BnAMzsI9QCf6alVcbDeeBfB7N1Pg4suvvN\nnd7U1CEdb96yDG0n5LX4KtAP/FnwvfV1dz8bWdFNEvJaHAghr8XrwL80s7eBCvAb7t5x/woOeS2+\nAvyhmf17al/gfr4TO4hm9i1qv+RHg+8rfgtIA7j716h9f/EUcBXIAl8Idd4OvFYiIrIF3WkrInJA\nKPBFRA4IBb6IyAGhwBcROSAU+CIiB4QCX0TkgFDgi4gcEP8fo6ZnBQpBz0oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8850551467670772\n",
            "Time:  431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZtg33arSKPL",
        "colab_type": "text"
      },
      "source": [
        "# XGBoost Multivariate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEzeNzXASMxS",
        "colab_type": "code",
        "outputId": "0a790500-5e19-4c94-b133-a9f44b1cf9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "seed(42)\n",
        "from keras import regularizers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class XGB_AnomalyDetection_ML:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, train_rate) -> 'XGB_AnomalyDetection_ML':\n",
        "    \treturn cls(dataframe, window_width, dimension, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension, train_rate) -> 'XGB_AnomalyDetection_ML':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, window_width, dimension, train_rate)\n",
        "     \n",
        "    def __init__(self,df, window_width, dimension, train_rate):\n",
        "\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "\n",
        "\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "    def reset_dataframe(self, df, dimension, train_rate):\n",
        "        self.df = df\n",
        "        self.dimension = dimension\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)         \n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a.reshape(-1))\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "        # fitting\n",
        "        multioutputregressor = MultiOutputRegressor(XGBRegressor(objective='reg:linear')).fit(self.train_X, self.train_y)\n",
        "\n",
        "        # predicting\n",
        "        self.predictions = multioutputregressor.predict(self.test_X) \n",
        "        # # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
        "        # # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
        "\n",
        "        # from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "        # self.model = Sequential()\n",
        "\n",
        "        # self.model = Sequential()\n",
        "        # self.model.add(LSTM(self.n_filters[0], batch_input_shape=(1, self.window_width, self.dimension), stateful=True, return_sequences=True))\n",
        "        # self.model.add(LSTM(self.n_filters[1], batch_input_shape=(1, self.window_width, self.dimension), stateful=True))\n",
        "        # self.model.add(Dense(self.dimension))\n",
        "        # self.model.compile(optimizer='adam', loss='mse')\n",
        "        # for i in range(self.n_epochs):\n",
        "        #     sys.stdout.write('\\r'+str(i)+':'+str(self.n_epochs))\n",
        "        #     self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=1, batch_size=1, verbose=0, shuffle=False)\n",
        "        #     self.model.reset_states()\n",
        "        # print('')\n",
        "\n",
        "        # # self.plotTraining()\n",
        "        # self.predictions = self.model.predict(self.test_X, batch_size = 1)\n",
        "\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        self.euclidean_errors = numpy.linalg.norm(self.test_y.reshape(self.predictions.shape) - self.predictions, axis=1)\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        true_anomaly_predicted_errors = self.euclidean_errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.euclidean_errors[self.euclidean_errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.euclidean_errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16,32], [16,32,48,64],  [32,64,12,24],[128,128,128,128],[64,64,64,64],[256,256,256,256],[128,256,512,1024]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "\n",
        "\n",
        "# xgb = XGB_ML_AnomalyDetection('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',13,3,0.3)\n",
        "# # xgb.reset_dataframe(df,5, 0.3)\n",
        "# xgb.fit()\n",
        "# # # cnn.plot()\n",
        "# auc = xgb.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "\n",
        "# print(best_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pv9ceyXSP0j",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxz-vlvqSOd2",
        "colab_type": "code",
        "outputId": "d3ce5dcd-d3ff-43ca-a589-7697b44e602c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "xgb = XGB_AnomalyDetection_ML.from_DataFrame(df_synthetic,108,5,0.3)\n",
        "xgb.fit()\n",
        "auc = xgb.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[03:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:23:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:23:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:23:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:23:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAfOElEQVR4nO3de3xU1b338c8vIVdyhQQIhIQA4a4I\nRoKiVY+o1FbosVd7tNracmprn9r6+NSettaj53lOb8f22HrtqbUXldrT1qantl5RaRUkiiCEW7gl\nhBACuZNMksms548JkFIwA8xkT2a+79crL2bPXpn9e61X+GZl77XXNuccIiIS+xK8LkBERIaGAl9E\nJE4o8EVE4oQCX0QkTijwRUTihAJfRCRODBr4ZvaomR0ws40n2W9mdp+ZVZvZBjObH/4yRUTkTIUy\nwn8MWPIu+98LlPZ/LQcePPOyREQk3AYNfOfcq0DTuzRZBvzcBa0GcsysIFwFiohIeIwIw2dMAGoH\nbO/tf6/++IZmtpzgXwGMHDny3BkzZoTh8CIiJxdwjrauXlo6e+no9hNtawsU5qaRm54ccvs333zz\noHMu/3SOFY7AD5lz7hHgEYCysjJXWVk5lIcXkTjh6+3j5a2N/GH9Pl7Y3IDfH2B6Thrvn1vA+84q\nID8zxesSj8pOSyI9OfQoNrM9p3uscAR+HTBxwHZh/3siIkMmEHC8tuMQT79dx7Mb99Pe7Wf0yGQ+\net5Els4dz/yiXBISzOsyPRWOwK8AbjGzFUA50Oqc+7vTOSIikdDY3s1TlbWsWFtDbVMXmSkjuHLO\nOJbOHc8FU0YzIlGzz48YNPDN7EngEiDPzPYC3wSSAJxzDwHPAFcB1UAn8MlIFSsiAsHR/Os7D/HE\nmhqe3bQff8CxcPIobr9yBlfMGktqUqLXJUalQQPfOXftIPsd8PmwVSQichINbT6eXlfHk2/UsPtQ\nJznpSdx4wSSuLS9iSn6G1+VFvSG9aCsiEqoef4Cq+jbW1TTzVk0Lb+1ppq6lC4DzJuVy6+JpLJkz\nTqP5U6DAF5Go0NDm4609zayrDYb7O3WtdPsDABRkpzK/KJdPLprExdPyKR2b6XG1w5MCX0SGXI8/\nwKZ9rbxV08K6mmbW1bQcHb0nJyYwZ0IW1y8sZn5xLvOKcijITvO44tigwBeRIREIONbsauL3b9fx\nzDv1tPn8AIzPTmVecS6furCEeUU5zB6fRcoInaaJBAW+iESMc47N9e38/u06Ktbvo77VR3pyIlfO\nHsfls8YyvyiXcdmpXpcZNxT4IhJ2tU2dVKzfx9Pr6th+oIMRCcbF0/L56lUzuXzmWNKSNYL3ggJf\nRM6Ir7ePqvo2NtS2sGFvK+v3trCj8TAAZcW53POBObzvrAJGjQx9vRiJDAW+iISsty/A1v3tvFPX\nyoa9LayvbWVbQzv+QHBJsvzMFOYWZvPhsom876wCJo5K97hiGUiBLyInFAg4dh7sYH1tK+/UBUfu\nVfvajk6VzE5L4uzCbP55xmTOLsxhbmEOY7NSMIvv9WqimQJfRP5GXUsXP3h+G3/auJ+O7uBMmvTk\nROaMz+b6hcWcPTGHsydkUzw6XeE+zCjwRQSAls4eHnh5B4+9thscfGDeeMomjWJuYQ5Tx2SQGOcr\nTcYCBb5InOvq6eOnr+3iwZd30NHt55p5hXzp8lIKc3X+PdYo8EXikK+3jzd2NbFqeyMV6/fR0NbN\nZTPGcPuS6cwYl+V1eRIhCnyROHDkBqhV2xtZtf0gb+xuoscfIDkxgfLJo/jhtfNZUDLK6zIlwhT4\nIjHqQJuPVdsP8pfqg6zafpCDHd0ATBubwfULi7moNI/yktG6CSqOKPBFhrF2Xy/7W33Ut/qO/lvf\n2sXbtS1s2d8OwOiRySyamsdFpXlcVJqvpQzimAJfJAo552jr8lPf1nUszFv6X7cdC/gj0yYHystI\nYdrYDL6yZAYXleYxqyAr7p/lKkEKfJEh5pyj6XDPsSBv87G/9ViwHxmpd/X2/c33mcGYzBTGZacx\nNT+DC6fmUZCdSkFOGgXZqYzLSmVMVopWmpSTUuCLREBfwLHrYAeb9rWxdX87dS0DAr3NR0//3apH\nJCYY47JSGZedyszxWfzDjDGMy06lIDut/99U8jNTSNIDueUMKPBFztDhbj9b9rdRta+Nqvo2qurb\n2bq/DV9vMNRHJBgFOakUZKVxzsSc4Kg8O5Vx2WlHX4/OSNGNTRJxCnyREDnnaGjrpqq+9Vi472tj\nT1MnLrh2GNlpScwen8U/lRczqyCLWeOzmJKfQfIIjczFewp8kXfxWvVBVm49cDTcmzt7j+4rHp3O\nzHFZXDO/8Gi4F2Snan0ZiVoKfJETqG3q5J7/qeK5qgaSRyQwfWwmV8wax6zxwWCfMS6TzNQkr8sU\nOSUKfJEBunr6ePCVHTz8yg4SzLj9yuncdGEJqUma+SLDnwJfpN/KLQf4+tMbqWvp4uq54/mXq2ZQ\nkJ3mdVkiYaPAFyH4JKebH3+TCTlprFi+kIWTR3tdkkjYaeqACBBwDl9vgGvmFyrsJWYp8EVE4oQC\nXwSOzqPXjEqJZQp8ETi6CFlGii5rSexS4IsAHT4FvsQ+/XRLXPL3Bdiyv53K3U2s3dNM5e4mAHLT\nkz2uTCRyFPgSFzp7/Lxd08La3c1U7mnirT3NHO4JLj9ckJ1KecloyiePYtHUPI8rFYkcBb7EpAPt\nPt7c3Xw04Dfta6Mv4DCD6WMzuWZ+IWWTcimbNIoJObq5SuKDAl9iyv5WH3dVbOLPm/YDkJqUwNzC\nHG6+eAplk3KZV5RLdprWwJH4FFLgm9kS4D+BROC/nHPfOm5/EfAzIKe/zR3OuWfCXKvISQUCjsfX\n7OE7f95KT1+A//UPU7l0xhhmj8/W0sQi/QYNfDNLBO4HLgf2AmvNrMI5VzWg2deBp5xzD5rZLOAZ\nYFIE6hX5O9sa2rnjNxt4q6aFC6fm8X//cQ7Fo0d6XZZI1AllhL8AqHbO7QQwsxXAMmBg4Dsgq/91\nNrAvnEWKnMzzVQ187vE3yUgZwb0fmcs/zpug9ehFTiKUwJ8A1A7Y3guUH9fmLuA5M/sCMBJYfKIP\nMrPlwHKAoqKiU61V5G+0+Xr52u/eoXRMJr/8dDmjRmpKpci7CdfJzWuBx5xzhcBVwC/M7O8+2zn3\niHOuzDlXlp+fH6ZDS7y697ltNHZ08+/XnKWwFwlBKIFfB0wcsF3Y/95ANwFPATjnXgdSAU1oloj5\n44Z6fv76bj6xsJi5E3O8LkdkWAgl8NcCpWZWYmbJwMeAiuPa1ACXAZjZTIKB3xjOQkUADnf7+T//\nvZ7PP/EWZ03I5rYrp3tdksiwMeg5fOec38xuAZ4lOOXyUefcJjO7G6h0zlUAtwE/NrMvEbyAe6Nz\nR9YfFAmPdTXN3Pqrt6lp6uTzl07h1sXTSErUlEuRUIU0D79/Tv0zx71354DXVcCi8JYmEtTa1cvD\nr+zg4Vd3Mi4rlRWfWUi5HlIicsp0p61Erc4eP4+9tpuHX9lJa1cv18ybwDeXztadsiKnSYEvUafb\n38eKN2r54UvVHOzo5tLp+dx2xXTmTMj2ujSRYU2BL1Ghty/AO3WtrN55iMdX11DX0kV5ySgeum4+\nZZNGeV2eSExQ4Isnuv19bNjbypqdh1izq4k39zTT2b9c8byiHL71wbO4cGqe7poVCSMFvgwJX28f\n62paWLPrEGt2NvFWTTPd/gAAM8Zl8uFzCymfPJoFJaPIy0jxuFqR2KTAl4hpaPPx+JoaVu84xNu1\nLfT0BTCDmeOy+Hh5EeUlwYDXXbIiQ0OBL2HX5gtOo/zJX3bR4w8wZ0I2N1xQTHnJaM6bNIrsdM2y\nEfGCAl/Cxtfbxy9X7+FHK6tp6exl6dzx3HbFNC1VLBIlFPhyRrp6+tjR2MHbtS08+PIO6lq6uKg0\nj68smaFplCJRRoEvIWk+3EN1YwfVB4JfO/pf17V0cWQRjbMLs/nOh87Wg8BFopQCX45yzlHf6jsa\n6kcCfseBDg4d7jnaLjUpgcl5GcwvyuUjZROZkp9B6dgMSsdkaBqlSBRT4Mepdl8vr+04dDTQqxuD\n/x7unwsPkJ2WxNQxGSyeOZapYzKOfk3ISSMhQcEuMtwo8ONMfWsXj/11N0+sqaG92w9AQXYqU8dk\n8OGyiX8T7KNHJmvELhJDFPhxYnN9Gz9+dScV6/fhgKvOKuC68iJmT8gmI0U/BiLxQP/TY5hzjr9W\nH+LhV3ewavtB0pMTuf78Yj61qISJo9K9Lk9EhpgCPwY553hpywHue3E76/e2kp+Zwu1XTue68mLd\n9CQSxxT4McQ5x3NVDdz34nY27Wtj4qg0/v2as7hm/gRSRiR6XZ6IeEyBHwMCAcezm/Zz30vVbK5v\no3h0Ot/90Nl8YN4EPQJQRI5S4A9ztU2dfOlXb1O5p5nJeSO59yNzWTp3PCMU9CJyHAX+MOWc43fr\n6rjz95sw4DsfOpsPzi8kUfPjReQkFPjDUGtXL19/eiN/WL+P8yblcu9HztGsGxEZlAJ/mGn39bL0\nR3+hrrmL26+czmcvnqJRvYiERIE/zPzHc9uoaerkiU8v5Pwpo70uR0SGEV3ZG0Y27G3hZ6/v5vqF\nxQp7ETllGuEPA0fumL3z9xvJz0jhf1853euSRGQYUuBHudd3HOL7z2/jjd1NFGSn8v2PnkNWqu6W\nFZFTp8CPUm/sauL7z2/j9Z2HGJuVwt3LZvPR8ybqjlkROW0K/Cjj7wvw2V++xQubG8jLSOHO98/i\n4+VFpCYp6EXkzCjwo8xLWw7wwuYGbrl0Kp+/dCppyQp6EQkPBX6UWbG2ljGZKdy6uFTLI4hIWClR\nosj+Vh8vbz3Ah8sKFfYiEnZKlSiyZX8bAQeXTB/jdSkiEoMU+FFISyWISCQo8EVE4kRIgW9mS8xs\nq5lVm9kdJ2nzETOrMrNNZvZEeMuMDy9sbiDBID8jxetSRCQGDTpLx8wSgfuBy4G9wFozq3DOVQ1o\nUwp8FVjknGs2M52EPkXrapp5fE0NN14wSUsdi0hEhDLCXwBUO+d2Oud6gBXAsuPafAa43znXDOCc\nOxDeMmNbV08f//K7jYzNTOW2K7ROjohERiiBPwGoHbC9t/+9gaYB08zsr2a22syWnOiDzGy5mVWa\nWWVjY+PpVRxjXqhqYPG9r7C5vo1/XTabjBTdGiEikRGudBkBlAKXAIXAq2Z2lnOuZWAj59wjwCMA\nZWVlLkzHHpbqWrq4q2ITz1c1UDomgxXLF7JwspY8FpHICSXw64CJA7YL+98baC+wxjnXC+wys20E\nfwGsDUuVMaTb38ejf9nNfS9uB+CO987gU4tKSB6hCVMiElmhBP5aoNTMSggG/ceAjx/X5mngWuCn\nZpZH8BTPznAWOtz5+wL89q06/vPF7dS1dHHFrLHcefUsCnN1gVZEhsagge+c85vZLcCzQCLwqHNu\nk5ndDVQ65yr6911hZlVAH3C7c+5QJAsfLgIBxx/fqef7z29j58HDzC3M5tsfPJsLS/O8Lk1E4ow5\n582p9LKyMldZWenJsYeCc46Xthzge89tY3N9G9PHZnLbFdO4fNZYzHQnrYicHjN70zlXdjrfqykh\nEbD74GHurNjEq9saKR6dzg8+eg5Xzx2vJRNExFMK/DDy9fbx0Cs7eODlHSQnJvCN98/iE+cXk6SV\nL0UkCijww2TV9ka+8fRGdh/q5P1nF/CN989ibFaq12WJiBylwD9Dh7v93PM/VaxYW0tJ3kh+cdMC\nLirN97osEZG/o8A/A+trW/jiinXsaerk5kum8MXLSvXsWRGJWgr809AXcDz4cjU/eGE7YzJTePIz\nuktWRKKfAv8U9fYF+Owv3uTFLQe4eu54/u0Dc8hOS/K6LBGRQSnwT4Fzjjt+8w4vbjnAXVfP4oYL\nJmlOvYgMGwr8U/CdZ7fym7f2cuviUm5cVOJ1OSIip0SBH4Lapk5++NJ2nqrcy8fLi/jiZaVelyQi\ncsoU+O9i98HD3L+ymt+uqyPRjE9fWMJXr5qp0zgiMiwp8E9gZ2MHP1pZze/f3seIBOMT5xfzz++Z\nwrhs3UglIsOXAv8433t2Kw+8XE3yiAQ+tWgSn3nPZMZkKuhFZPhT4A9Q29TJAy9Xs2TOOO5eNoe8\njBSvSxIRCRut6jXAT/6yiwQz7nz/bIW9iMQcBX6/Nl8vT1XWsnTueJ2rF5GYpMDvt21/O509fVw9\nd7zXpYiIRIQCv1+7zw9AdrqWSRCR2KTA79fm6wUgK1XXsUUkNinwgXZfLw+s3EFW6gjGZad5XY6I\nSETE/XDW3xfgC0+uo7qxg59/agEZKXHfJSISo+J+hP9vf9zMy1sbuWfZHBZNzfO6HBGRiInrwF+1\nvZHHXtvNJxdN4uPlRV6XIyISUXEb+L7ePr7x9EZK8kbylSUzvC5HRCTi4vaE9QMrq9l9qJNf3lSu\n59CKSFyI2xH+z1fv4crZY7mwVOftRSQ+xGXgBwKO1q5epo/N9LoUEZEhE5eB39nbh3OQoZusRCSO\nxGXg72vpAiAnPdnjSkREhk5cBv6fN+4H4CKdvxeROBKXgf/HDfWcNymXAi2jICJxJO4Cf8+hw2xt\naOeqswq8LkVEZEjFXeBvrm8D4NziXI8rEREZWnEX+NsaOgCYOibD40pERIZW3AX+9gMdFOamkZ6s\nKZkiEl9CCnwzW2JmW82s2szueJd2HzQzZ2Zl4SsxvJoP95CfqQeUi0j8GTTwzSwRuB94LzALuNbM\nZp2gXSbwRWBNuIsMp/ZuP5mpeoyhiMSfUEb4C4Bq59xO51wPsAJYdoJ29wDfBnxhrC+snHM0He4m\nU3fYikgcCiXwJwC1A7b39r93lJnNByY65/74bh9kZsvNrNLMKhsbG0+52DO1dncztU1dLJw8esiP\nLSLitTO+aGtmCcC9wG2DtXXOPeKcK3POleXn55/poU/Zj1ftJDc9iQ/NLxzyY4uIeC2UwK8DJg7Y\nLux/74hMYA7wspntBhYCFdF24Xb3wcO8sLmB6xcWk5as9e9FJP6EEvhrgVIzKzGzZOBjQMWRnc65\nVudcnnNuknNuErAaWOqcq4xIxafp+aoGnIOPLtCjDEUkPg0a+M45P3AL8CywGXjKObfJzO42s6WR\nLjBcXtnWyLSxGUzI0fo5IhKfQpqu4px7BnjmuPfuPEnbS868rPDq7PHzxq4mbrig2OtSREQ8Exd3\n2u5sPExPX4D5RVo/R0TiV1wEfn1r8NaA8TqdIyJxLE4CP/iEq4KcVI8rERHxTlwE/vaGDjJSRpA3\nUmvoiEj8iovAf3NPM/OKckhIMK9LERHxTMwHfke3ny3725inC7YiEudiPvCfXldHwMGiKVo/R0Ti\nW0wHfre/j/tXVnNucS4LSkZ5XY6IiKdiOvB/tbaW+lYfX1o8DTOdvxeR+BazgR8IOH68aidlxbks\nmqrTOSIiMRv4f91xkNqmLq4/v1ijexERYjjwV7xRS056ElfOHud1KSIiUSEmA985x/NVDVx99nhS\nk7T2vYgIxGjgd/b00dMXoDBXa+eIiBwRk4Hf7vMDkKGHlYuIHBWTgd90uAeA7LQkjysREYkeMRn4\nG/a2ADCrIMvjSkREokdMBv6be5rJTU+iJG+k16WIiESNmAv8A20+Vm5t5NziXM2/FxEZIKYCv83X\nyw0/XUtnj59bF0/zuhwRkagSM4Hv6+1j+c8r2d7QzkPXncucCdlelyQiElViIvD3tXTxyZ+uZfXO\nJr734bm8Z1q+1yWJiESdYT1R3TnHb9+q464/bKIv4Pjuh87mA/MmeF2WiEhUGraBf7Cjm3/57Ts8\nV9XAeZNy+d6H51I8WrNyREROZlgGfkObj/fdt4o2n5+vXTWTT11YQqKeVysi8q6GZeD/eeN+Dnb0\n8LvPXaBn1YqIhGhYXrR9ZVsjxaPTFfYiIqdg2AV+R7ef13cc4mLNxBEROSXDLvD/3zOb8fn7uGZ+\nodeliIgMK8Mq8F/d1sgTa2r49IUlnDMxx+tyRESGlWET+B3dfr7ymw1MHZPBbVdM97ocEZFhZ9jM\n0lnxRg31rT5+c/P5emyhiMhpGBYj/N6+AI/+ZRcLJ4/i3OJRXpcjIjIsDYvAf/KNGva1+vjMRZO9\nLkVEZNgKKfDNbImZbTWzajO74wT7v2xmVWa2wcxeNLPicBRXfaCdGx59gzt/v4lzJuZw6fQx4fhY\nEZG4NOg5fDNLBO4HLgf2AmvNrMI5VzWg2TqgzDnXaWY3A98BPnq6RbV09vCDF7bzi9V7SE9O5Ovv\nm8knzp9EgpZPEBE5baFctF0AVDvndgKY2QpgGXA08J1zKwe0Xw1cd7oFPflGDd/60xbafb1cu6CI\nL18+jdEZKaf7cSIi0i+UwJ8A1A7Y3guUv0v7m4A/nWiHmS0HlgMUFRX93f6qfW189bfvsKBkFP+6\ndDYz9RByEZGwCeu0TDO7DigDLj7RfufcI8AjAGVlZe74/f+1aifpyYn8+PoystOTwlmaiEjcCyXw\n64CJA7YL+9/7G2a2GPgacLFzrvtUC6lv7aJi/T6uP79YYS8iEgGhzNJZC5SaWYmZJQMfAyoGNjCz\necDDwFLn3IHTKeSlLQfwBxz/VB6WCT4iInKcQQPfOecHbgGeBTYDTznnNpnZ3Wa2tL/Zd4EM4Ndm\n9raZVZzk407K3xc8wzNqZPKpfquIiIQgpHP4zrlngGeOe+/OAa8Xh7kuEREJs2Fxp62IiJw5Bb6I\nSJxQ4IuIxImoCfy+QPCirRZPEBGJjKgJ/MaObpISjew0zcEXEYmEqAn8+pYuxmalaoE0EZEIiZrA\nr23uYnx2mtdliIjErKgI/MPdfjbsbWFekR5MLiISKVER+K/vOERvn+PiaflelyIiErOiIvBXbW8k\nLSmRcyflel2KiEjMiorA39fqo3h0OikjEr0uRUQkZkVF4Hf4/GSlajqmiEgkRUXgt3f3kpEa1mex\niIjIcaIi8Dt8fjIV+CIiERUVgd/u85ORosAXEYmk6Al8jfBFRCLK88Bv8/XS0xdgVLqedCUiEkme\nB359iw+AghwtqyAiEkmeB/6+1i4AxmenelyJiEhs8zzwV245QFKiMSU/w+tSRERimqeB33y4h19X\n7mXZORPIHalz+CIikeRp4D++Zg9dvX18+qISL8sQEYkLngV+wDke/etu3jMtnxnjsrwqQ0Qkbng2\n+f1QRw92uIdbF5d6VYKISFzxbITf2NHNpdPzmV+kJZFFRIaCZ4HfF3B89uIpXh1eRCTueHrRtmh0\nupeHFxGJK54GvhZMExEZOp4G/shkBb6IyFDxNPATEszLw4uIxBXPl1YQEZGhocAXEYkTCnwRkTih\nwBcRiRMKfBGROBFS4JvZEjPbambVZnbHCfanmNmv+vevMbNJgx7YNENHRGQoDRr4ZpYI3A+8F5gF\nXGtms45rdhPQ7JybCnwf+PagB1bei4gMqVBG+AuAaufcTudcD7ACWHZcm2XAz/pf/zdwmdm7D+ET\nlfgiIkMqlFtdJwC1A7b3AuUna+Oc85tZKzAaODiwkZktB5b3b3ab2cbTKToG5XFcX8Ux9cUx6otj\n1BfHTD/dbxzStQ2cc48AjwCYWaVzrmwojx+t1BfHqC+OUV8co744xswqT/d7QzmlUwdMHLBd2P/e\nCduY2QggGzh0ukWJiEj4hRL4a4FSMysxs2TgY0DFcW0qgBv6X38IeMk558JXpoiInKlBT+n0n5O/\nBXgWSAQedc5tMrO7gUrnXAXwE+AXZlYNNBH8pTCYR86g7lijvjhGfXGM+uIY9cUxp90XpoG4iEh8\n0J22IiJxQoEvIhInIh74kViWYbgKoS++bGZVZrbBzF40s2Iv6hwKg/XFgHYfNDNnZjE7JS+UvjCz\nj/T/bGwysyeGusahEsL/kSIzW2lm6/r/n1zlRZ2RZmaPmtmBk92rZEH39ffTBjObH9IHO+ci9kXw\nIu8OYDKQDKwHZh3X5nPAQ/2vPwb8KpI1efUVYl9cCqT3v745nvuiv10m8CqwGijzum4Pfy5KgXVA\nbv/2GK/r9rAvHgFu7n89C9jtdd0R6ov3APOBjSfZfxXwJ8CAhcCaUD430iP8iCzLMEwN2hfOuZXO\nuc7+zdUE73mIRaH8XADcQ3BdJt9QFjfEQumLzwD3O+eaAZxzB4a4xqESSl84IKv/dTawbwjrGzLO\nuVcJzng8mWXAz13QaiDHzAoG+9xIB/6JlmWYcLI2zjk/cGRZhlgTSl8MdBPB3+CxaNC+6P8TdaJz\n7o9DWZgHQvm5mAZMM7O/mtlqM1syZNUNrVD64i7gOjPbCzwDfGFoSos6p5onwBAvrSChMbPrgDLg\nYq9r8YKZJQD3Ajd6XEq0GEHwtM4lBP/qe9XMznLOtXhalTeuBR5zzv2HmZ1P8P6fOc65gNeFDQeR\nHuFrWYZjQukLzGwx8DVgqXOue4hqG2qD9UUmMAd42cx2EzxHWRGjF25D+bnYC1Q453qdc7uAbQR/\nAcSaUPriJuApAOfc60AqwYXV4k1IeXK8SAe+lmU4ZtC+MLN5wMMEwz5Wz9PCIH3hnGt1zuU55yY5\n5yYRvJ6x1Dl32otGRbFQ/o88TXB0j5nlETzFs3MoixwiofRFDXAZgJnNJBj4jUNaZXSoAD7RP1tn\nIdDqnKsf7JsiekrHRW5ZhmEnxL74LpAB/Lr/unWNc26pZ0VHSIh9ERdC7ItngSvMrAroA253zsXc\nX8Eh9sVtwI/N7EsEL+DeGIsDRDN7kuAv+bz+6xXfBJIAnHMPEbx+cRVQDXQCnwzpc2Owr0RE5AR0\np62ISJxQ4IuIxAkFvohInFDgi4jECQW+iEicUOCLiMQJBb6ISJz4/wAEH3cMizsVAAAAAElFTkSu\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7368649133293483\n",
            "Time:  13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7a5cT2EiuKe",
        "colab_type": "text"
      },
      "source": [
        "### Results for NASA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laYC-4JXSTJS",
        "colab_type": "code",
        "outputId": "58991fa7-006c-4f0b-bee7-c181d13bcfeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "xgb = XGB_AnomalyDetection_ML.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,108,9,0.3)\n",
        "xgb.fit()\n",
        "auc = xgb.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[23:53:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[23:54:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[23:54:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[23:55:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[23:55:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[23:56:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[23:56:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[23:57:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[23:57:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3RVZd728e+PBAiE0KuEUEMXBCJg\nA2dARUVxrOCAogKKDzg6Pjj62mYcX1/LoI9tREYBUcGCCigIOBYQlBJaqIEAAUIoIYFQkpB2v38k\nM+RhwBwhyT7l+qzFWjnn7ORc6ya5snPvve9tzjlERCT4VfI6gIiIVAwVvohIiFDhi4iECBW+iEiI\nUOGLiIQIFb6ISIgotfDNbJKZHTCz9Wd43czsNTNLMrMEM+te9jFFRORc+bKHPwUY8AuvXw3EFv8b\nBbx17rFERKSslVr4zrlFQMYvbDIImOqKLAVqm1mTsgooIiJlI7wMvkZTYHeJxynFz+09dUMzG0XR\nXwFERkb2aN++fRm8vYiIt47k5LEvM4cT+YXUi6zCebWrldt7rVy58qBzrsHZfG5ZFL7PnHMTgYkA\ncXFxLj4+viLfXkSkTGVm5fHYFwnMXbeP9lFVGdsvliEXNiM8rPzOhzGznWf7uWVR+HuAZiUeRxc/\nJyIStLbuP8q9768kOf04f7yiLaP6tCKicpjXsX5RWRT+bGCMmX0E9AIynXP/MZ0jIhIs1qVkcufk\n5eQXFPL33/dgQOfGXkfySamFb2bTgcuB+maWAjwNVAZwzk0A5gLXAElAFnBXeYUVEfGSc45Za1J5\ncuZ6oiLCmTyyN+0aR3kdy2elFr5zbkgprzvgv8oskYiIHzp47ARjpq1i6fYMWtaP5MMRvcr14Gx5\nqNCDtiIigcY5xwfLdvH83E3kFhTy2NXtGXFZK8IqmdfRfjUVvojIGSxJOsgTM9ez4+BxusXU5oWb\nutC2UeBM4ZxKhS8icoqCQsfbi7bx4rxEwioZT1/XkaG9m1O5HE+3rAgqfBGRYnkFhSxMTGPCwm3E\n7zxE/RpV+XLsJTSpFVhz9WeiwhcRAX7cmsYzX25k64Fj1IwIZ9xV7bivb+uAnKs/ExW+iIS01MPZ\n/OPH7UxekkyzutV44/ZuXNmxMVXCA3v65nRU+CISkrJzC5iwcBsTFm7jRH4hv+vWlL8M6kTNiMpe\nRys3KnwRCSlfrk1l5uo9LE/O4GhOPgO7NOGRq9oTU6+619HKnQpfRELG+0t38uTMons53XDBeQy7\nqDk9mtf1OFXFUeGLSNA7fiKfF+dtZurSnfTv0JA3f9+dquH+vdBZeVDhi0hQ27zvCA99vJZNe48w\nrHdzHr+2Q0iWPajwRSRI5eYX8vbCbYz/ZgtVwivx4k1duPXCZqV/YhBT4YtI0Jm7bi8vzNvMzvQs\nru3ShGcHdaZOZBWvY3lOhS8iQeWdH7fz7JxNREWEM/6WrtzYvSlmwXPx1LlQ4YtI0Ji1Zg/Pzd3E\nVZ0a8ergbn5/B6qKpsIXkYC3Zf9R/t/cTXyfmEbrBpG8ctsFKvvTUOGLSMByzvHhsl08NWs9kVXD\n+dOA9gztHUP1Kqq209GoiEhA2n8kh8e/WMc/Nx3gwhZ1mDgsTgdmS6HCF5GA45zjkRkJLEk6yAP9\nYhnVpxU1qqrOSqMREpGA4pzj6dkbWLgljSeu7cCIy1p5HSlgqPBFJGAcOp7L819v5uP43dzYrSl3\nXdLS60gBRYUvIgFhZ/pxbp7wM2lHTzD84hY8NbAjlYLo5iQVQYUvIn7NOUfSgWPcOWk5mVl5vH9P\nTy6LbeB1rICkwhcRv5STV8D8Dft44evNpGbmEFkljOmjetOjeR2vowUsFb6I+JUjOXnMXpPKhIXb\nSDmUTbXKYdxxUXNG9WlFdJ3gv0lJeVLhi4hfcM7xz00HeHbORnamZ9GsbjVeH9KNKzo20lWzZUSF\nLyKeSzmUxd1TVrBl/zFa1Y9kwtAeXNWpkRY9K2MqfBHx1La0Ywx7ZxlHc/L56w2duTUuOmRvUFLe\nVPgi4pkNqZncOWk5zsFH9/am03m1vI4U1FT4IlLhUg5lMWlxMpOW7KBmRDif3ncx7RpHeR0r6Knw\nRaRCpRzK4rrXF3M4O4+bukfzyIB2NKoZ4XWskKDCF5EKc+BIDqM/WMWxE/l8NfZSTeFUMBW+iFSI\n5IPHue+Dlew4eJxXbrtAZe8BFb6IlKu8gkKWbc/g/g9XciQnn2dv6MzALud5HSskqfBFpNysSM5g\n1NR4DmXl0bR2NWaNuZSW9SO9jhWyKvmykZkNMLNEM0sys0dP83qMmX1vZqvNLMHMrin7qCISKJxz\nLNiwjxHvxVNQ6Hh18AUseKiPyt5jpe7hm1kY8CZwBZACrDCz2c65jSU2ewL4xDn3lpl1BOYCLcoh\nr4j4uYSUw7w4L5HFSQdp3ziKCUN70EJF7xd8mdLpCSQ557YDmNlHwCCgZOE7oGbxx7WA1LIMKSL+\nr6DQMXnJDl6cn0jNiMo8fEVbRvZppXVw/Igvhd8U2F3icQrQ65Rt/gwsMLOxQCTQ/3RfyMxGAaMA\nYmJifm1WEfFDW/Yf5X/+uYVvNu4nr8DRNboW7w6/kPo1qnodTU5RVgdthwBTnHPjzewi4H0z6+yc\nKyy5kXNuIjARIC4uzpXRe4uIRzbvO8J1ry8mrJJxfdemXBBTW2vh+DFfCn8P0KzE4+ji50q6BxgA\n4Jz72cwigPrAgbIIKSL+ZVvaMd77KZmPV+wmIjyMrx+8TGvVBwBfCn8FEGtmLSkq+sHA7adsswvo\nB0wxsw5ABJBWlkFFxFvOORZtPcjLCxJZm5JJ5TCjb9sGPNAvVmUfIEotfOdcvpmNAeYDYcAk59wG\nM3sGiHfOzQYeBv5hZg9RdAB3uHNOUzYiQeBoTh6fxKfw3k/J7MrIIioinEevbs/vujXVGjgBxrzq\n5bi4OBcfH+/Je4uIbyYt3sH4BYkczy0grnkdbomLZkDnJtSqVtnraCHLzFY65+LO5nN1pa2I/Ies\n3HxenJfIlJ+S6dCkJi/cdD5domt7HUvOkQpfRP4tr6CQ93/eyTs/bic1M4fbe8Xwl+s7UTnMp4vy\nxc+p8EUEKCr7//50LbPWpNI9pjavDunGhS3qeh1LypAKX0RIOnCUe96LZ2d6Fg/2j+XB/m29jiTl\nQIUvEsKcc7zz4w5e+ecWIquG8/awHlzZsZHXsaScqPBFQlR+QSEPfryGrxL2cn7TWrx5e3di6ul8\n+mCmwhcJQQWFjidnreerhL3cfUlLnri2A5UqmdexpJyp8EVCzMbUI4ydvoptaccZ2juGJwd2wExl\nHwpU+CIhIju3gElLdvDyN1uoVjmMRwa0Y3Tf1ir7EKLCFwkB89bv5fmvN5OcnkXHJjV5d3gcTWpV\n8zqWVDAVvkiQ+z7xAPd/uIoW9SKZcteF9G3bQHv1IUqFLxKkUg9n87f5iXyZkEqLepF88V+XaA2c\nEKfCFwlCCzbs49HP13EoK5d+7Rvy3O/OV9mLCl8kmOTmF/LyN1uYsHAbrRpEMn1kb9o1jvI6lvgJ\nFb5IEHlkxlpmrknlxu5NefaGzlSvoh9xOUnfDSJB4NiJfJ6etYGZa1K546LmPDOos9eRxA+p8EUC\n3K70LIZNWsbO9CxGX96aB/vHeh1J/JQKXySArd19mAc+Wk3KoWwmDO3OgM5NvI4kfkyFLxKgvt98\ngBFT44kIr8T/3HaByl5KpcIXCTAFhY4ft6bxwPTVNIqqyozRF3NebV01K6VT4YsEkMR9Rxn1ftGN\nSprVrca0Eb1V9uIzFb5IANibmc3r3yUxIz6FmtXCeWZQJ27uEa3TLuVX0XeLiJ+bk7CXhz5eg8Nx\nU/doHr6yHQ2iqnodSwKQCl/ET327aT8fLN3J94lp1Iuswsf3XkSbhjW8jiUBTIUv4mecc0xYuJ0X\n5m0mskoYIy5tyV2XtqSp5urlHKnwRfzI0Zw8Hvt8HV8l7OXi1vWYMKwHNSO06JmUDRW+iJ9YkZzB\n/R+uIu3oCR74bRseuqKt1q2XMqXCF/FYYaHj9e+SePOHJOpFVuHvv+/ONefrIiopeyp8EQ8VFDqe\nnLWeact20aN5HV4b0k1z9VJuVPgiHjl+Ip8/fZbAVwl7ueuSFjw1sKOmcKRcqfBFPLBl/1Ee+ngN\nG/ce4eEr2jK2n1a4lPKnwhepQCmHsnj2q03M27CPqIhwJgztwVWdGnsdS0KECl+kgsxJ2MtjnyeQ\nV+C4rut5jLuyHTH1qnsdS0KICl+knO04eJx3F2/ng6W76NqsNq8NvoDm9SK9jiUhyKfCN7MBwKtA\nGPCOc+7502xzK/BnwAFrnXO3l2FOkYCzLiWTdxdvZ+aaVAAGdmnCSzd3pVqVMI+TSagqtfDNLAx4\nE7gCSAFWmNls59zGEtvEAo8BlzjnDplZw/IKLBIIvlybyh8/WYNh3Nu3Fb/v2VzTN+I5X/bwewJJ\nzrntAGb2ETAI2Fhim5HAm865QwDOuQNlHVQkUKzdfZhxM9bSol4k00f1pn4NrWwp/qGSD9s0BXaX\neJxS/FxJbYG2ZrbEzJYWTwH9BzMbZWbxZhaflpZ2dolF/JRzjk/jd3PLhJ+JiqjMq4O7qezFr5TV\nQdtwIBa4HIgGFpnZ+c65wyU3cs5NBCYCxMXFuTJ6bxHP5eYXMmbaKhZs3E/X6Fq8O/xClb34HV8K\nfw/QrMTj6OLnSkoBljnn8oAdZraFol8AK8okpYifyszKY9KSHUxesoMjOfnccVFzHr+2A1XDdWBW\n/I8vhb8CiDWzlhQV/WDg1DNwZgJDgMlmVp+iKZ7tZRlUxN/szsji2td+5EhOPv07NGTwhTH079jI\n61giZ1Rq4Tvn8s1sDDCfotMyJznnNpjZM0C8c2528WtXmtlGoAAY55xLL8/gIl45nJXLrDWpvPbt\nVgAmDY/jt+1V9OL/zDlvptLj4uJcfHy8J+8tcrYWbknjzknLAejctCav3HoBsY2iPE4locTMVjrn\n4s7mc3WlrYiP1uw+zMip8bRuEMlfru/MpbH1vY4k8quo8EV88Gn8bh7/Yj01q1Vm6j29tGa9BCQV\nvsgvyMzK44lZ6/lybSot6lXnfZW9BDAVvshpZGbn8fcfkvjg553k5BfyQL9Yxv62DZXDfLlWUcQ/\nqfBFSjiRX8DcdXt5aV4iqZk5XNGxEWN+04auzWp7HU3knKnwRYrFJ2fw1682sjYlkzYNa/DZ6Ivp\n0byO17FEyowKX0JexvFcHv9iHV+v30f9GlV5bUg3Bp7fhEqVdH9ZCS4qfAlpCSmHGf3BKtKOneDe\nPq0Y2y+WGlX1YyHBSd/ZEpKcc7y/dCfPztlEgxpVmXHfRXSJ1jy9BDcVvoScwkLHWwu38dL8RC5p\nU4/Xh3SnbmQVr2OJlDsVvoSU3RlZPD17A99tPsBv2zfknTviNFcvIUOFLyFjwsJtPP/1ZsxgWO/m\nPH1dR5W9hBQVvgS97NwCXv4mkX/8uINeLevyt1u60qyu7i8roUeFL0Ft/5Ecxs1IYNGWNAZ2acJz\nN55PzYjKXscS8YQKX4LWiuQM7pmygiM5+Tx+TQdG9mnldSQRT6nwJSgt257OyKnxVKsSxif3XUT7\nxjW9jiTiORW+BJV9mTk8N3cTs9em0rR2NaaN7EXzepFexxLxCyp8CQrOOSYvSeZvCxLJL3Q80C+W\n0X1bU62KbiYu8i8qfAl4u9KzePTzBH7als7Frevx/I1diKmns3BETqXCl4CVV1DIzNV7ePyL9YRV\nMsZd1Y77L2+Nmc6tFzkdFb4EpJy8Au6avIKft6fTsUlN3hraXXP1IqVQ4UvAKSx0PPzJWn7ens4z\ngzoxpGeM7kQl4gMVvgSUg8dO8KcZCXy7+QDDL27BHRe18DqSSMBQ4UvAWLY9nbHTV3Pg6AmG9o7h\n6es6eh1JJKCo8CUgfLYyhYc/Xct5tSKYPeYSrV0vchZU+OLXCgsdLy1I5K0ftlGjajhT7u5J20ZR\nXscSCUgqfPFLu9KzeH7eJn7cepCjOflc2bERrw3pRkRlXUglcrZU+OJXdmdk8eycjczfsB+Am3tE\n85t2Dbnm/MY6v17kHKnwxS845/h81R4e+SyBSlZU9Pf1bUWbhpq+ESkrKnzxXG5+IXdPWcHipIO0\nbxzF5LsupEmtal7HEgk6KnzxVMbxXMZMW8VP29IZd1U77r6kpRY8EyknKnzxzOZ9RxjxXjyph7N5\n9Or23Ne3tdeRRIKaCl8qXFZuPh8t382r327l+Il8Prn3IuJa1PU6lkjQU+FLhdqVnsW9H6xk094j\nXNCsNk9c20FlL1JBVPhSYZYkHWTs9NVk5xbwxu3dGNjlPK8jiYQUn5YYNLMBZpZoZklm9ugvbHeT\nmTkziyu7iBLojubk8eTM9Qx7dxl1I6vw5dhLVfYiHih1D9/MwoA3gSuAFGCFmc12zm08Zbso4A/A\nsvIIKoEp7egJxkxbxbIdGdwW14ynrutIZFX9YSniBV9+8noCSc657QBm9hEwCNh4ynZ/BV4AxpVp\nQglIBYWOyUt28PI3W8jNL+SZQZ20lLGIx3wp/KbA7hKPU4BeJTcws+5AM+fcHDM7Y+Gb2ShgFEBM\nTMyvTyt+70R+AT9vS2fCwm0s3Z7BpW3q89cbOtOyvu5GJeK1c/7b2swqAS8Dw0vb1jk3EZgIEBcX\n5871vcV/OOf4P1+sY9aaVLJyC6hkcP/lrRl3VTutgSPiJ3wp/D1AsxKPo4uf+5cooDPwQ/EPdmNg\ntpld75yLL6ug4r8KCh3PztnI9OW7ubpzY27qHk2P5nWoE1nF62giUoIvhb8CiDWzlhQV/WDg9n+9\n6JzLBOr/67GZ/QD8t8o++OUVFDJ/wz6m/rST5ckZDL+4BU8N7EilStqjF/FHpRa+cy7fzMYA84Ew\nYJJzboOZPQPEO+dml3dI8S+FhY5Za/fwyIwE8gqKZuaeuLYDIy5r5XEyEfklPs3hO+fmAnNPee6p\nM2x7+bnHEn/149Y0XpyXyLo9mbRpWIMRl7bkuq7n6VRLkQCgn1LxyZrdh3ns83Vs2nuERjWrMv6W\nrtzQrSlhmr4RCRgqfPlFCSmHGb9gC4u2ptG4ZgRPDezIbRc20x69SADST638h7yCQuYk7GX+hn18\nvX4fdSOrcHvPGB7s35YGUVW9jiciZ0mFL//mnOPTlSm89u1WUg5l0yCqKqP6tOLePq2oV0NFLxLo\nVPgCwLz1exm/YAtbDxyjfeMoJg2P4zftGuqiKZEgosIPcdvSjvH+zzuZ8lMyrRpE8uJNXbipR7QO\nxooEIRV+iMrKzeepWRuYsTIFgBu7N+XP13eiZkRlj5OJSHlR4Yeg/IJCHpi+mm83H+C+vq25uUc0\nbRrW8DqWiJQzFX6ISTmUxUMfr2FF8iEe7B/Lg/3beh1JRCqICj9E7M7IYvyCRGavTSWichiv3NaV\nGy5o6nUsEalAKvwQ8O2m/TwwfTW5BYX8vldzRl7Wiph61b2OJSIVTIUfxJxzvPFdEuO/2UL7xlG8\nc2cc0XVU9CKhSoUfxP7+wzbGf7OFi1vXY/ytXWlSq5rXkUTEQyr8IPX6t1sZ/80W+rVvyD/uiNMa\n9SKiwg82ew5nM3nxDt77OZm+bRvwxu3dVfYiAqjwg8qu9CxGTo0ncf9RLm1Tn+duPJ9qVcK8jiUi\nfkKFHwRy8wt54/sk3vohCYDJd13Ib9o19DiViPgbFX6AO3jsBPd/uIrlOzLo36Ehj17dQVfNishp\nqfAD2I9b07jv/ZXkFTjG39KVm3pEex1JRPyYCj8A5RcUcv+Hq1iwcT+1q1fms/t7075xTa9jiYif\nU+EHGOccf/5yAws27mfQBefx+DUdaFgzwutYIhIAVPgBZNGWNN74PonlOzK4t08rHrumg9eRRCSA\nqPADwOGsXP7y5Ua+WL2H6DrV+O8r23L/5W28jiUiAUaF78fSjp5gTkIqHy7bxba0Y4zq04o/9Isl\nsqr+20Tk11Nz+KlZa/bw1682cfDYCZrUimDyXT3p27aB17FEJICp8P3MwWMneParjcxck0pswxq8\neXs3erasq5uJi8g5U+H7idTD2fz9hyQ+Wr4bB9x/eWse6BdLRGUtjSAiZUOF7wdWJGdwy4SfgaKb\niY+4tBUdz9N59SJStlT4HjpwJIe/LUjks1V7qBkRzos3d2VA58ZexxKRIKXC98j3iQd48KM1ZOcW\nMKx3cx7sH0vt6lW8jiUiQUyF74H1ezIZ+V48jWpG8PG9WhZBRCqGCr8COedYtesQD0xfQ81qlZk1\n5hLq16jqdSwRCREq/AqSnVvAS/MTmbRkB3WqV+b9e3qp7EWkQqnwy5lzjh+3HuSxz9ex53A2l8XW\nZ8LQHrpaVkQqnE+tY2YDgFeBMOAd59zzp7z+R2AEkA+kAXc753aWcdaAs35PJi9/s4XvNh+gWd1q\nvD2sB79p15Aq4ZW8jiYiIajUwjezMOBN4AogBVhhZrOdcxtLbLYaiHPOZZnZaOBF4LbyCOzvnHPM\nXbePyUt2EL/zENWrhPGHfrGM6tNKe/Ui4ilfGqgnkOSc2w5gZh8Bg4B/F75z7vsS2y8FhpZlyEBR\nUOh4evZ6Pli6i5i61XlyYEdu7hFNrWqVvY4mIuJT4TcFdpd4nAL0+oXt7wG+Pt0LZjYKGAUQExPj\nY8TAkJmdx4j3VrAi+RA3dY/mxZu7EFZJ69+IiP8o0zkGMxsKxAF9T/e6c24iMBEgLi7OleV7e2nz\nviOM+zSBdXsy+fN1HRl2UQuVvYj4HV8Kfw/QrMTj6OLn/hcz6w88DvR1zp0om3j+7UhOHpMW7+DV\nb7cSVTWct4f14KpOWhpBRPyTL4W/Aog1s5YUFf1g4PaSG5hZN+BtYIBz7kCZp/RDP207yCMzEkg5\nlE3PFnUZf2tXmtWt7nUsEZEzKrXwnXP5ZjYGmE/RaZmTnHMbzOwZIN45Nxt4CagBfFq8bvsu59z1\n5ZjbM845nvlqI5OXJNOkVgTTRvbi4tb1vY4lIlIqn+bwnXNzgbmnPPdUiY/7l3Euv5R88DhPzFzP\n4qSD3Nwjmmdv6Kz16kUkYOjEcB9kZufx+aoUXpi3mRP5hTzYP5Y/9IvVXahEJKCo8EuRmZ3H9W8s\nZmd6Fr1a1uUvgzppdUsRCUgq/F/gnOP+D1eyOyNLZ+CISMDToi5ncOBIDrf/YxlLktL504D2KnsR\nCXjawz+N3RlZ3Dl5OSkZ2Tw5sCN3X9LC60giIudMhV+Cc45PV6bwzJcbMWDqPT3p3aqe17FERMqE\nCr+E2WtTeWRGAj1b1mX8LbqQSkSCiwq/2Heb9/PEzPW0bxzFtBG9CA/T4Q0RCS4qfOCZLzcyackO\n2jaqwVtDe6jsRSQohXzhf7k2lUlLdtA1uhYfjuxNDd2kRESCVEjvyv6QeICHP1lL/RpVVPYiEvRC\ntvCXJB3knvfiaVI7gs9HX6KyF5GgF5Ittys9i9EfrKRxzQg+G30x9WtU9TqSiEi5C7k9/LSjJ7h5\nwk8UOpgwtIfKXkRCRkjt4S/cksZzczZxODuPz0dfTOemtbyOJCJSYUJmD3/22lTunLScYyfyeWNI\nN5W9iISckNjDf+fH7Tw7ZxMxdauz4KE+ummJiISkoC787NwCXpi3mSk/JdO7VV1eurmryl5EQlZQ\nFn5Wbj5LktJ5/butJKRkcu35TfifwRdQWVfQikgIC6rCz8krYPHWg4ybsZZDWXnUqBrO//1dZ37f\nq7nX0UREPBc0hb9y5yEe/Hg1uzOyaRBVlQlDu/Pb9o2oEq69ehERCJLC33M4m7unrMAM3ry9O5e3\na0CkrpwVEflfAroV/3XDkqdnbaDAOaberRuWiIicScAWfn5BIW8v2s5L8xPp2qw2rw/uRkw93bBE\nRORMArLwc/IKGD55OUu3Z3BZbH2m3NWTsErmdSwREb8WUIXvnOO9n5J5/bsk0o/n8pfrOzGsd3Mq\nqexFREoVMIW/ed8RXvlmC/M37KdbTG1evu0C+rZt4HUsEZGA4feFfyQnj3cWbee175IAePyaDoy4\nrCVm2qsXEfk1/LrwF289yH9NW0Vmdh592zbg2Rs606yuDsyKiJwNvy38L1anMO7TBFo3qMEH9/Ti\n/Gitbikici78rvAPZ+UycdF23l60nR4xdXhneBw1Iyp7HUtEJOD5VeFv2X+UsdNWk7j/KAO7NOG5\nG89X2YuIlBG/Kfw5CXsZO30VVcIr8fR1HbnrkpZeRxIRCSp+UfgLNuxjzPRVtG0YxbSRvain+8yK\niJQ5zwv/g6U7eXLWerpE12bq3T2pVU1TOCIi5cGntYPNbICZJZpZkpk9eprXq5rZx8WvLzOzFr58\n3RfmbeaJmeu5vG0Dpt6lshcRKU+lFr6ZhQFvAlcDHYEhZtbxlM3uAQ4559oArwAvlPZ1k9OP89YP\n2xjSM4aJd8RRq7rKXkSkPPmyh98TSHLObXfO5QIfAYNO2WYQ8F7xxzOAflbKpbBHc/IZd1U7nvtd\nZ916UESkAvgyh98U2F3icQrQ60zbOOfyzSwTqAccLLmRmY0CRhU/PDHmt7Hrx5xN6uBTn1PGKoRp\nLE7SWJyksTip3dl+YoUetHXOTQQmAphZvHMuriLf319pLE7SWJyksThJY3GSmcWf7ef6MpeyB2hW\n4nF08XOn3cbMwoFaQPrZhhIRkbLnS+GvAGLNrKWZVQEGA7NP2WY2cGfxxzcD3znnXNnFFBGRc1Xq\nlE7xnPwYYD4QBkxyzm0ws2eAeOfcbOBd4H0zSwIyKPqlUJqJ55A72GgsTtJYnKSxOEljcdJZj4Vp\nR1xEJDTofEgRkRChwhcRCRHlXvjltSxDIPJhLP5oZhvNLMHMvjWz5l7krAiljUWJ7W4yM2dmQXtK\nni9jYWa3Fn9vbDCzaRWdsaL48DMSY2bfm9nq4p+Ta7zIWd7MbJKZHTCz9Wd43czsteJxSjCz7j59\nYedcuf2j6CDvNqAVUAVYC3Q8ZZv7gQnFHw8GPi7PTF7983EsfgNUL/54dCiPRfF2UcAiYCkQ53Vu\nD78vYoHVQJ3ixw29zu3hWEwERhd/3BFI9jp3OY1FH6A7sP4Mr18DfA0Y0BtY5svXLe89/HJZliFA\nlToWzrnvnXNZxQ+XUnTNQ2p3GJIAAAIlSURBVDDy5fsC4K8UrcuUU5HhKpgvYzESeNM5dwjAOXeg\ngjNWFF/GwgE1iz+uBaRWYL4K45xbRNEZj2cyCJjqiiwFaptZk9K+bnkX/umWZWh6pm2cc/nAv5Zl\nCDa+jEVJ91D0GzwYlToWxX+iNnPOzanIYB7w5fuiLdDWzJaY2VIzG1Bh6SqWL2PxZ2ComaUAc4Gx\nFRPN7/zaPgH8YD18+U9mNhSIA/p6ncULZlYJeBkY7nEUfxFO0bTO5RT91bfIzM53zh32NJU3hgBT\nnHPjzewiiq7/6eycK/Q6WCAo7z18Lctwki9jgZn1Bx4HrnfOnaigbBWttLGIAjoDP5hZMkVzlLOD\n9MCtL98XKcBs51yec24HsIWiXwDBxpexuAf4BMA59zMQQdHCaqHGpz45VXkXvpZlOKnUsTCzbsDb\nFJV9sM7TQilj4ZzLdM7Vd861cM61oOh4xvXOubNeNMqP+fIzMpOivXvMrD5FUzzbKzJkBfFlLHYB\n/QDMrANFhZ9WoSn9w2zgjuKzdXoDmc65vaV9UrlO6bjyW5Yh4Pg4Fi8BNYBPi49b73LOXe9Z6HLi\n41iEBB/HYj5wpZltBAqAcc65oPsr2MexeBj4h5k9RNEB3OHBuINoZtMp+iVfv/h4xdNAZQDn3ASK\njl9cAyQBWcBdPn3dIBwrERE5DV1pKyISIlT4IiIhQoUvIhIiVPgiIiFChS8iEiJU+CIiIUKFLyIS\nIv4/MFwUX5y1wPUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.4738531429159074\n",
            "Time:  261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54zwQUSVSo66",
        "colab_type": "text"
      },
      "source": [
        "# LOF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCvWneTnSr46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class LOF_AnomalyDetection_MV:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_neighbors, train_rate) -> 'LOF_AnomalyDetection_MV':\n",
        "    \treturn cls(dataframe, dimension, window_width, n_neighbors, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension, n_neighbors, train_rate) -> 'LOF_AnomalyDetection_MV':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, dimension, window_width, n_neighbors, train_rate)\n",
        "     \n",
        "    def __init__(self,dataframe, dimension, window_width, n_neighbors, train_rate):\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.df = dataframe\n",
        "        self.window_width = window_width\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "\t\t\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return np.array(dataX), np.array(dataY)\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def __build_sets(self):\n",
        "\t\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        # self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        self.errors = np.zeros_like(self.test[:,0])\n",
        "        # compute anomalies\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "        for i,_ in enumerate(self.test[:-self.window_width+1]):\n",
        "            sys.stdout.write('\\r'+str(i)+':'+str(len(self.test) - self.window_width))\n",
        "\n",
        "            window = self.test[i:i+self.window_width]\n",
        "            clf=LocalOutlierFactor(self.n_neighbors,contamination ='auto')\n",
        "            clf.fit_predict(window)\n",
        "            error = clf.negative_outlier_factor_\n",
        "            # error=error - 1 \n",
        "            # error= error**(-1)\n",
        "            self.errors[i:i+self.window_width] += 1/error\n",
        "\n",
        "\n",
        "        # normalize anomaly score\n",
        "        self.errors[:-self.window_width+1] /= self.window_width\n",
        "        for i,error in enumerate(self.test[-self.window_width+1:]):\n",
        "            self.errors[-self.window_width + 1 + i] /=self.window_width-(i+1)\n",
        "\n",
        "        # self.errors_original = self.errors\n",
        "        scalar = preprocessing.MinMaxScaler((0,1)).fit(self.errors.reshape(-1,1))\n",
        "        self.errors = scalar.transform(self.errors.reshape(-1,1))*10\n",
        "\n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        # true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "\n",
        "# iforest = OneClassSVM_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',None,30,3,0.7,0.3)\n",
        "# iforest.fit()\n",
        "# auc = iforest.get_roc_auc(verbose=False,plot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w_UphTJWvJY",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRxA7SUpWwAu",
        "colab_type": "code",
        "outputId": "4f501e88-bd35-4f02-f7fe-a100379bc3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# dataframe,window_width, dimension, nu, train_rate\n",
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "\n",
        "best_value, best_window, best_neighbor = 0,0,0\n",
        "for i in range(1,30):\n",
        "    window= np.random.randint(30,400)\n",
        "    neighbors = np.random.randint(3,window/2)\n",
        "    lof = LOF_AnomalyDetection_MV.from_DataFrame(df_synthetic,window,5,neighbors,0.3)\n",
        "    lof.fit()\n",
        "    auc = lof.get_roc_auc(verbose=False,plot=False)\n",
        "    if auc > best_value:\n",
        "        best_value = auc\n",
        "        best_window = window\n",
        "        best_neighbor = neighbors\n",
        "\n",
        "    endTime = datetime.datetime.now()\n",
        "    diff = endTime - startTime\n",
        "    print('window:', window, ' - neighbors:', neighbors,' - Time: ',diff.seconds)\n",
        "\n",
        "print('best: window: ', best_window,' - neighbor: ', best_neighbor, ' - auc:', best_value )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1777:1777AUC:  0.685734693877551\n",
            "window: 323  - neighbors: 132  - Time:  18\n",
            "1879:1879AUC:  0.6774727891156461\n",
            "window: 221  - neighbors: 62  - Time:  25\n",
            "1794:1794AUC:  0.6726734693877551\n",
            "window: 306  - neighbors: 60  - Time:  37\n",
            "2049:2049AUC:  0.4873877551020408\n",
            "window: 51  - neighbors: 14  - Time:  39\n",
            "1726:1726AUC:  0.6575510204081633\n",
            "window: 374  - neighbors: 51  - Time:  52\n",
            "2012:2012AUC:  0.5733197278911565\n",
            "window: 88  - neighbors: 30  - Time:  55\n",
            "1883:1883AUC:  0.6875680272108844\n",
            "window: 217  - neighbors: 82  - Time:  63\n",
            "1800:1800AUC:  0.6683571428571429\n",
            "window: 300  - neighbors: 53  - Time:  74\n",
            "1707:1707AUC:  0.6587823129251701\n",
            "window: 393  - neighbors: 57  - Time:  89\n",
            "1827:1827AUC:  0.6796054421768707\n",
            "window: 273  - neighbors: 66  - Time:  99\n",
            "1940:1940AUC:  0.6598809523809525\n",
            "window: 160  - neighbors: 53  - Time:  104\n",
            "1936:1936AUC:  0.5966938775510204\n",
            "window: 164  - neighbors: 23  - Time:  109\n",
            "1742:1742AUC:  0.6795238095238096\n",
            "window: 358  - neighbors: 169  - Time:  132\n",
            "1797:1797AUC:  0.6897244897959184\n",
            "window: 303  - neighbors: 134  - Time:  149\n",
            "1982:1982AUC:  0.5302074829931972\n",
            "window: 118  - neighbors: 16  - Time:  152\n",
            "1829:1829AUC:  0.5461428571428572\n",
            "window: 271  - neighbors: 11  - Time:  158\n",
            "1725:1725AUC:  0.6597312925170068\n",
            "window: 375  - neighbors: 55  - Time:  172\n",
            "1731:1731AUC:  0.6746224489795917\n",
            "window: 369  - neighbors: 94  - Time:  190\n",
            "1704:1704AUC:  0.6721394557823129\n",
            "window: 396  - neighbors: 190  - Time:  218\n",
            "1807:1807AUC:  0.650200680272109\n",
            "window: 293  - neighbors: 37  - Time:  227\n",
            "1865:1865AUC:  0.6888333333333333\n",
            "window: 235  - neighbors: 83  - Time:  236\n",
            "2021:2021AUC:  0.415452380952381\n",
            "window: 79  - neighbors: 6  - Time:  238\n",
            "2069:2069AUC:  0.43225510204081635\n",
            "window: 31  - neighbors: 8  - Time:  240\n",
            "2017:2017AUC:  0.4136360544217687\n",
            "window: 83  - neighbors: 6  - Time:  243\n",
            "1761:1761AUC:  0.6835238095238095\n",
            "window: 339  - neighbors: 148  - Time:  263\n",
            "1853:1853AUC:  0.6642857142857144\n",
            "window: 247  - neighbors: 46  - Time:  272\n",
            "1909:1909AUC:  0.6834183673469387\n",
            "window: 191  - neighbors: 76  - Time:  279\n",
            "1801:1801AUC:  0.6870408163265307\n",
            "window: 299  - neighbors: 97  - Time:  293\n",
            "1767:1767AUC:  0.5920544217687075\n",
            "window: 333  - neighbors: 17  - Time:  300\n",
            "best: window:  303  - neighbor:  134  - auc: 0.6897244897959184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8y-9GJVixou",
        "colab_type": "text"
      },
      "source": [
        "### Results for NASA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeGzQKsvPL_v",
        "colab_type": "code",
        "outputId": "283fc428-c4cb-4b5a-a986-52ad6015b8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "lof = LOF_AnomalyDetection_MV.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,83,9,6,0.3)\n",
        "# LOF_AnomalyDetection_MV.from_DataFrame(df_synthetic,83,5,6,0.3)\n",
        "lof.fit()\n",
        "auc = lof.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34285:34285AUC:  0.8158120558009263\n",
            "Time:  53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4OX8Yhyjl-y",
        "colab_type": "text"
      },
      "source": [
        "# DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbYjfkrRjove",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class DBSCAN_AnomalyDetection_MV:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, eps, min_samples, train_rate,metric) -> 'DBSCAN_AnomalyDetection_MV':\n",
        "    \treturn cls(dataframe, dimension, window_width, eps, min_samples, train_rate,metric)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension, eps, min_samples, train_rate,metric) -> 'DBSCAN_AnomalyDetection_MV':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, dimension, window_width, eps, min_samples, train_rate,metric)\n",
        "\n",
        "    def __init__(self,dataframe, dimension, window_width, eps, min_samples, train_rate,metric):    \n",
        "        self.df = dataframe\n",
        "        self.eps = eps\n",
        "        self.metric = metric\n",
        "        self.min_samples = min_samples\n",
        "        self.window_width = window_width\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "\t\t\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return np.array(dataX), np.array(dataY)\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def __build_sets(self):\n",
        "\t\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        # self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        self.errors = np.zeros_like(self.test[:,0])\n",
        "        # compute anomalies\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "        for i,_ in enumerate(self.test[:-self.window_width+1]):\n",
        "            sys.stdout.write('\\r'+str(i)+':'+str(len(self.test) - self.window_width))\n",
        "\n",
        "            window = self.test[i:i+self.window_width]\n",
        "            clf=DBSCAN(self.eps, self.min_samples,metric = self.metric)\n",
        "            error = clf.fit_predict(window)\n",
        "            error[error>0] = 0\n",
        "            error*=-1\n",
        "            # error=error - 1 \n",
        "            # error= error**(-1)\n",
        "            self.errors[i:i+self.window_width] += error\n",
        "\n",
        "\n",
        "        # normalize anomaly score\n",
        "        self.errors[:-self.window_width+1] /= self.window_width\n",
        "        for i,error in enumerate(self.test[-self.window_width+1:]):\n",
        "            self.errors[-self.window_width + 1 + i] /=self.window_width-(i+1)\n",
        "\n",
        "        # self.errors_original = self.errors\n",
        "        # scalar = preprocessing.MinMaxScaler((0,1)).fit(self.errors.reshape(-1,1))\n",
        "        # self.errors = scalar.transform(self.errors.reshape(-1,1))*10\n",
        "\n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        # true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "\n",
        "# iforest = OneClassSVM_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',None,30,3,0.7,0.3)\n",
        "# iforest.fit()\n",
        "# auc = iforest.get_roc_auc(verbose=False,plot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxA5vBRBAVQM",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKpSBtvDAWDq",
        "colab_type": "code",
        "outputId": "b25aa750-4f2e-4528-f59b-f0d47bbef49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "dbscan = DBSCAN_AnomalyDetection_MV.from_DataFrame(df_synthetic,100,5,0.3,30, 0.3,'euclidean')\n",
        "dbscan.fit()\n",
        "auc = dbscan.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000:2000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDNGSCPkAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.506904761904762\n",
            "Time:  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC6DfjFni6m9",
        "colab_type": "text"
      },
      "source": [
        "### Results for NASA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLIj-R2NRr2I",
        "colab_type": "code",
        "outputId": "78ad37fc-35fb-43c5-d86a-81eaed087a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "dbscan = DBSCAN_AnomalyDetection_MV.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,30,9,0.3,6, 0.8,'euclidean')\n",
        "dbscan.fit()\n",
        "auc = dbscan.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9790:9790"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.46416395834236107\n",
            "Time:  17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze-UWN0-FvnK",
        "colab_type": "text"
      },
      "source": [
        "# iForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z0rOm5GFx3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn.ensemble import IsolationForest \n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class iForest_AnomalyDetection_MV:\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_estimators, contamination, train_rate) -> 'iForest_AnomalyDetection_MV':\n",
        "    \treturn cls(dataframe, dimension, window_width, n_estimators, contamination, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension, n_estimators, contamination, train_rate) -> 'iForest_AnomalyDetection_MV':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, dimension, window_width, n_estimators, contamination, train_rate)\n",
        "\n",
        "    def __init__(self,dataframe, dimension, window_width, n_estimators, contamination, train_rate):    \n",
        "        self.df = dataframe\n",
        "        self.n_estimators = n_estimators\n",
        "        self.contamination = contamination\n",
        "        self.window_width = window_width\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "\t\t\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return np.array(dataX), np.array(dataY)\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def __build_sets(self):\n",
        "\t\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        # self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        self.errors = np.zeros_like(self.test[:,0])\n",
        "        # compute anomalies\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "        for i,_ in enumerate(self.test[:-self.window_width+1]):\n",
        "            sys.stdout.write('\\r'+str(i)+':'+str(len(self.test) - self.window_width))\n",
        "\n",
        "            window = self.test[i:i+self.window_width]\n",
        "\n",
        "\n",
        "            clf=IsolationForest(n_estimators=self.n_estimators,   # number of isolation trees\n",
        "                            max_samples='auto', # number of samples to draw to create an isolation tree\n",
        "                            contamination=self.contamination, # porportion of outliers\n",
        "                            max_features=1.0,   #\n",
        "                            bootstrap=False, \n",
        "                            n_jobs=-1, \n",
        "                            random_state=42, \n",
        "                            verbose=0, behaviour='new')\n",
        "            clf.fit(window)\n",
        "            error = clf.decision_function(window) \n",
        "            error[error>0] = 0\n",
        "            self.errors[i:i+self.window_width] += error*-1\n",
        "\n",
        "            # error=error - 1 \n",
        "            # error= error**(-1)\n",
        "            # self.errors[i:i+self.window_width] += error\n",
        "\n",
        "\n",
        "        # normalize anomaly score\n",
        "        self.errors[:-self.window_width+1] /= self.window_width\n",
        "        for i,error in enumerate(self.test[-self.window_width+1:]):\n",
        "            self.errors[-self.window_width + 1 + i] /=self.window_width-(i+1)\n",
        "\n",
        "        # self.errors_original = self.errors\n",
        "        # scalar = preprocessing.MinMaxScaler((0,1)).fit(self.errors.reshape(-1,1))\n",
        "        # self.errors = scalar.transform(self.errors.reshape(-1,1))*10\n",
        "\n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        # true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "\n",
        "# iforest = OneClassSVM_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',None,30,3,0.7,0.3)\n",
        "# iforest.fit()\n",
        "# auc = iforest.get_roc_auc(verbose=False,plot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VSlN98QGuMP",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E245sSKhGu7R",
        "colab_type": "code",
        "outputId": "99088b60-eaca-407f-c89b-5e538d34431a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "dbscan = iForest_AnomalyDetection_MV.from_DataFrame(df_synthetic,100,5,20, 'auto', 0.3)\n",
        "dbscan.fit()\n",
        "auc = dbscan.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000:2000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.6354353741496599\n",
            "Time:  231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQB4qzOQdppN",
        "colab_type": "text"
      },
      "source": [
        "### Results for NASA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7U7puqJSz9j",
        "colab_type": "code",
        "outputId": "e83ef115-1c99-4e6a-da41-072bad16f38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "dbscan = iForest_AnomalyDetection_MV.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,100,9,20, 'auto', 0.3)\n",
        "dbscan.fit()\n",
        "auc = dbscan.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34268:34268"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8814064167399759\n",
            "Time:  4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgeWoigQfuhI",
        "colab_type": "text"
      },
      "source": [
        "#VAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqqwjWs8fveI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "seed(42)\n",
        "from statsmodels.tsa.api import VAR, DynamicVAR\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class VAR_AnomalyDetection:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, train_rate, distance_function) -> 'Projection_AnomalyDetection':\n",
        "    \treturn cls(dataframe, window_width, dimension, train_rate, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, window_width, dimension, train_rate, distance_function) -> 'Projection_AnomalyDetection':\n",
        "    \tdf = read_csv(path, header=0, index_col=None, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df,window_width, dimension, train_rate, distance_function)\n",
        "         \n",
        "    # def __init__(self,path, window_width, dimension, train_rate):\n",
        "\n",
        "    #     self.dimension = dimension\n",
        "    #     self.n_epochs = n_epochs\n",
        "    #     self.window_width = window_width\n",
        "        \n",
        "    #     self.n_filters = n_filters\n",
        "    #     self.kernel_size = kernel_size\n",
        "    #     self.n_dense = n_dense\n",
        "\n",
        "    #     self.df = read_csv(path, header=0, index_col=None, parse_dates=True,squeeze=True)\n",
        "    #     self.df = self.df.reset_index(drop=True)\n",
        "    #     self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "    #     self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "    #     self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "        \n",
        "    #     self.X_origin = self.df.iloc[:,:dimension].values\n",
        "    #     self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "    #     df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "    #     self.values = df_sensors\n",
        "    #     self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "    #     self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,10)]),np.array(['V'+str(i)+'_t+1' for i in range(1,10)]),['is_anomaly']]\n",
        "\n",
        "    #     # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "    #     # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "    #     self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "    def __init__(self,dataframe, window_width, dimension, train_rate, distance_function):\n",
        "\n",
        "        self.df = dataframe\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "        self.distance_function = distance_function\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "        self.train_size = int(len(self.values) * train_rate)   \n",
        " \n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        self.X = self.dataframe.iloc[:,:-1].values\n",
        "        self.Y = self.dataframe.iloc[:,-1].values\n",
        "        self.train, self.test = self.X[1:self.train_size], self.X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.train[:,:self.dimension], self.train[:,self.dimension: -1]\n",
        "        self.test_X, self.test_y = self.test[:,:self.dimension], self.test[:,self.dimension: -1]\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        # self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        # self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        # self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        # self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.standardize_dataframe()\n",
        "        self.create_persistence()\n",
        "        self.build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "\n",
        "        self.compute_Errors_RMSE()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self, verbose=False):\n",
        "        self.model = VAR(self.train_X)\n",
        "        self.model_fit = self.model.fit(self.window_width)\n",
        "        self.window = self.model_fit.k_ar\n",
        "        self.coef = self.model_fit.params  \n",
        "        # if verbose:      \n",
        "        #     print('Lag: %s' % self.model_fit.k_ar)\n",
        "        #     print('Coefficients: %s' % self.model_fit.params)\n",
        "        self.history = self.train_X[len(self.train_X)-self.window:]\n",
        "        self.history = [self.history[i] for i in range(len(self.history))]\n",
        "        self.predictions = list()\n",
        "        for t in range(len(self.test_X)):\n",
        "            length = len(self.history)\n",
        "            lag = [self.history[i] for i in range(length-self.window,length)]\n",
        "            self.yhat = self.model_fit.forecast(lag,1)\n",
        "            # yhat = self.coef[0]\n",
        "            # for d in range(self.window):\n",
        "            #     yhat += self.coef[d+1] * lag[self.window-d-1]\n",
        "            obs = self.test_X[t]\n",
        "            self.predictions.append(self.yhat[0])\n",
        "            self.history.append(obs)        \n",
        "        # for i in range(len(predictions)):\n",
        "        #     print('predicted=%f, expected=%f' % (predictions[i], test[i]))\n",
        "        # rmse = sqrt(mean_squared_error(self.test, self.predictions))\n",
        "        self.error_vect = np.absolute(self.test_X - np.array(self.predictions))\n",
        "        # Calculate Mahalonbis distance \n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "\n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "                \n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def getchange(self, V_0,V_1):\n",
        "        Matrix = V_1.T@V_0@V_0.T@V_1\n",
        "        eigenvalues = np.linalg.eig(Matrix)[0]\n",
        "        lambda_min = np.min(eigenvalues)\n",
        "        return np.sqrt(max((1-lambda_min),0))\n",
        "        \n",
        "    def get_projected_Dataframe(self):\n",
        "        changes_anomaly = np.empty((len(self.X_origin)-self.window_width-1,2))\n",
        "        for i in range(len(self.X_origin)-self.window_width-1):\n",
        "            W_0 = self.X_origin[i:i+self.window_width]\n",
        "            W_1 = self.X_origin[i+1:i+self.window_width+1]\n",
        "            changes_anomaly[i] = [self.getchange(W_0,W_1),self.Y_origin[i]]         \n",
        "        return pd.DataFrame(changes_anomaly)\n",
        "\n",
        "\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16,32], [16,32,48,64],  [32,64,12,24],[128,128,128,128],[64,64,64,64],[256,256,256,256],[128,256,512,1024]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "# best_auc = [0,0]\n",
        "# histories = []\n",
        "# for f in filters:\n",
        "#     for k in kernelsizes:\n",
        "#         for d in dense:\n",
        "\n",
        "#             cnn = WaveNet_AnomalyDetection('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',30,9,20,0.3,f,k,d)\n",
        "#             hist = cnn.fit()\n",
        "#             histories.append(((f,k,d), hist))\n",
        "#             # cnn.plot()\n",
        "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#             if best_auc[1] < auc:\n",
        "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#                 best_auc = [(f,k,d),auc]\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16,32], [16,32,48,64],  [32,64,12,24],[128,128,128,128],[64,64,64,64],[256,256,256,256],[128,256,512,1024]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "\n",
        "# for epochs in [50,60,70,80,100,150,200]:\n",
        "#     # cnn = LSTM_AnomalyDetection('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',30,9,20,0.3,[4,4],k,d)\n",
        "#     cnn = LSTM_AnomalyDetection(dataframe=df,window_width=13,dimension=5,n_epochs=epochs,train_rate=0.3,n_filters=[7,7])\n",
        "#     # cnn.reset_dataframe(df,5,13, 0.3)\n",
        "#     cnn.fit()\n",
        "#     # # cnn.plot()\n",
        "#     auc = cnn.get_roc_auc(verbose=False,plot=True)\n",
        "#     print(best_auc)\n",
        "#     # 0.59 40 EPochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr8OSQcTfx-p",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvxBGCved8sA",
        "colab_type": "text"
      },
      "source": [
        "### Results for NASA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Oar1Nmqfy0E",
        "colab_type": "code",
        "outputId": "44dcc64a-ab48-40bf-b481-061c6bc3d0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "var = VAR_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',5,9,0.3,'mahalanobis')\n",
        "var.standardize_dataframe()\n",
        "var.create_persistence()\n",
        "var.build_sets()\n",
        "var.compute_anomalyScores()\n",
        "auc =var.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print(diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.46322603568670045\n",
            "0:00:03.000232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRrZYevlgiak",
        "colab_type": "text"
      },
      "source": [
        "# Average OCSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78fyjxwzg1jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class OneClassSVM_Average_AnomalyDetection:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, nu, train_rate) -> 'OneClassSVM_AnomalyDetection':\n",
        "    \treturn cls(dataframe, window_width, nu, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, window_width, nu, train_rate) -> 'OneClassSVM_AnomalyDetection':\n",
        "    \tdf = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df,window_width, nu, train_rate)\n",
        "     \n",
        "    def __init__(self,df, window_width, nu, train_rate):\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "        self.nu = nu\n",
        "        self.window_width = window_width\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "        # train_labeled, test_labeled = self.dataframe.values[1:self.train_size], self.dataframe.values[self.train_size:]\n",
        "        # self.train_X, self.train_y = train_labeled[:,0], train_labeled[:,1]\n",
        "        # self.test_X, self.test_y = test_labeled[:,0], test_labeled[:,1]     \n",
        "        # self.create_persistence()\n",
        "\n",
        "        # X = series.values\n",
        "        # self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "\n",
        "    def __build_sets(self):\n",
        "        train_labeled, test_labeled = self.dataframe.values[1:self.train_size], self.dataframe.values[self.train_size:]\n",
        "        self.train_X, self.train_y = train_labeled[:,0], train_labeled[:,1]\n",
        "        self.test_X, self.test_y = test_labeled[:,0], test_labeled[:,1]   \n",
        "\n",
        "        X = self.dataframe.iloc[:,1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = []\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors.append(X[i:i+self.window_width])\n",
        "        return vectors\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        self.errors = np.zeros_like(self.test)\n",
        "        # compute anomalies\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "        # history = self.getWindowedVectors(self.train)\n",
        "\n",
        "        for i,_ in enumerate(self.test[:-self.window_width+1]):\n",
        "            sys.stdout.write('\\r'+str(i)+':'+str(len(self.test) - self.window_width))\n",
        "\n",
        "            window = self.test[i:i+self.window_width]\n",
        "            window2D = np.zeros((len(window),2))\n",
        "            window2D[:,1] = window\n",
        "            clf=OneClassSVM(nu=self.nu)\n",
        "            clf.fit(window2D)\n",
        "            error = clf.decision_function(window2D) \n",
        "            error[error>0] = 0\n",
        "            self.errors[i:i+self.window_width] += error*-10\n",
        "\n",
        "\n",
        "        # normalize anomaly score\n",
        "        self.errors[:-self.window_width+1] /= self.window_width\n",
        "        for i,error in enumerate(self.test[-self.window_width+1:]):\n",
        "            self.errors[-self.window_width + 1 + i] /=self.window_width-(i+1)\n",
        "\n",
        "        # self.errors_original = self.errors\n",
        "        # scalar = preprocessing.MinMaxScaler((0,1)).fit(self.errors.reshape(-1,1))\n",
        "        # self.errors = scalar.transform(self.errors.reshape(-1,1))*10\n",
        "\n",
        "\n",
        "    def plot(self):\n",
        "        df_test = pd.DataFrame(self.df.iloc[self.train_size:].values)\n",
        "\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test)\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5)\n",
        "        pyplot.plot(df_test[df_test[1]==1.].index, df_test[df_test[1]==1.].iloc[:,0].values,'ro')\n",
        "        pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "# iforest = OneClassSVM_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_1.csv',30,0.7,0.3)\n",
        "# iforest.fit()\n",
        "# iforest.plot()\n",
        "# iforest.get_roc_auc(verbose=False)\n",
        "\n",
        "def concatenate_errors(ar_univariates,dimension):\n",
        "    pci_ = ar_univariates[0]\n",
        "    errors = np.zeros((len(pci_.errors),dimension))\n",
        "    errors[:,0] = pci_.errors.T\n",
        "    # for i in range(1,5):\n",
        "    for i in range(1,dimension):\n",
        "        errors[:,0:i+1] = np.c_[errors[:,:i],ar_univariates[i].errors.reshape(-1,1)]\n",
        "    return np.min(errors,axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8pGTukCg3N5",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO7wg_HKpCtR",
        "colab_type": "code",
        "outputId": "52b553e4-8898-4ade-83c2-05adf094b7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "def concatenate_errors(ar_univariates,dimension):\n",
        "    pci_ = ar_univariates[0]\n",
        "    errors = np.zeros((len(pci_.errors),dimension))\n",
        "    errors[:,0] = pci_.errors.T\n",
        "    # for i in range(1,5):\n",
        "    for i in range(1,dimension):\n",
        "        errors[:,0:i+1] = np.c_[errors[:,:i],ar_univariates[i].errors.reshape(-1,1)]\n",
        "    return np.mean(errors,axis=1)\n",
        "\n",
        "errors = concatenate_errors(ar_univariates,9)\n",
        "ar_full = OneClassSVM_Average_AnomalyDetection.from_DataFrame(df_stmp,30,0.7,0.3)\n",
        "ar_full.errors = errors\n",
        "ar_full.get_roc_auc(verbose=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.9212302228911977\n",
            "Time:  0:45:25.726566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c3PLALLg4HW",
        "colab_type": "code",
        "outputId": "1b6c36b6-9a35-4628-9b09-d2e5ab21da6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "source": [
        "\n",
        "def concatenate_errors(ar_univariates,dimension):\n",
        "    pci_ = ar_univariates[0]\n",
        "    errors = np.zeros((len(pci_.errors),dimension))\n",
        "    errors[:,0] = pci_.errors.T\n",
        "    # for i in range(1,5):\n",
        "    for i in range(1,dimension):\n",
        "        errors[:,0:i+1] = np.c_[errors[:,:i],ar_univariates[i].errors.reshape(-1,1)]\n",
        "    return np.mean(errors,axis=1)\n",
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "dimension = 9\n",
        "# df = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "ar_univariates = []\n",
        "df_stmp = read_csv('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', header=0, index_col=None, parse_dates=True,squeeze=True)\n",
        "df_stmp.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "df_stmp.loc[df_stmp.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "# df = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "ar_univariates = []\n",
        "for i in range (dimension):\n",
        "    print(i)\n",
        "    df_univariate = pd.DataFrame(np.c_[df_stmp.iloc[:,i].values,df_stmp.iloc[:,-1].values])\n",
        "    df_univariate.columns = ['V1','is_anomaly']\n",
        "    ar = OneClassSVM_Average_AnomalyDetection.from_DataFrame(df_univariate,30,0.7,0.3)\n",
        "    # ar.getAndReadAnaomaliesByPCI(plot=False)\n",
        "    ar.fit()\n",
        "    ar_univariates.append(ar)\n",
        "\t\n",
        "errors = concatenate_errors(ar_univariates,9)\n",
        "ar_full = OneClassSVM_Average_AnomalyDetection.from_DataFrame(df_stmp,30,0.7,0.3)\n",
        "ar_full.errors = errors\n",
        "ar_full.get_roc_auc(verbose=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff)\n",
        "\n",
        "# iforest = XGBRegressor_AnomalyDetection('Univariate/YahooServiceNetworkTraffic/A1Benchmark/real_4.csv',30,0.7,0.66)\n",
        "# iforest.fit()\n",
        "# iforest.plot()\n",
        "# iforest.get_roc_auc(verbose=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "34338:343381\n",
            "34338:343382\n",
            "34338:343383\n",
            "34338:343384\n",
            "34338:343385\n",
            "34338:343386\n",
            "34338:343387\n",
            "34338:343388\n",
            "34338:34338"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.9212302228911977\n",
            "Time:  0:05:37.896078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1yF1EIlr9j4",
        "colab_type": "text"
      },
      "source": [
        "# AVerage AR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si-Ko_gVr_TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "import sys\n",
        "\n",
        "class AR_Compact:\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "\n",
        "    def create_persistence(self):\n",
        "        predictions = list()\n",
        "        for x in self.test_X:\n",
        "            yhat = self.model_persistence(x)\n",
        "            predictions.append(yhat)\n",
        "        rmse = sqrt(mean_squared_error(self.test_y, predictions))\n",
        "        # print('Train shape', self.train_X.shape, ' - Test shape:' , self.test_X.shape)\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)     \n",
        "        \n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe, train_rate) -> 'AR_Compact':\n",
        "    \treturn cls(dataframe, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, file: str, train_rate) -> 'AR_Compact':\n",
        "    \tdf = read_csv(path, header=0, index_col=0, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, train_rate)\n",
        "\n",
        "    \n",
        "    def __init__(self,df, train_rate):\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'anomaly':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        series = pd.DataFrame(self.df.iloc[:,0].values)  \n",
        "        self.values = DataFrame(series.values)\n",
        "        self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "        self.train, self.test = self.dataframe.values[1:self.train_size], self.dataframe.values[self.train_size:]\n",
        "        self.train_X, self.train_y = self.train[:,0], self.train[:,1]\n",
        "        self.test_X, self.test_y = self.test[:,0], self.test[:,1]     \n",
        "        # self.create_persistence()\n",
        "\n",
        "        # X = (self.dataframe['t+1'] - self.dataframe['t']).values\n",
        "        X = series.values\n",
        "\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]\n",
        "\n",
        "          \n",
        "    def fit(self, verbose=False):\n",
        "        self.model = AR(self.train)\n",
        "        self.model_fit = self.model.fit()\n",
        "        self.window = self.model_fit.k_ar\n",
        "        self.coef = self.model_fit.params  \n",
        "        if verbose:      \n",
        "            print('Lag: %s' % self.model_fit.k_ar)\n",
        "            print('Coefficients: %s' % self.model_fit.params)\n",
        "\n",
        "    \n",
        "    def predict(self):\n",
        "        self.history = self.train[len(self.train)-self.window:]\n",
        "        self.history = [self.history[i] for i in range(len(self.history))]\n",
        "        self.predictions = list()\n",
        "        for t in range(len(self.test)):\n",
        "            length = len(self.history)\n",
        "            lag = [self.history[i] for i in range(length-self.window,length)]\n",
        "            yhat = self.coef[0]\n",
        "            for d in range(self.window):\n",
        "                yhat += self.coef[d+1] * lag[self.window-d-1]\n",
        "            obs = self.test[t]\n",
        "            self.predictions.append(yhat)\n",
        "            self.history.append(obs)        \n",
        "        # for i in range(len(predictions)):\n",
        "        #     print('predicted=%f, expected=%f' % (predictions[i], test[i]))\n",
        "        # rmse = sqrt(mean_squared_error(self.test, self.predictions))\n",
        "        self.errors = np.absolute(self.test - np.array(self.predictions))\n",
        "        # print('Prediction Test RMSE: %.3f' % rmse)\n",
        "    def plot(self):\n",
        "        # plot predicted error\n",
        "        df_test = pd.DataFrame(self.df.iloc[self.train_size:].values)\n",
        "\n",
        "        pyplot.figure(figsize=(50,5))\n",
        "        pyplot.plot(self.test,color ='blue', linewidth=0.5)\n",
        "        pyplot.plot(self.predictions, color='green',  linewidth=0.5)\n",
        "        pyplot.plot(self.errors, color = 'red',  linewidth=0.5)\n",
        "        pyplot.plot(df_test[df_test[1]==1.].index, df_test[df_test[1]==1.].iloc[:,0].values,'ro')\n",
        "        pyplot.show()\n",
        "\n",
        "    # def plot(self):\n",
        "    #     # plot predicted error\n",
        "    #     indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "    #     pyplot.figure(figsize=(50,5))\n",
        "    #     pyplot.plot(self.test, color='green',  linewidth=0.5,label='True Values')\n",
        "    #     pyplot.plot(self.predictions, color='blue',  linewidth=0.5,label='Predictions')\n",
        "    #     pyplot.plot(self.errors, color = 'red',  linewidth=0.5, label='Errors')\n",
        "    #     pyplot.plot(self.df[self.df['is_anomaly']==1].index[indices] - self.train_size, self.test[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size -1], linestyle=\"\",marker=\".\", label='Anomalies')\n",
        "    #     pyplot.legend()\n",
        "    #     pyplot.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# ar_model = AR_Compact('drive/My Drive/MT/Experiments/Univariate/YahooServiceNetworkTraffic/A4Benchmark/A4Benchmark-TS18.csv', 0.3)\n",
        "# ar_model.fit()\n",
        "# ar_model.predict()\n",
        "# ar_model.plot()\n",
        "# ar_model.get_roc_auc(verbose=True)\n",
        "\n",
        "def concatenate_errors(ar_univariates, dimension):\n",
        "    pci_ = ar_univariates[0]\n",
        "    errors = np.zeros((len(pci_.errors),dimension))\n",
        "    errors[:,0] = pci_.errors.T\n",
        "    # for i in range(1,5):\n",
        "    for i in range(1,dimension):\n",
        "        errors[:,0:i+1] = np.c_[errors[:,:i],ar_univariates[i].errors.reshape(-1,1)]\n",
        "    return np.min(errors,axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
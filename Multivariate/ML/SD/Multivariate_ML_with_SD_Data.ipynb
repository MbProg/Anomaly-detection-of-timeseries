{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multivariate ML with SD Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd4DMD8mR5Ty",
        "colab_type": "text"
      },
      "source": [
        "# Generate synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poArBOs0BIB0",
        "colab_type": "code",
        "outputId": "74ef2c9c-84b7-42bb-fb4f-8a805eb333c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima_process import arma_generate_sample\n",
        "n = int(3000)\n",
        "# alpha1 = 0.666, alpha2 = -.333\n",
        "alphas = np.array([.1])\n",
        "betas = np.array([0.])\n",
        "\n",
        "# Python requires us to specify the zero-lag value which is 1\n",
        "# Also note that the alphas for the AR model must be negated\n",
        "# We also set the betas for the MA equal to 0 for an AR(p) model\n",
        "# For more information see the examples at statsmodels.org\n",
        "ar = np.r_[1, -alphas]\n",
        "ma = np.r_[1, betas]\n",
        "# # AR(2)\n",
        "# ar2 = arma_generate_sample(ar=ar, ma=ma, nsample=n) \n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.plot( ar2)\n",
        "\n",
        "T_1 =  arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_2 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_3 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_4 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_5 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "M =[[1 , 0 , 0 , 0 , 1],\n",
        "[0 , 1 , 0 , 0 , 1],\n",
        "[0 , 0 , 1 , 0 , 1],\n",
        "[0 , 0 , 0 , 1 , 1],\n",
        "[1 , -1 , 0 , 0 , 1]]\n",
        "delta = np.zeros((n,1))\n",
        "delta_anomal = np.zeros((n,1))\n",
        "delta_anomal[300:320]   = np.ones((20,1))\n",
        "delta_anomal[600:610]   = np.full((10,1),-0.7)\n",
        "delta_anomal[1300:1320] = np.full((20,1),2)\n",
        "delta_anomal[2100:2150] = np.full((50,1),-1.5)\n",
        "\n",
        "# delta_anomal[41:50] = np.ones((9,1))\n",
        "N = np.concatenate((T_1,T_2,T_3,T_4,delta), axis=1)\n",
        "N_anomal =  np.concatenate((T_1,T_2,T_3,T_4,delta_anomal), axis=1)\n",
        "B = N@M\n",
        "B_anomal = N_anomal@M\n",
        "\n",
        "T_1 = B[:,0]\n",
        "T_2 = B[:,1]\n",
        "T_3 = B[:,2]\n",
        "T_4 = B[:,3]\n",
        "T_5 = B[:,4]\n",
        "\n",
        "\n",
        "T_1_anomal = B_anomal[:,0]\n",
        "T_2_anomal = B_anomal[:,1]\n",
        "T_3_anomal = B_anomal[:,2]\n",
        "T_4_anomal = B_anomal[:,3]\n",
        "T_5_anomal = B_anomal[:,4]\n",
        "\n",
        "MD_T = np.concatenate((T_1.reshape((-1,1)),T_2.reshape((-1,1)),T_3.reshape((-1,1)),T_4.reshape((-1,1)),T_5.reshape((-1,1))),axis=1)\n",
        "MD_T_anomaly = np.concatenate((T_1_anomal.reshape((-1,1)),T_2_anomal.reshape((-1,1)),T_3_anomal.reshape((-1,1)),T_4_anomal.reshape((-1,1)),T_5_anomal.reshape((-1,1))),axis=1)\n",
        "MD_T.shape,MD_T_anomaly.shape\n",
        "\n",
        "labels = np.zeros((n,1))\n",
        "labels[300:320]     = 1\n",
        "labels[600:610]     = 1\n",
        "labels[1300:1320]   = 1\n",
        "labels[2100:2150]   = 1\n",
        "df_synthetic = pd.DataFrame(np.concatenate((MD_T_anomaly,labels), axis = 1))\n",
        "df_synthetic.columns =  np.r_[np.array(['V'+str(i) for i in range(1,6)]),['is_anomaly']]\n",
        "df_synthetic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>is_anomaly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.142487</td>\n",
              "      <td>-1.178184</td>\n",
              "      <td>1.569132</td>\n",
              "      <td>1.106891</td>\n",
              "      <td>1.640325</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.299361</td>\n",
              "      <td>-0.497105</td>\n",
              "      <td>-0.505582</td>\n",
              "      <td>0.064425</td>\n",
              "      <td>-0.638900</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.134870</td>\n",
              "      <td>-0.050699</td>\n",
              "      <td>-1.590549</td>\n",
              "      <td>1.639128</td>\n",
              "      <td>-0.136990</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.118251</td>\n",
              "      <td>-0.181265</td>\n",
              "      <td>-0.682700</td>\n",
              "      <td>1.075405</td>\n",
              "      <td>0.329691</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.438922</td>\n",
              "      <td>-1.048433</td>\n",
              "      <td>-1.953325</td>\n",
              "      <td>1.237037</td>\n",
              "      <td>-2.203643</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>1.129619</td>\n",
              "      <td>-0.149452</td>\n",
              "      <td>-0.707156</td>\n",
              "      <td>-0.840981</td>\n",
              "      <td>-0.567969</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>-0.234800</td>\n",
              "      <td>0.992676</td>\n",
              "      <td>-0.091148</td>\n",
              "      <td>0.520872</td>\n",
              "      <td>1.187599</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>0.506162</td>\n",
              "      <td>-1.059046</td>\n",
              "      <td>0.438690</td>\n",
              "      <td>-2.586029</td>\n",
              "      <td>-2.700223</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>1.122350</td>\n",
              "      <td>0.321395</td>\n",
              "      <td>-0.787998</td>\n",
              "      <td>-0.408501</td>\n",
              "      <td>0.247247</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>-0.341958</td>\n",
              "      <td>0.811087</td>\n",
              "      <td>-0.963412</td>\n",
              "      <td>1.486578</td>\n",
              "      <td>0.992295</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            V1        V2        V3        V4        V5  is_anomaly\n",
              "0     0.142487 -1.178184  1.569132  1.106891  1.640325         0.0\n",
              "1     0.299361 -0.497105 -0.505582  0.064425 -0.638900         0.0\n",
              "2    -0.134870 -0.050699 -1.590549  1.639128 -0.136990         0.0\n",
              "3     0.118251 -0.181265 -0.682700  1.075405  0.329691         0.0\n",
              "4    -0.438922 -1.048433 -1.953325  1.237037 -2.203643         0.0\n",
              "...        ...       ...       ...       ...       ...         ...\n",
              "2995  1.129619 -0.149452 -0.707156 -0.840981 -0.567969         0.0\n",
              "2996 -0.234800  0.992676 -0.091148  0.520872  1.187599         0.0\n",
              "2997  0.506162 -1.059046  0.438690 -2.586029 -2.700223         0.0\n",
              "2998  1.122350  0.321395 -0.787998 -0.408501  0.247247         0.0\n",
              "2999 -0.341958  0.811087 -0.963412  1.486578  0.992295         0.0\n",
              "\n",
              "[3000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PZ9KXMnSAAr",
        "colab_type": "text"
      },
      "source": [
        "# OCSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsQLF1wlSCdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class OneClassSVM_AnomalyDetection_MV:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, nu, train_rate) -> 'OneClassSVM_AnomalyDetection_MV':\n",
        "    \treturn cls(dataframe, dimension, window_width, nu, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension, nu, train_rate) -> 'OneClassSVM_AnomalyDetection_MV':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, dimension, window_width, nu, train_rate)\n",
        "     \n",
        "    def __init__(self,dataframe, dimension, window_width, nu, train_rate):\n",
        "        self.nu = nu\n",
        "        self.df = dataframe\n",
        "        self.window_width = window_width\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "\t\t\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return np.array(dataX), np.array(dataY)\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def __build_sets(self):\n",
        "\t\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        # self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        self.errors = np.zeros_like(self.test[:,0])\n",
        "        # compute anomalies\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "        for i,_ in enumerate(self.test[:-self.window_width+1]):\n",
        "            sys.stdout.write('\\r'+str(i)+':'+str(len(self.test) - self.window_width))\n",
        "\n",
        "            window = self.test[i:i+self.window_width]\n",
        "            clf=OneClassSVM(nu=self.nu)\n",
        "            clf.fit(window)\n",
        "            error = clf.decision_function(window) \n",
        "            error[error>0] = 0\n",
        "            self.errors[i:i+self.window_width] += error*-10\n",
        "\n",
        "\n",
        "        # normalize anomaly score\n",
        "        self.errors[:-self.window_width+1] /= self.window_width\n",
        "        for i,error in enumerate(self.test[-self.window_width+1:]):\n",
        "            self.errors[-self.window_width + 1 + i] /=self.window_width-(i+1)\n",
        "\n",
        "        # self.errors_original = self.errors\n",
        "        # scalar = preprocessing.MinMaxScaler((0,1)).fit(self.errors.reshape(-1,1))\n",
        "        # self.errors = scalar.transform(self.errors.reshape(-1,1))*10\n",
        "\n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "\n",
        "# iforest = OneClassSVM_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',None,30,3,0.7,0.3)\n",
        "# iforest.fit()\n",
        "# auc = iforest.get_roc_auc(verbose=False,plot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u80EmlqNSGMw",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYwLjK0DSG7d",
        "colab_type": "code",
        "outputId": "350cf3ef-d7c3-4000-8c27-1fea108f39af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# dataframe,window_width, dimension, nu, train_rate\n",
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "ocsvm = OneClassSVM_AnomalyDetection_MV.from_DataFrame(df_synthetic,350,5,0.9,0.3)\n",
        "ocsvm.fit()\n",
        "auc = ocsvm.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1750:1750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7960068027210885\n",
            "Time:  17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZtg33arSKPL",
        "colab_type": "text"
      },
      "source": [
        "# XGBoost Multivariate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEzeNzXASMxS",
        "colab_type": "code",
        "outputId": "3f319d6d-89c3-4640-85c2-9fb22d48a417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "seed(42)\n",
        "from keras import regularizers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class XGB_AnomalyDetection_ML:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, train_rate) -> 'XGB_AnomalyDetection_ML':\n",
        "    \treturn cls(dataframe, window_width, dimension, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension, train_rate) -> 'XGB_AnomalyDetection_ML':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, window_width, dimension, train_rate)\n",
        "     \n",
        "    def __init__(self,df, window_width, dimension, train_rate):\n",
        "\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "\n",
        "\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "    def reset_dataframe(self, df, dimension, train_rate):\n",
        "        self.df = df\n",
        "        self.dimension = dimension\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)         \n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a.reshape(-1))\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "        # fitting\n",
        "        multioutputregressor = MultiOutputRegressor(XGBRegressor(objective='reg:linear')).fit(self.train_X, self.train_y)\n",
        "\n",
        "        # predicting\n",
        "        self.predictions = multioutputregressor.predict(self.test_X) \n",
        "        # # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
        "        # # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
        "\n",
        "        # from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "        # self.model = Sequential()\n",
        "\n",
        "        # self.model = Sequential()\n",
        "        # self.model.add(LSTM(self.n_filters[0], batch_input_shape=(1, self.window_width, self.dimension), stateful=True, return_sequences=True))\n",
        "        # self.model.add(LSTM(self.n_filters[1], batch_input_shape=(1, self.window_width, self.dimension), stateful=True))\n",
        "        # self.model.add(Dense(self.dimension))\n",
        "        # self.model.compile(optimizer='adam', loss='mse')\n",
        "        # for i in range(self.n_epochs):\n",
        "        #     sys.stdout.write('\\r'+str(i)+':'+str(self.n_epochs))\n",
        "        #     self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=1, batch_size=1, verbose=0, shuffle=False)\n",
        "        #     self.model.reset_states()\n",
        "        # print('')\n",
        "\n",
        "        # # self.plotTraining()\n",
        "        # self.predictions = self.model.predict(self.test_X, batch_size = 1)\n",
        "\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        self.euclidean_errors = numpy.linalg.norm(self.test_y.reshape(self.predictions.shape) - self.predictions, axis=1)\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        true_anomaly_predicted_errors = self.euclidean_errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.euclidean_errors[self.euclidean_errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.euclidean_errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16,32], [16,32,48,64],  [32,64,12,24],[128,128,128,128],[64,64,64,64],[256,256,256,256],[128,256,512,1024]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "\n",
        "\n",
        "# xgb = XGB_ML_AnomalyDetection('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',13,3,0.3)\n",
        "# # xgb.reset_dataframe(df,5, 0.3)\n",
        "# xgb.fit()\n",
        "# # # cnn.plot()\n",
        "# auc = xgb.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "\n",
        "# print(best_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pv9ceyXSP0j",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxz-vlvqSOd2",
        "colab_type": "code",
        "outputId": "d3ce5dcd-d3ff-43ca-a589-7697b44e602c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "xgb = XGB_AnomalyDetection_ML.from_DataFrame(df_synthetic,108,5,0.3)\n",
        "xgb.fit()\n",
        "auc = xgb.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[03:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:23:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:23:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:23:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[03:23:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7368649133293483\n",
            "Time:  13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laYC-4JXSTJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54zwQUSVSo66",
        "colab_type": "text"
      },
      "source": [
        "# LOF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCvWneTnSr46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class LOF_AnomalyDetection_MV:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_neighbors, train_rate) -> 'LOF_AnomalyDetection_MV':\n",
        "    \treturn cls(dataframe, dimension, window_width, n_neighbors, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension, n_neighbors, train_rate) -> 'LOF_AnomalyDetection_MV':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, dimension, window_width, n_neighbors, train_rate)\n",
        "     \n",
        "    def __init__(self,dataframe, dimension, window_width, n_neighbors, train_rate):\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.df = dataframe\n",
        "        self.window_width = window_width\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "\t\t\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return np.array(dataX), np.array(dataY)\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def __build_sets(self):\n",
        "\t\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        # self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        self.errors = np.zeros_like(self.test[:,0])\n",
        "        # compute anomalies\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "        for i,_ in enumerate(self.test[:-self.window_width+1]):\n",
        "            sys.stdout.write('\\r'+str(i)+':'+str(len(self.test) - self.window_width))\n",
        "\n",
        "            window = self.test[i:i+self.window_width]\n",
        "            clf=LocalOutlierFactor(self.n_neighbors,contamination ='auto')\n",
        "            clf.fit_predict(window)\n",
        "            error = clf.negative_outlier_factor_\n",
        "            # error=error - 1 \n",
        "            # error= error**(-1)\n",
        "            self.errors[i:i+self.window_width] += 1/error\n",
        "\n",
        "\n",
        "        # normalize anomaly score\n",
        "        self.errors[:-self.window_width+1] /= self.window_width\n",
        "        for i,error in enumerate(self.test[-self.window_width+1:]):\n",
        "            self.errors[-self.window_width + 1 + i] /=self.window_width-(i+1)\n",
        "\n",
        "        # self.errors_original = self.errors\n",
        "        scalar = preprocessing.MinMaxScaler((0,1)).fit(self.errors.reshape(-1,1))\n",
        "        self.errors = scalar.transform(self.errors.reshape(-1,1))*10\n",
        "\n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        # true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "\n",
        "# iforest = OneClassSVM_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',None,30,3,0.7,0.3)\n",
        "# iforest.fit()\n",
        "# auc = iforest.get_roc_auc(verbose=False,plot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w_UphTJWvJY",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRxA7SUpWwAu",
        "colab_type": "code",
        "outputId": "4f501e88-bd35-4f02-f7fe-a100379bc3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# dataframe,window_width, dimension, nu, train_rate\n",
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "\n",
        "best_value, best_window, best_neighbor = 0,0,0\n",
        "for i in range(1,30):\n",
        "    window= np.random.randint(30,400)\n",
        "    neighbors = np.random.randint(3,window/2)\n",
        "    lof = LOF_AnomalyDetection_MV.from_DataFrame(df_synthetic,window,5,neighbors,0.3)\n",
        "    lof.fit()\n",
        "    auc = lof.get_roc_auc(verbose=False,plot=False)\n",
        "    if auc > best_value:\n",
        "        best_value = auc\n",
        "        best_window = window\n",
        "        best_neighbor = neighbors\n",
        "\n",
        "    endTime = datetime.datetime.now()\n",
        "    diff = endTime - startTime\n",
        "    print('window:', window, ' - neighbors:', neighbors,' - Time: ',diff.seconds)\n",
        "\n",
        "print('best: window: ', best_window,' - neighbor: ', best_neighbor, ' - auc:', best_value )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1777:1777AUC:  0.685734693877551\n",
            "window: 323  - neighbors: 132  - Time:  18\n",
            "1879:1879AUC:  0.6774727891156461\n",
            "window: 221  - neighbors: 62  - Time:  25\n",
            "1794:1794AUC:  0.6726734693877551\n",
            "window: 306  - neighbors: 60  - Time:  37\n",
            "2049:2049AUC:  0.4873877551020408\n",
            "window: 51  - neighbors: 14  - Time:  39\n",
            "1726:1726AUC:  0.6575510204081633\n",
            "window: 374  - neighbors: 51  - Time:  52\n",
            "2012:2012AUC:  0.5733197278911565\n",
            "window: 88  - neighbors: 30  - Time:  55\n",
            "1883:1883AUC:  0.6875680272108844\n",
            "window: 217  - neighbors: 82  - Time:  63\n",
            "1800:1800AUC:  0.6683571428571429\n",
            "window: 300  - neighbors: 53  - Time:  74\n",
            "1707:1707AUC:  0.6587823129251701\n",
            "window: 393  - neighbors: 57  - Time:  89\n",
            "1827:1827AUC:  0.6796054421768707\n",
            "window: 273  - neighbors: 66  - Time:  99\n",
            "1940:1940AUC:  0.6598809523809525\n",
            "window: 160  - neighbors: 53  - Time:  104\n",
            "1936:1936AUC:  0.5966938775510204\n",
            "window: 164  - neighbors: 23  - Time:  109\n",
            "1742:1742AUC:  0.6795238095238096\n",
            "window: 358  - neighbors: 169  - Time:  132\n",
            "1797:1797AUC:  0.6897244897959184\n",
            "window: 303  - neighbors: 134  - Time:  149\n",
            "1982:1982AUC:  0.5302074829931972\n",
            "window: 118  - neighbors: 16  - Time:  152\n",
            "1829:1829AUC:  0.5461428571428572\n",
            "window: 271  - neighbors: 11  - Time:  158\n",
            "1725:1725AUC:  0.6597312925170068\n",
            "window: 375  - neighbors: 55  - Time:  172\n",
            "1731:1731AUC:  0.6746224489795917\n",
            "window: 369  - neighbors: 94  - Time:  190\n",
            "1704:1704AUC:  0.6721394557823129\n",
            "window: 396  - neighbors: 190  - Time:  218\n",
            "1807:1807AUC:  0.650200680272109\n",
            "window: 293  - neighbors: 37  - Time:  227\n",
            "1865:1865AUC:  0.6888333333333333\n",
            "window: 235  - neighbors: 83  - Time:  236\n",
            "2021:2021AUC:  0.415452380952381\n",
            "window: 79  - neighbors: 6  - Time:  238\n",
            "2069:2069AUC:  0.43225510204081635\n",
            "window: 31  - neighbors: 8  - Time:  240\n",
            "2017:2017AUC:  0.4136360544217687\n",
            "window: 83  - neighbors: 6  - Time:  243\n",
            "1761:1761AUC:  0.6835238095238095\n",
            "window: 339  - neighbors: 148  - Time:  263\n",
            "1853:1853AUC:  0.6642857142857144\n",
            "window: 247  - neighbors: 46  - Time:  272\n",
            "1909:1909AUC:  0.6834183673469387\n",
            "window: 191  - neighbors: 76  - Time:  279\n",
            "1801:1801AUC:  0.6870408163265307\n",
            "window: 299  - neighbors: 97  - Time:  293\n",
            "1767:1767AUC:  0.5920544217687075\n",
            "window: 333  - neighbors: 17  - Time:  300\n",
            "best: window:  303  - neighbor:  134  - auc: 0.6897244897959184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4OX8Yhyjl-y",
        "colab_type": "text"
      },
      "source": [
        "# DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbYjfkrRjove",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class DBSCAN_AnomalyDetection_MV:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, eps, min_samples, train_rate,metric) -> 'DBSCAN_AnomalyDetection_MV':\n",
        "    \treturn cls(dataframe, dimension, window_width, eps, min_samples, train_rate,metric)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension, eps, min_samples, train_rate,metric) -> 'DBSCAN_AnomalyDetection_MV':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, dimension, window_width, eps, min_samples, train_rate,metric)\n",
        "\n",
        "    def __init__(self,dataframe, dimension, window_width, eps, min_samples, train_rate,metric):    \n",
        "        self.df = dataframe\n",
        "        self.eps = eps\n",
        "        self.metric = metric\n",
        "        self.min_samples = min_samples\n",
        "        self.window_width = window_width\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "\t\t\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return np.array(dataX), np.array(dataY)\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def __build_sets(self):\n",
        "\t\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        # self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        self.errors = np.zeros_like(self.test[:,0])\n",
        "        # compute anomalies\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "        for i,_ in enumerate(self.test[:-self.window_width+1]):\n",
        "            sys.stdout.write('\\r'+str(i)+':'+str(len(self.test) - self.window_width))\n",
        "\n",
        "            window = self.test[i:i+self.window_width]\n",
        "            clf=DBSCAN(self.eps, self.min_samples,metric = self.metric)\n",
        "            error = clf.fit_predict(window)\n",
        "            error[error>0] = 0\n",
        "            error*=-1\n",
        "            # error=error - 1 \n",
        "            # error= error**(-1)\n",
        "            self.errors[i:i+self.window_width] += error\n",
        "\n",
        "\n",
        "        # normalize anomaly score\n",
        "        self.errors[:-self.window_width+1] /= self.window_width\n",
        "        for i,error in enumerate(self.test[-self.window_width+1:]):\n",
        "            self.errors[-self.window_width + 1 + i] /=self.window_width-(i+1)\n",
        "\n",
        "        # self.errors_original = self.errors\n",
        "        # scalar = preprocessing.MinMaxScaler((0,1)).fit(self.errors.reshape(-1,1))\n",
        "        # self.errors = scalar.transform(self.errors.reshape(-1,1))*10\n",
        "\n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        # true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "\n",
        "# iforest = OneClassSVM_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',None,30,3,0.7,0.3)\n",
        "# iforest.fit()\n",
        "# auc = iforest.get_roc_auc(verbose=False,plot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxA5vBRBAVQM",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKpSBtvDAWDq",
        "colab_type": "code",
        "outputId": "b25aa750-4f2e-4528-f59b-f0d47bbef49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "dbscan = DBSCAN_AnomalyDetection_MV.from_DataFrame(df_synthetic,100,5,0.3,30, 0.3,'euclidean')\n",
        "dbscan.fit()\n",
        "auc = dbscan.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000:2000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDNGSCPkAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.506904761904762\n",
            "Time:  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze-UWN0-FvnK",
        "colab_type": "text"
      },
      "source": [
        "# iForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z0rOm5GFx3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from sklearn.ensemble import IsolationForest \n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "\n",
        "class iForest_AnomalyDetection_MV:\n",
        "\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_estimators, contamination, train_rate) -> 'iForest_AnomalyDetection_MV':\n",
        "    \treturn cls(dataframe, dimension, window_width, n_estimators, contamination, train_rate)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension, n_estimators, contamination, train_rate) -> 'iForest_AnomalyDetection_MV':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, dimension, window_width, n_estimators, contamination, train_rate)\n",
        "\n",
        "    def __init__(self,dataframe, dimension, window_width, n_estimators, contamination, train_rate):    \n",
        "        self.df = dataframe\n",
        "        self.n_estimators = n_estimators\n",
        "        self.contamination = contamination\n",
        "        self.window_width = window_width\n",
        "        self.dimension = dimension\n",
        "        self.window_width = window_width\n",
        "\t\t\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        self.X_origin = self.df.iloc[:,:dimension].values\n",
        "        self.Y_origin = self.df.iloc[:,-1].values\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return np.array(dataX), np.array(dataY)\n",
        "\n",
        "    def build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "        \n",
        "    def __build_sets(self):\n",
        "\t\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values[:,:-1]\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(np.concatenate((X,self.dataframe.values[:,-1].reshape(-1,1)),axis=1))\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe['t'].iloc[self.train_size:], self.dataframe['t+1'].iloc[self.train_size::]))\n",
        "#         print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        # self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        self.errors = np.zeros_like(self.test[:,0])\n",
        "        # compute anomalies\n",
        "        warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "        for i,_ in enumerate(self.test[:-self.window_width+1]):\n",
        "            sys.stdout.write('\\r'+str(i)+':'+str(len(self.test) - self.window_width))\n",
        "\n",
        "            window = self.test[i:i+self.window_width]\n",
        "\n",
        "\n",
        "            clf=IsolationForest(n_estimators=self.n_estimators,   # number of isolation trees\n",
        "                            max_samples='auto', # number of samples to draw to create an isolation tree\n",
        "                            contamination=self.contamination, # porportion of outliers\n",
        "                            max_features=1.0,   #\n",
        "                            bootstrap=False, \n",
        "                            n_jobs=-1, \n",
        "                            random_state=42, \n",
        "                            verbose=0, behaviour='new')\n",
        "            clf.fit(window)\n",
        "            error = clf.decision_function(window) \n",
        "            error[error>0] = 0\n",
        "            self.errors[i:i+self.window_width] += error*-1\n",
        "\n",
        "            # error=error - 1 \n",
        "            # error= error**(-1)\n",
        "            # self.errors[i:i+self.window_width] += error\n",
        "\n",
        "\n",
        "        # normalize anomaly score\n",
        "        self.errors[:-self.window_width+1] /= self.window_width\n",
        "        for i,error in enumerate(self.test[-self.window_width+1:]):\n",
        "            self.errors[-self.window_width + 1 + i] /=self.window_width-(i+1)\n",
        "\n",
        "        # self.errors_original = self.errors\n",
        "        # scalar = preprocessing.MinMaxScaler((0,1)).fit(self.errors.reshape(-1,1))\n",
        "        # self.errors = scalar.transform(self.errors.reshape(-1,1))*10\n",
        "\n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size ]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        # true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, max(true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended),np.max(self.errors) + np.mean(self.errors))]\n",
        "\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "\n",
        "\n",
        "# iforest = OneClassSVM_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv',None,30,3,0.7,0.3)\n",
        "# iforest.fit()\n",
        "# auc = iforest.get_roc_auc(verbose=False,plot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VSlN98QGuMP",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E245sSKhGu7R",
        "colab_type": "code",
        "outputId": "99088b60-eaca-407f-c89b-5e538d34431a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "dbscan = iForest_AnomalyDetection_MV.from_DataFrame(df_synthetic,100,5,20, 'auto', 0.3)\n",
        "dbscan.fit()\n",
        "auc = dbscan.get_roc_auc(verbose=False,plot=True)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000:2000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.6354353741496599\n",
            "Time:  231\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultivariateNeuralNetworks with SD and NASA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmSzxnT6JsJg",
        "colab_type": "code",
        "outputId": "c232acc1-ad07-4ec8-cc14-8ce6c6eab939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsBQbAYYZyWG",
        "colab_type": "text"
      },
      "source": [
        "# Create Synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVbEbFQoJz80",
        "colab_type": "code",
        "outputId": "b4314b26-7ad1-45f9-9b63-c7ac99d94ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima_process import arma_generate_sample\n",
        "n = int(3000)\n",
        "# alpha1 = 0.666, alpha2 = -.333\n",
        "alphas = np.array([.1])\n",
        "betas = np.array([0.])\n",
        "\n",
        "# Python requires us to specify the zero-lag value which is 1\n",
        "# Also note that the alphas for the AR model must be negated\n",
        "# We also set the betas for the MA equal to 0 for an AR(p) model\n",
        "# For more information see the examples at statsmodels.org\n",
        "ar = np.r_[1, -alphas]\n",
        "ma = np.r_[1, betas]\n",
        "# # AR(2)\n",
        "# ar2 = arma_generate_sample(ar=ar, ma=ma, nsample=n) \n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.plot( ar2)\n",
        "\n",
        "T_1 =  arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_2 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_3 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_4 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "T_5 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
        "M =[[1 , 0 , 0 , 0 , 1],\n",
        "[0 , 1 , 0 , 0 , 1],\n",
        "[0 , 0 , 1 , 0 , 1],\n",
        "[0 , 0 , 0 , 1 , 1],\n",
        "[1 , -1 , 0 , 0 , 1]]\n",
        "delta = np.zeros((n,1))\n",
        "delta_anomal = np.zeros((n,1))\n",
        "delta_anomal[300:320]   = np.ones((20,1))\n",
        "delta_anomal[600:610]   = np.full((10,1),-0.7)\n",
        "delta_anomal[1300:1320] = np.full((20,1),2)\n",
        "delta_anomal[2100:2150] = np.full((50,1),-1.5)\n",
        "\n",
        "# delta_anomal[41:50] = np.ones((9,1))\n",
        "N = np.concatenate((T_1,T_2,T_3,T_4,delta), axis=1)\n",
        "N_anomal =  np.concatenate((T_1,T_2,T_3,T_4,delta_anomal), axis=1)\n",
        "B = N@M\n",
        "B_anomal = N_anomal@M\n",
        "\n",
        "T_1 = B[:,0]\n",
        "T_2 = B[:,1]\n",
        "T_3 = B[:,2]\n",
        "T_4 = B[:,3]\n",
        "T_5 = B[:,4]\n",
        "\n",
        "\n",
        "T_1_anomal = B_anomal[:,0]\n",
        "T_2_anomal = B_anomal[:,1]\n",
        "T_3_anomal = B_anomal[:,2]\n",
        "T_4_anomal = B_anomal[:,3]\n",
        "T_5_anomal = B_anomal[:,4]\n",
        "\n",
        "MD_T = np.concatenate((T_1.reshape((-1,1)),T_2.reshape((-1,1)),T_3.reshape((-1,1)),T_4.reshape((-1,1)),T_5.reshape((-1,1))),axis=1)\n",
        "MD_T_anomaly = np.concatenate((T_1_anomal.reshape((-1,1)),T_2_anomal.reshape((-1,1)),T_3_anomal.reshape((-1,1)),T_4_anomal.reshape((-1,1)),T_5_anomal.reshape((-1,1))),axis=1)\n",
        "MD_T.shape,MD_T_anomaly.shape\n",
        "\n",
        "labels = np.zeros((n,1))\n",
        "labels[300:320]     = 1\n",
        "labels[600:610]     = 1\n",
        "labels[1300:1320]   = 1\n",
        "labels[2100:2150]   = 1\n",
        "df_synthetic = pd.DataFrame(np.concatenate((MD_T_anomaly,labels), axis = 1))\n",
        "df_synthetic.columns =  np.r_[np.array(['V'+str(i) for i in range(1,6)]),['is_anomaly']]\n",
        "df_synthetic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>is_anomaly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.496714</td>\n",
              "      <td>-1.907808</td>\n",
              "      <td>-1.114081</td>\n",
              "      <td>0.765402</td>\n",
              "      <td>-1.759773</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.088593</td>\n",
              "      <td>-1.051166</td>\n",
              "      <td>-0.742339</td>\n",
              "      <td>1.149953</td>\n",
              "      <td>-0.732145</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.638829</td>\n",
              "      <td>-0.518722</td>\n",
              "      <td>-1.016294</td>\n",
              "      <td>0.613685</td>\n",
              "      <td>-0.282502</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.586913</td>\n",
              "      <td>1.835815</td>\n",
              "      <td>-0.649625</td>\n",
              "      <td>-1.881129</td>\n",
              "      <td>0.891974</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.075462</td>\n",
              "      <td>0.740135</td>\n",
              "      <td>-0.279113</td>\n",
              "      <td>-0.343535</td>\n",
              "      <td>0.042024</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>-0.019684</td>\n",
              "      <td>0.262047</td>\n",
              "      <td>0.081516</td>\n",
              "      <td>-1.146083</td>\n",
              "      <td>-0.822204</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>0.255784</td>\n",
              "      <td>1.178853</td>\n",
              "      <td>1.175369</td>\n",
              "      <td>-0.187431</td>\n",
              "      <td>2.422576</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>-1.216182</td>\n",
              "      <td>-1.099519</td>\n",
              "      <td>1.705984</td>\n",
              "      <td>0.819271</td>\n",
              "      <td>0.209554</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>0.212558</td>\n",
              "      <td>0.357999</td>\n",
              "      <td>-0.514389</td>\n",
              "      <td>-0.018769</td>\n",
              "      <td>0.037399</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>-0.134003</td>\n",
              "      <td>-1.134481</td>\n",
              "      <td>0.749743</td>\n",
              "      <td>-0.948191</td>\n",
              "      <td>-1.466932</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            V1        V2        V3        V4        V5  is_anomaly\n",
              "0     0.496714 -1.907808 -1.114081  0.765402 -1.759773         0.0\n",
              "1    -0.088593 -1.051166 -0.742339  1.149953 -0.732145         0.0\n",
              "2     0.638829 -0.518722 -1.016294  0.613685 -0.282502         0.0\n",
              "3     1.586913  1.835815 -0.649625 -1.881129  0.891974         0.0\n",
              "4    -0.075462  0.740135 -0.279113 -0.343535  0.042024         0.0\n",
              "...        ...       ...       ...       ...       ...         ...\n",
              "2995 -0.019684  0.262047  0.081516 -1.146083 -0.822204         0.0\n",
              "2996  0.255784  1.178853  1.175369 -0.187431  2.422576         0.0\n",
              "2997 -1.216182 -1.099519  1.705984  0.819271  0.209554         0.0\n",
              "2998  0.212558  0.357999 -0.514389 -0.018769  0.037399         0.0\n",
              "2999 -0.134003 -1.134481  0.749743 -0.948191 -1.466932         0.0\n",
              "\n",
              "[3000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEnz4cDKJ4tM",
        "colab_type": "text"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzlcPjDWJ6D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "seed(42)\n",
        "from keras import regularizers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class MLP_AnomalyDetection:\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
        "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, distance_function)\n",
        "     \n",
        "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, distance_function):\n",
        "\n",
        "        self.distance_function = distance_function\n",
        "        self.dimension = dimension\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a.reshape(-1))\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        # self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "        set_random_seed(42)\n",
        "        seed(42)\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Dense(30, activation='relu', input_dim=self.window_width*self.dimension))\n",
        "        self.model.add(Dense(40, activation='relu'))\n",
        "        self.model.add(Dense(20, activation='relu'))\n",
        "        self.model.add(Dense(self.dimension))\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=1)\n",
        "\n",
        "        self.plotTraining()\n",
        "\n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "        # xgb = XGBRegressor()\n",
        "        # xgb.fit(self.train_X.reshape(-1,1),self.train_y.reshape(-1,1))\n",
        "\n",
        "        # rmse = sqrt(mean_squared_error(self.test, self.predictions))\n",
        "        # self.errors = np.absolute(self.test - np.array(self.predictions))\n",
        "        # print('Prediction Test RMSE: %.3f' % rmse)\n",
        "\n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "\t\t\t\t\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)        \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# # mlp = MLP_AnomalyDetection('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',100,9,30,0.3)\n",
        "# mlp = MLP_AnomalyDetection.from_DataFrame(df_synthetic,100,5,30,0.3)\n",
        "# mlp.fit()\n",
        "# # mlp.plot()\n",
        "# mlp.get_roc_auc(verbose=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AoeJ2EIs7XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "0.46719427454831985"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0PrfNR87tT_",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lBk_V0R7vk8",
        "colab_type": "text"
      },
      "source": [
        "### Mahalanobis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUVzcvVZ7xGJ",
        "colab_type": "code",
        "outputId": "858a8c8a-1234-4f8f-c60a-275a9e53783e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "mlp = MLP_AnomalyDetection.from_DataFrame(df_synthetic,100,5,30,0.3,'mahalanobis')\n",
        "mlp.fit()\n",
        "# mlp.plot()\n",
        "mlp.get_roc_auc(verbose=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 798 samples, validate on 79 samples\n",
            "Epoch 1/30\n",
            "798/798 [==============================] - 22s 28ms/step - loss: 1.1077 - val_loss: 0.9955\n",
            "Epoch 2/30\n",
            "798/798 [==============================] - 0s 252us/step - loss: 0.6104 - val_loss: 1.0685\n",
            "Epoch 3/30\n",
            "798/798 [==============================] - 0s 246us/step - loss: 0.2988 - val_loss: 1.1171\n",
            "Epoch 4/30\n",
            "798/798 [==============================] - 0s 235us/step - loss: 0.1113 - val_loss: 1.1238\n",
            "Epoch 5/30\n",
            "798/798 [==============================] - 0s 241us/step - loss: 0.0476 - val_loss: 1.1320\n",
            "Epoch 6/30\n",
            "798/798 [==============================] - 0s 251us/step - loss: 0.0279 - val_loss: 1.1200\n",
            "Epoch 7/30\n",
            "798/798 [==============================] - 0s 249us/step - loss: 0.0223 - val_loss: 1.1215\n",
            "Epoch 8/30\n",
            "798/798 [==============================] - 0s 268us/step - loss: 0.0218 - val_loss: 1.1252\n",
            "Epoch 9/30\n",
            "798/798 [==============================] - 0s 247us/step - loss: 0.0180 - val_loss: 1.1349\n",
            "Epoch 10/30\n",
            "798/798 [==============================] - 0s 246us/step - loss: 0.0176 - val_loss: 1.1145\n",
            "Epoch 11/30\n",
            "798/798 [==============================] - 0s 250us/step - loss: 0.0164 - val_loss: 1.1148\n",
            "Epoch 12/30\n",
            "798/798 [==============================] - 0s 247us/step - loss: 0.0173 - val_loss: 1.1136\n",
            "Epoch 13/30\n",
            "798/798 [==============================] - 0s 262us/step - loss: 0.0185 - val_loss: 1.1233\n",
            "Epoch 14/30\n",
            "798/798 [==============================] - 0s 241us/step - loss: 0.0223 - val_loss: 1.1079\n",
            "Epoch 15/30\n",
            "798/798 [==============================] - 0s 266us/step - loss: 0.0261 - val_loss: 1.0929\n",
            "Epoch 16/30\n",
            "798/798 [==============================] - 0s 248us/step - loss: 0.0241 - val_loss: 1.1026\n",
            "Epoch 17/30\n",
            "798/798 [==============================] - 0s 255us/step - loss: 0.0239 - val_loss: 1.0874\n",
            "Epoch 18/30\n",
            "798/798 [==============================] - 0s 263us/step - loss: 0.0237 - val_loss: 1.0995\n",
            "Epoch 19/30\n",
            "798/798 [==============================] - 0s 254us/step - loss: 0.0223 - val_loss: 1.0639\n",
            "Epoch 20/30\n",
            "798/798 [==============================] - 0s 247us/step - loss: 0.0196 - val_loss: 1.0878\n",
            "Epoch 21/30\n",
            "798/798 [==============================] - 0s 263us/step - loss: 0.0179 - val_loss: 1.0645\n",
            "Epoch 22/30\n",
            "798/798 [==============================] - 0s 250us/step - loss: 0.0170 - val_loss: 1.0800\n",
            "Epoch 23/30\n",
            "798/798 [==============================] - 0s 263us/step - loss: 0.0156 - val_loss: 1.0591\n",
            "Epoch 24/30\n",
            "798/798 [==============================] - 0s 254us/step - loss: 0.0142 - val_loss: 1.0737\n",
            "Epoch 25/30\n",
            "798/798 [==============================] - 0s 254us/step - loss: 0.0140 - val_loss: 1.0543\n",
            "Epoch 26/30\n",
            "798/798 [==============================] - 0s 248us/step - loss: 0.0144 - val_loss: 1.0622\n",
            "Epoch 27/30\n",
            "798/798 [==============================] - 0s 237us/step - loss: 0.0130 - val_loss: 1.0673\n",
            "Epoch 28/30\n",
            "798/798 [==============================] - 0s 263us/step - loss: 0.0127 - val_loss: 1.0581\n",
            "Epoch 29/30\n",
            "798/798 [==============================] - 0s 255us/step - loss: 0.0132 - val_loss: 1.0605\n",
            "Epoch 30/30\n",
            "798/798 [==============================] - 0s 265us/step - loss: 0.0134 - val_loss: 1.0629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8559486607142855\n",
            "Time:  37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvAnHO0rAXf_",
        "colab_type": "code",
        "outputId": "4c6c9ba0-e986-477f-b555-94189fc67c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "mlp = MLP_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',None,100,9,30,0.3,'mahalanobis')\n",
        "mlp.fit()\n",
        "# mlp.plot()\n",
        "mlp.get_roc_auc(verbose=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14627 samples, validate on 1462 samples\n",
            "Epoch 1/30\n",
            "14627/14627 [==============================] - 3s 181us/step - loss: 1.1377 - val_loss: 0.7150\n",
            "Epoch 2/30\n",
            "14627/14627 [==============================] - 2s 153us/step - loss: 1.1185 - val_loss: 0.7165\n",
            "Epoch 3/30\n",
            "14627/14627 [==============================] - 2s 151us/step - loss: 1.1103 - val_loss: 0.7212\n",
            "Epoch 4/30\n",
            "14627/14627 [==============================] - 2s 154us/step - loss: 1.0934 - val_loss: 0.7297\n",
            "Epoch 5/30\n",
            "14627/14627 [==============================] - 2s 153us/step - loss: 1.0662 - val_loss: 0.7408\n",
            "Epoch 6/30\n",
            "14627/14627 [==============================] - 2s 152us/step - loss: 1.0328 - val_loss: 0.7535\n",
            "Epoch 7/30\n",
            "14627/14627 [==============================] - 2s 151us/step - loss: 0.9907 - val_loss: 0.7752\n",
            "Epoch 8/30\n",
            "14627/14627 [==============================] - 2s 153us/step - loss: 0.9514 - val_loss: 0.7592\n",
            "Epoch 9/30\n",
            "14627/14627 [==============================] - 2s 149us/step - loss: 0.9164 - val_loss: 0.7809\n",
            "Epoch 10/30\n",
            "14627/14627 [==============================] - 2s 157us/step - loss: 0.8851 - val_loss: 0.7945\n",
            "Epoch 11/30\n",
            "14627/14627 [==============================] - 2s 152us/step - loss: 0.8514 - val_loss: 0.8228\n",
            "Epoch 12/30\n",
            "14627/14627 [==============================] - 2s 152us/step - loss: 0.8253 - val_loss: 0.8297\n",
            "Epoch 13/30\n",
            "14627/14627 [==============================] - 2s 152us/step - loss: 0.8010 - val_loss: 0.8634\n",
            "Epoch 14/30\n",
            "14627/14627 [==============================] - 2s 157us/step - loss: 0.7860 - val_loss: 0.8483\n",
            "Epoch 15/30\n",
            "14627/14627 [==============================] - 2s 154us/step - loss: 0.7781 - val_loss: 0.8321\n",
            "Epoch 16/30\n",
            "14627/14627 [==============================] - 2s 153us/step - loss: 0.7737 - val_loss: 0.8331\n",
            "Epoch 17/30\n",
            "14627/14627 [==============================] - 2s 153us/step - loss: 0.7633 - val_loss: 0.8593\n",
            "Epoch 18/30\n",
            "14627/14627 [==============================] - 2s 155us/step - loss: 0.7619 - val_loss: 0.8782\n",
            "Epoch 19/30\n",
            "14627/14627 [==============================] - 2s 151us/step - loss: 0.7467 - val_loss: 0.8591\n",
            "Epoch 20/30\n",
            "14627/14627 [==============================] - 2s 151us/step - loss: 0.7384 - val_loss: 0.9144\n",
            "Epoch 21/30\n",
            "14627/14627 [==============================] - 2s 153us/step - loss: 0.7267 - val_loss: 0.8542\n",
            "Epoch 22/30\n",
            "14627/14627 [==============================] - 2s 156us/step - loss: 0.7325 - val_loss: 0.8708\n",
            "Epoch 23/30\n",
            "14627/14627 [==============================] - 2s 152us/step - loss: 0.7148 - val_loss: 0.8666\n",
            "Epoch 24/30\n",
            "14627/14627 [==============================] - 2s 153us/step - loss: 0.7045 - val_loss: 0.8964\n",
            "Epoch 25/30\n",
            "14627/14627 [==============================] - 2s 153us/step - loss: 0.6924 - val_loss: 0.8442\n",
            "Epoch 26/30\n",
            "14627/14627 [==============================] - 2s 151us/step - loss: 0.6906 - val_loss: 0.8808\n",
            "Epoch 27/30\n",
            "14627/14627 [==============================] - 2s 151us/step - loss: 0.6793 - val_loss: 0.8515\n",
            "Epoch 28/30\n",
            "14627/14627 [==============================] - 2s 152us/step - loss: 0.6689 - val_loss: 0.8924\n",
            "Epoch 29/30\n",
            "14627/14627 [==============================] - 2s 152us/step - loss: 0.6563 - val_loss: 0.8784\n",
            "Epoch 30/30\n",
            "14627/14627 [==============================] - 2s 149us/step - loss: 0.6501 - val_loss: 0.8990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngYhIjvv/RoNTPblrbowAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deViWZaLH8e8N4r7lriCKqai4oYg6\ntliT6dhCtpmmZVY2lXVOM+WZqabFpqZybLcpM9Nq0sppilJTMz25Fi6pgIoIKiiKiIKyL/f5A0rG\no/KqwPMuv891eV3v8vDy8+b1x+P9PO/9GGstIiLi/fycDiAiIjVDhS8i4iNU+CIiPkKFLyLiI1T4\nIiI+QoUvIuIjKi18Y8xsY0y6MSb2DM8bY8wbxphEY8xWY0y/qo8pIiIXypU9/DnAiLM8/zugS/mf\nScA/LjyWiIhUtUoL31r7A5B5lk2igA9tmfVAU2NM26oKKCIiVaNWFbxGIJBS4X5q+WNpp25ojJlE\n2f8CaNCgQf9u3bpVwbcXEXFWqbWkZOaRnV9E8wa1ade0XrV9r40bN2ZYa1uez9dWReG7zFo7E5gJ\nEBERYTds2FCT315EpEpZa1mxM51pSxLITMvmL8O68sDQi6nlX33nwxhj9p7v11ZF4e8H2le4H1T+\nmIiI11q9K4MnvtzG3iO5BDatx/Rb+nBT/yCnY51VVRR+NDDZGDMfGAhkWWv/33SOiIg3KCwuZd5P\n+3hx8Q6aNajNizf24sZ+QdSu5f5nuVda+MaYecBQoIUxJhV4GggAsNa+AywCRgKJQC5wV3WFFRFx\nUmZOIWPfW8+Og8dp0bA2n9w7kA7NGzgdy2WVFr61dkwlz1vgwSpLJCLihhLTT/DAPzey90gub40N\nZ0RYm2qdq68ONXrQVkTE05SUWl76dgfvr06mfoA/b4wJZ3hYG6djnRcVvojIGRzKzuehTzbz055M\nbukfxGMjQmnVqK7Tsc6bCl9E5DTW7T7ClH9tIeN4IS/f1JtbB7Sv/IvcnApfROQU//xxL0/8O5b6\ntf2ZOzGSyJBmTkeqEip8EZEK3vnf3by4eAdXdmvFq7f2pUn9AKcjVRkVvogIsD7pCK99l8D6pExG\n9mrDm2P64e9nnI5VpVT4IuLTjuUW8vryXXywZg9N6wfw1LU9GDeog9eVPajwRcRH5RYW80x0HP/a\ntJ+SUsuYyGCevq4HdQP8nY5WbVT4IuJz0rLymLJgK2sSM7hjcEdu7h9Ez8AmTseqdip8EfEZ8Qey\nmbU6iS8376fUwnNRYYwf3NHpWDVGhS8iXi8tK48XFu1g0bY06gf4c3P/IB4Y2pmOLTxnHZyqoMIX\nEa+1ad9RZq1K4rv4dIpKS5k4JIQHhl5M84Z1nI7mCBW+iHilt77fxd+XJlAvwJ+b+gcy4TchhLZp\n5HQsR6nwRcSrnCgo5rVlCcxancyo8ECmRoXRqK73fHjqQqjwRcQrWGv5bns6z0THsf9YHmMig3ku\nKszjljCuTip8EfF4i7al8cqyBBLTT9CqUR3mTozk8q7ndZ1vr6bCFxGPZa3l/dXJPL9oO11aNWTa\nzb2J6hvoEZcbdIIKX0Q8Un5RCf89/2e+jTvIJZ1b8Pa4fjTWXP1ZqfBFxONk5xcxasYadh/O4bHh\noTww9GKM8b61b6qaCl9EPEpWbhGjZ65jX2Yuz4/qye0DOzgdyWOo8EXEIxSVlPL1lgO8tSKR5Iwc\nZk8YwBWhrZyO5VFU+CLi1rJyi/hicyqfxqSw4+BxWjeuw0s39VbZnwcVvoi4rcPHCxj//o+/Fv0r\nt/ZhVHig5uvPkwpfRNzS6l0ZTP0mjoRDJ3h8ZDfuvbSTiv4CqfBFxK2UlFpeXZbAWysSAZg5vj9X\nh7VxOJV3UOGLiNs4nl/ElAVbWRx7kKGhLXl9dLhXXUTcaSp8EXELK3am8+S/YzmQlccfh3Vl8pWd\nNYVTxVT4IuKo0lLLyoR07vtoI+0vqs+HEyO5tIvWwakOKnwRcUxaVh53zv6JhEMnaN6gNp//frDP\nXpykJqjwRcQRaVl5TJyzgYRDJ7jnkhDu9+ErUdUUFb6I1LicgmJufHst2XlFvDOuHyN6tnU6kk9Q\n4YtIjSksLuW17xKYvSaZguJSLY9Qw1T4IlIjDh8v4K45PxG7P5uhoS2555JOXNKlhdOxfIoKX0Sq\n3Yod6Tw0bzNFJaVMv6UPN/UPcjqST1Lhi0i12Z6WzVvfJ7JwWxpN6gUw4/YIXXrQQS4VvjFmBPA6\n4A/Msta+eMrzwcBcoGn5Nn+y1i6q4qwi4gGKS0r5x8rdLN+Rzs8pxwC4pX8Qjw4PpXXjug6n822V\nFr4xxh+YAQwDUoEYY0y0tTa+wmZPAp9Za/9hjOkBLAI6VkNeEXFTyRk5fLhuD8viD5F6NI/w4KZM\nvqIzN4S3o3OrRk7HE1zbw48EEq21SQDGmPlAFFCx8C3QuPx2E+BAVYYUEfeVkpnL3LV7mL0mmVr+\nfvzm4uY8clVXzdO7IVcKPxBIqXA/FRh4yjbPAEuNMQ8BDYCrTvdCxphJwCSA4ODgc80qIm5kxc50\nXlq8gx0Hj2MMXNOrLU9d14NWjTRt466q6qDtGGCOtXa6MWYw8JExpqe1trTiRtbamcBMgIiICFtF\n31tEatjbKxN5+dudNKkXwBMjuzOiZxvaN6vvdCyphCuFvx9oX+F+UPljFd0NjACw1q4zxtQFWgDp\nVRFSRNzHrFVJvPztToaHteaFUb20HIIHcaXwY4AuxpgQyor+NmDsKdvsA34LzDHGdAfqAoerMqiI\nOOdYbiFfbznAgo2pbEnNol9wU94YE06dWv5OR5NzUGnhW2uLjTGTgSWUnXI521obZ4yZCmyw1kYD\nfwTeM8Y8QtkB3AnWWk3ZiHi4IycK+GLTfmasTORYbhGN6tRiyohQ7r20EwH+fk7Hk3Pk0hx++Tn1\ni0557KkKt+OBIVUbTUSc9G1sGo98uoW8ohLC2jXm7zf34YpurfD300VJPJU+aSsi/88vB2V7BzVh\n2s19CG2j8+i9gQpfRH71bexBPl6/l9WJGQzoeBHvjOuvg7JeRIUvIgDMXbuHp6PjaNO4Lvdd3omH\nr+xCgzqqCG+in6aIMGtVEn9duJ1BnZox684BNFTReyX9VEV8mLWWWauSeX7Rdvq2b8q74yJU9l5M\nP1kRH2Wt5blvtjN7TTK/69mGv9/SR1M4Xk4/XREfZK1l8rzNLNyaxtiBwTx/Q0+M0emW3k6FL+JD\nrLXE7s/m+UXxrE/KZPygDjx7fZjK3keo8EV8RGZOIU9+uY1F2w4S4G+YGhXGuIEd8NMHqXyGCl/E\nByyJO8jTX8WRcaKAG8MD+Z/fddPVp3yQCl/Eix3NKeS5hfF8sWk/nVo24Ms7h9AzsInTscQhKnwR\nL5SckcMryxJYvv0QuYUl3Dm4A49f012rW/o4Fb6IF0nJzOXVZQlEbzlAgL8fl3dtye2Dgrm0S0un\no4kbUOGLeIHC4lJe/S6B935IAmD0gPY8eEVn2jWt53AycScqfBEPty01iz989jO70k9wbe+2PD6y\nu4peTkuFL+LBXl2WwOvLd1E3wI/37ohgWI/WTkcSN6bCF/FQn/y4j9eX7+LKbq149vowXURcKqXC\nF/FAB7PyefeH3XRv25iZ4/tTS5cbFBfoXSLiYRLTTzDmvfWkZxcwZUSoyl5cpj18EQ+RX1TC9KU7\neX91MvVr12LuxEgiQ5o5HUs8iApfxM3lF5Xw+cZU/r5kJ1l5RVzbuy3PXB9GC116UM6RCl/ETVlr\nWb49nenLEtielk3jurV4d3x/hoe1cTqaeCgVvoibevW7XbyxfBdN6wfw5phwftezjebr5YKo8EXc\nTH5RCc9ExzE/JoWBIc34+J6BBKjopQqo8EXcSHJGDn/5MpbViRncd1knpozohr/Wq5cqosIXcQNZ\neUU8Ex3HN1sPUMvPj6ev68FdQ0KcjiVeRoUv4rBdh45z+6wfOXyigPGDOjD5is600sVJpBqo8EUc\ntHpXBg/P34y/n+HTSYN1Xr1UKxW+iEOWxB3k4XmbadukLu9PGMDFLRs6HUm8nApfxAHTl+7kze8T\n6RnYmLfH9ie4uRY+k+qnwhepQUUlpby6LIG3V+7m6h6teXNsuC47KDVGhS9SQ47mFDJxbgyb9x1j\nTGR7nr4uTGUvNUqFL1IDvt5ygCe/jCWvsIQ3x4RzXZ92TkcSH6TCF6lGK3ak89mGFBbHHiSsXWNe\nvLE3vYKaOB1LfJRLn9c2xowwxuw0xiQaY/50hm1uNcbEG2PijDGfVG1MEc8zd+0e7poTw/8mHGb8\noA7MujNCZS+OqnQP3xjjD8wAhgGpQIwxJtpaG19hmy7An4Eh1tqjxphW1RVYxN2lZOYybclOorcc\noF9wU+ZNGqS5enELrkzpRAKJ1tokAGPMfCAKiK+wzb3ADGvtUQBrbXpVBxXxBBknChj//o/szczl\nvss68ciwrip7cRuuFH4gkFLhfiow8JRtugIYY9YA/sAz1tpvT30hY8wkYBJAcHDw+eQVcVuHsvOZ\n8EEMB7PzmX/vIAZ2au50JJH/UFUHbWsBXYChQBDwgzGml7X2WMWNrLUzgZkAERERtoq+t4ij8otK\nWBybxl+/2U5uYQkzx0eo7MUtuVL4+4H2Fe4HlT9WUSrwo7W2CEg2xiRQ9gsgpkpSirip5IwcHvn0\nZ35OOUa3No14a2w4nVs1cjqWyGm5UvgxQBdjTAhlRX8bMPaUbb4ExgAfGGNaUDbFk1SVQUXcSWFx\nKfNj9vHXhdspKbXcNaQjj4/srguViFurtPCttcXGmMnAEsrm52dba+OMMVOBDdba6PLnrjbGxAMl\nwGPW2iPVGVzECdZaPlq/l1eXJXA0t4gebRvz1thwOmnhM/EAxlpnptIjIiLshg0bHPneIufDWvvr\ndWa7tGrIlBHduKp7K4zRFamk5hhjNlprI87na/VJWxEXfbhuL28s38WwHq15+/Z+mr4Rj6N3rIgL\nYvdn8fK3O349MKuyF0+kPXyRs8gtLGbO2j28sjSB1o3rMuvOCH2QSjyWCl/kDDbuPcq9H24gM6eQ\nyJBmvH5bX9o2qed0LJHzpsIXOY1F29L442dbaFi3Fgt+P5iIjrrWrHg+Fb5IBcUlpbz6XQIzVuym\nd1ATXrm1L51b6ZRL8Q4qfJFyyRk5TFmwhZg9RxkVHshLN/Wmdi0dnBXvocIXoewc+8mfbCIlM5cn\nr+nOPZd2cjqSSJVT4YvPs9by2IKtxB3I5vlRPbl9YAenI4lUCxW++LT4A9n85atYNu49ytU9WnPb\nAC3bLd5LhS8+a09GDrfNXAfA1Kgwxg3sgJ+flkkQ76XCF59UWFzKXxdu53hBMSv+OJSOLRo4HUmk\n2qnwxef8kHCY6Ut3siU1ixv6tlPZi89Q4YvPSM/O59EFW/kh4TD1a/vzXFQY4wbpAK34DhW++ITk\njBxGv7uO9OMFPHxlZ34/9GLq19bbX3yL3vHi1Y7mFPKvTanMWJEIwFcPDqFP+6YOpxJxhgpfvFJJ\nqWXGikReX76LklLLJZ1b8PjI7vRo19jpaCKOUeGL19l7JIf7P95EfFo2XVs35KWbehMefJHTsUQc\np8IXr1FYXLbw2Zw1e/D3M7wwqhdjB+qDVCK/UOGLVzhyooCH5m1m7e4jXNO7LY+P7E5gU61dL1KR\nCl88XnJGDje+vYbj+cW8cmsfbuwX5HQkEbekwhePlZaVx1c/H+CN5bsAmDsxkiGdWzicSsR9qfDF\n42zcm8nfFu1g476jWAtDOjdn2s19aKcpHJGzUuGLxyguKeW/Pv2ZhVvTqBvgx839grh/6MWEtGiA\nMVr0TKQyKnzxCOnZ+TwdHcfi2INM+E1HHhseSoM6evuKnAv9ixG3lnGigKe+imVZ/CGKSiz3XdaJ\nP/2um/boRc6DCl/ckrWWaUt28v7qZKyFOwd35JaI9oS2aeR0NBGPpcIXt1NQXMJTX8bx6YYUrght\nyZQR3ejeVksiiFwoFb64jdJSyxeb9zNrVRI7Dh5n/KAOPHt9mK5CJVJFVPjiFjJOFPA/C7ayfEc6\noa0bMe3m3twS0d7pWCJeRYUvjlu0LY2no+PIyivi6et6MOE3HXVQVqQaqPDFEdZavt+Rzpy1e1i1\nK4MurRry3h0R9NVa9SLVRoUvNcpay/a04/xt8XZW7cqgbZO6/GFYV+69tBP1avs7HU/Eq6nwpcZk\n5hRy15wYtqQco1GdWjxzXQ/GDepALX8/p6OJ+AQVvlQ7ay0frtvLtCU7ySsq4e5LQrh/6MW0aFjH\n6WgiPsWlwjfGjABeB/yBWdbaF8+w3U3AAmCAtXZDlaUUjxW7P4unvopl075j9G3flBdG9dJlBkUc\nUmnhG2P8gRnAMCAViDHGRFtr40/ZrhHwX8CP1RFUPEtxSSkzVuzmrRW7qFvLn6eu7cGdv+mIv86p\nF3GMK3v4kUCitTYJwBgzH4gC4k/Z7jngJeCxKk0oHif+QDYPzdvE7sM5XNO7LVOvD6O5pm9EHOdK\n4QcCKRXupwIDK25gjOkHtLfWLjTGnLHwjTGTgEkAwcG61qi3KS21fLB2D68uS6BBHX/evr0fv+vZ\nRufUi7iJCz5oa4zxA14BJlS2rbV2JjATICIiwl7o9xb3UVpquffDDSzfkc6lXVrwwqhetG9W3+lY\nIlKBK4W/H6j4Gfeg8sd+0QjoCaws35NrA0QbY67XgVvfcDSnkIfnb2bVrgweuaorD/+2s/bqRdyQ\nK4UfA3QxxoRQVvS3AWN/edJamwX8eiFRY8xK4FGVvW9YGneQx/8dS1ZeIVOjwhg/qIPKXsRNVVr4\n1tpiY8xkYAllp2XOttbGGWOmAhustdHVHVLcz/H8IqYvTWDO2j30aNuYj+6O1BLGIm7OpTl8a+0i\nYNEpjz11hm2HXngscWf/3pzKs1/Hcyy3iNsGtGdqVE9q19KnZUXcnT5pK+dk3k/7+PMX2+jbvin/\nPboLl3dtqSkcEQ+hwpdK/bKy5byf9vHd9nQubtmAj+6OpFHdAKejicg5UOHLWcXsyeSVpQmsSzpC\nozq1uPfSECZf2UVlL+KBVPhyWoXFpUxftpN3/zcJgKlRYYyJDCZAK1uKeCwVvvyHklLL9KU7+Xxj\nKoePF3Bplxa8NrqvlkYQ8QIqfPlVTkEx98zdwLqkI1zWtSV/vyWEy7q00EFZES+hwhcAtqdl89w3\n8axLOsKjV3flwSv0aVkRb6PC93G5hcX8c/0+pi3dibWWp6/rwV1DQpyOJSLVQIXvo6y1RG85wEuL\nd3AgK58hnZvz91v60LZJPaejiUg1UeH7mCMnCnhj+S6+2Lyf4/nFhLVrzPRb+zKoUzNN4Yh4ORW+\njziWW8i7PyTxz/V7ySsq4fKuLRnZqy039A3ET1ehEvEJKnwfkHT4BA9+spntadkM69Gax4aH0rV1\nI6djiUgNU+F7seKSUl5fvosP1uyhsKSUWXdEcFWP1k7HEhGHqPC91E/Jmfzpi60kHc4hMqQZL4zq\nSedW2qsX8WUqfC+TX1TCy9/uZPaaZOoG+PHijb0YPaC9DsiKiArfmxSXlPLkl7Es2JjK2IHB/M/w\nbjSpr0XORKSMCt9LZJwo4MF/buLH5EzGRLbnhVG9nI4kIm5Ghe8FMk4UMPa99ezJyGVqVBi3D+zg\ndCQRcUMqfA+3bvcR/mv+Zo7lFfHenRFc3rWl05FExE2p8D1U/IFsXvsugWXbDxHSvAFz7oqkRztd\nRFxEzkyF74GWxR9i8iebqFfbn/suu5iHruxMgzr6UYrI2aklPEhuYTFvfp/IP1bupnOrhnw6aZAu\nTCIiLlPhe4gtKce484OfOJZbxIiwNjwbFaayF5FzosL3AFtSjnH33Bjq1PLjs/sGExnSzOlIIuKB\nVPhuLL+ohBcX7+DTmBQC/A2f//43hLbR8ggicn5U+G5qadxBnvgylsPHC7ihbzse/m0XOrVs6HQs\nEfFgKnw3Yq3lw3V7eW9VEqlH8+jQvD4f3DWAK0JbOR1NRLyACt9NFJeUMn1ZAv9YuZuegY0ZFR7I\ng1d0pm6Av9PRRMRLqPDdQH5RCRM++In1SZnc2C+Ql2/qTS1/P6djiYiXUeE77GhOIQ/P38z6pEye\nvKY791zayelIIuKlVPgOKS21zF6TzHurksjMKeRvN/ZiTGSw07FExIup8B2QnV/ElM+38m3cQXoH\nNWHWHQPoFdTE6Vgi4uVU+DXsu/hD/Pnf2zh8vIBHrurKw7/trKtRiUiNUOHXkOKSUqYt2cm7PyRx\nUf0APr57IJd0aeF0LBHxIS4VvjFmBPA64A/Msta+eMrzfwDuAYqBw8BEa+3eKs7qsVbtOsxb3yfy\nY3ImkSHNeG10X9o1red0LBHxMZUWvjHGH5gBDANSgRhjTLS1Nr7CZpuBCGttrjHmfuBlYHR1BPYk\nOQXF/HXhdub9tI8Gtf11Fo6IOMqVPfxIINFamwRgjJkPRAG/Fr61dkWF7dcD46oypCc6cqKAa99c\nTVpWPtf0asu0W3pTv7Zm0ETEOa40UCCQUuF+KjDwLNvfDSw+3RPGmEnAJIDgYO89BTGvsIQHP9nE\noex83hgTzvV92jkdSUSEKv04pzFmHBABTDvd89bamdbaCGttRMuW3nnt1ez8IsbOWs+PyZn85doe\nKnsRcRuu7OHvB9pXuB9U/th/MMZcBTwBXG6tLaiaeJ4lp6CYuz6IYVtqFq+N7ktU30CnI4mI/MqV\nwo8BuhhjQigr+tuAsRU3MMaEA+8CI6y16VWe0gPsP5bHmJnrSTmay5tjwrm2t/bsRcS9VFr41tpi\nY8xkYAllp2XOttbGGWOmAhustdGUTeE0BD4v/xDRPmvt9dWY263kFhZz/8cbOZpbyPx7BzGwU3On\nI4mI/D8unTZirV0ELDrlsacq3L6qinN5jO1p2fzpi21s25/FO+P6q+xFxG3pPMHzlHT4BDNW7ObL\nn/djreUv1/RgeFgbp2OJiJyRCv8cWWv5fGMqLy3eQXZ+EbdGBDFleDcualDb6WgiImelwj8HKZm5\nvLh4Bwu3pdEnqAnPj4qkZ6BWuRQRz6DCd9Gx3EJu/MdaDh8v4IGhF/Po1aH4+WmVSxHxHCr8Slhr\nmbt2D9OW7CSnsITXRvflhnCdXy8inkeFfxbxB7J56qtYNuw9Sli7xkyNCqN/h2ZOxxIROS8q/DOY\nvTqZ5xdtp5af4bHhodx3WSddWFxEPJoK/xTWWh7/9zbm/ZTC4E7NeX1MX1o1qut0LBGRC6bCryCv\nsIRHF2xh4dY0bo0IYmpUT+oG+DsdS0SkSqjwy6Vn5zNxbgyx+7P5w7CuTL6is87CERGvosIHSkot\nN72zlvTsAq1fLyJey+cLP7+ohPs/3khKZh6v3NpHZS8iXstnC7+4pJT5MSm8sXwX6ccLmDIilFE6\nv15EvJhPFn5i+nGe/TqeVbsyCG3diOdu6KmFz0TE6/lU4a9POsJTX8WScOgEfgZ+f/nFPDY8FH8d\nnBURH+Azhb8s/hC//3gj7ZrW5YmR3YkKb6fz60XEp/hE4W/ce5Q/fvYzXVo15IO7BtC2ST2nI4mI\n1DivXyvgi02p3PzOWiww4/Z+KnsR8Vleu4dvreX91cn8bfEOQls34tP7BtOkXoDTsUREHOOVhX8s\nt5Cp38Tzxab9hAc35Z1x/VX2IuLzvK7wV+06zH/P/5ljeUWMjmjPs1FhWg9HRAQvK/xvYw/y8LzN\nBF1Ujw/vjiSsnS4/KCLyC68ofGstK3ce5uH5m+nethFzJ0bStL4uKi4iUpHHF/7W1GM8+3U8G/ce\npXXjOrwxJlxlLyJyGh5d+Ct3pjPpw40YA/dcEsKjw0M1Xy8icgYeW/ifb0hhyr+2EtK8AR/fM5B2\nTXV+vYjI2Xhk4c9enczUb+IZ0rk5790RQf3aHvnXEBGpUR7VlKWllnd/SOLlJTvo274p745X2YuI\nuMoj2jKvsIS3Vybyr42pHMjKp1ubRnx8z0Aa1vGI+CIibsHtGzN2fxaPLdjK9rRsLu/akj+P7M7V\nYa2pU0sHZ0VEzoVbF/5H6/bwl6/iaFo/gFl3RHBVj9ZORxIR8VhuWfgFxSXMWpXM9KU7GRrakldv\n7ctFDXRuvYjIhXC7wt+TkcPD8zezNTWLQZ2aMWNsPxporl5E5IK5VZOuTcxg4twYDIa/3diLMZHB\nTkcSEfEablH4ieknePbrOFbtyqBj8/p8fM9Agi6q73QsERGv4lLhG2NGAK8D/sAsa+2LpzxfB/gQ\n6A8cAUZba/dU9rqzViXx9dY0tqQco2GdWjx6dVfGRAbTvGGdc/17iIhIJSotfGOMPzADGAakAjHG\nmGhrbXyFze4GjlprOxtjbgNeAkaf7XX3HMnhrwu3Ex7clIlDQrj70hACtTyCiEi1cWUPPxJItNYm\nARhj5gNRQMXCjwKeKb+9AHjLGGOstfZML3o8v5jp14dxx+AOGGPOK7yIiLjOlcIPBFIq3E8FBp5p\nG2ttsTEmC2gOZFTcyBgzCZhUfrdgwpCQ2AnnEdoLteCUsfJhGouTNBYnaSxOCj3fL6zRg7bW2pnA\nTABjzAZrbURNfn93pbE4SWNxksbiJI3FScaYDef7tX4ubLMfaF/hflD5Y6fdxhhTC2hC2cFbERFx\nE64UfgzQxRgTYoypDdwGRJ+yTTRwZ/ntm4HvzzZ/LyIiNa/SKZ3yOfnJwBLKTsucba2NM8ZMBTZY\na6OB94GPjDGJQCZlvxQqM/MCcnsbjcVJGouTNBYnaSxOOu+xMNoRFxHxDa5M6YiIiBdQ4YuI+Ihq\nL3xjzAhjzE5jTKIx5k+neb6OMebT8ud/NMZ0rO5MTnFhLP5gjIk3xmw1xiw3xnRwImdNqGwsKmx3\nkzHGGmO89pQ8V8bCGHNr+XsjzhjzSU1nrCku/BsJNsasMMZsLv93MtKJnNXNGDPbGJNujIk9w/PG\nGPNG+ThtNcb0c+mFrbXV9oeyg7y7gU5AbWAL0OOUbR4A3im/fRvwaXVmcuqPi2NxBVC//Pb9vjwW\n5ds1An4A1gMRTud28H3RBdgMXFR+v5XTuR0ci5nA/eW3ewB7nM5dTWNxGdAPiD3D8yOBxYABBgE/\nuvK61b2H/+uyDNbaQuCXZTQR3KAAAAJHSURBVBkqigLmlt9eAPzWeOdaC5WOhbV2hbU2t/zueso+\n8+CNXHlfADxH2bpM+TUZroa5Mhb3AjOstUcBrLXpNZyxprgyFhZoXH67CXCgBvPVGGvtD5Sd8Xgm\nUcCHtsx6oKkxpm1lr1vdhX+6ZRkCz7SNtbYY+GVZBm/jylhUdDdlv8G9UaVjUf5f1PbW2oU1GcwB\nrrwvugJdjTFrjDHry1ev9UaujMUzwDhjTCqwCHioZqK5nXPtE8BN1sOX/2SMGQdEAJc7ncUJxhg/\n4BVggsNR3EUtyqZ1hlL2v74fjDG9rLXHHE3ljDHAHGvtdGPMYMo+/9PTWlvqdDBPUN17+FqW4SRX\nxgJjzFXAE8D11tqCGspW0yobi0ZAT2ClMWYPZXOU0V564NaV90UqEG2tLbLWJgMJlP0C8DaujMXd\nwGcA1tp1QF3KFlbzNS71yamqu/C1LMNJlY6FMSYceJeysvfWeVqoZCystVnW2hbW2o7W2o6UHc+4\n3lp73otGuTFX/o18SdnePcaYFpRN8STVZMga4spY7AN+C2CM6U5Z4R+u0ZTuIRq4o/xsnUFAlrU2\nrbIvqtYpHVt9yzJ4HBfHYhrQEPi8/Lj1Pmvt9Y6FriYujoVPcHEslgBXG2PigRLgMWut1/0v2MWx\n+CPwnjHmEcoO4E7wxh1EY8w8yn7Jtyg/XvE0EABgrX2HsuMXI4FEIBe4y6XX9cKxEhGR09AnbUVE\nfIQKX0TER6jwRUR8hApfRMRHqPBFRHyECl9ExEeo8EVEfMT/ARLEP2QAx4OCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.47170960141979185\n",
            "Time:  71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5p7NRhm75L-",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSymEs6-76Tf",
        "colab_type": "code",
        "outputId": "a3725bbe-0016-43b4-c74b-ac704d695bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "mlp = MLP_AnomalyDetection.from_DataFrame(df_synthetic,100,5,30,0.3,'euclidean')\n",
        "mlp.fit()\n",
        "# mlp.plot()\n",
        "mlp.get_roc_auc(verbose=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 798 samples, validate on 79 samples\n",
            "Epoch 1/30\n",
            "798/798 [==============================] - 23s 28ms/step - loss: 1.1117 - val_loss: 0.9875\n",
            "Epoch 2/30\n",
            "798/798 [==============================] - 0s 229us/step - loss: 0.6231 - val_loss: 1.0700\n",
            "Epoch 3/30\n",
            "798/798 [==============================] - 0s 234us/step - loss: 0.3158 - val_loss: 1.1222\n",
            "Epoch 4/30\n",
            "798/798 [==============================] - 0s 239us/step - loss: 0.1193 - val_loss: 1.1202\n",
            "Epoch 5/30\n",
            "798/798 [==============================] - 0s 251us/step - loss: 0.0500 - val_loss: 1.1368\n",
            "Epoch 6/30\n",
            "798/798 [==============================] - 0s 243us/step - loss: 0.0280 - val_loss: 1.1368\n",
            "Epoch 7/30\n",
            "798/798 [==============================] - 0s 237us/step - loss: 0.0222 - val_loss: 1.1321\n",
            "Epoch 8/30\n",
            "798/798 [==============================] - 0s 227us/step - loss: 0.0216 - val_loss: 1.1225\n",
            "Epoch 9/30\n",
            "798/798 [==============================] - 0s 242us/step - loss: 0.0193 - val_loss: 1.1323\n",
            "Epoch 10/30\n",
            "798/798 [==============================] - 0s 253us/step - loss: 0.0200 - val_loss: 1.1160\n",
            "Epoch 11/30\n",
            "798/798 [==============================] - 0s 239us/step - loss: 0.0199 - val_loss: 1.1201\n",
            "Epoch 12/30\n",
            "798/798 [==============================] - 0s 243us/step - loss: 0.0221 - val_loss: 1.1201\n",
            "Epoch 13/30\n",
            "798/798 [==============================] - 0s 247us/step - loss: 0.0225 - val_loss: 1.1218\n",
            "Epoch 14/30\n",
            "798/798 [==============================] - 0s 249us/step - loss: 0.0231 - val_loss: 1.1093\n",
            "Epoch 15/30\n",
            "798/798 [==============================] - 0s 248us/step - loss: 0.0216 - val_loss: 1.1164\n",
            "Epoch 16/30\n",
            "798/798 [==============================] - 0s 243us/step - loss: 0.0208 - val_loss: 1.1087\n",
            "Epoch 17/30\n",
            "798/798 [==============================] - 0s 247us/step - loss: 0.0200 - val_loss: 1.1098\n",
            "Epoch 18/30\n",
            "798/798 [==============================] - 0s 245us/step - loss: 0.0177 - val_loss: 1.1003\n",
            "Epoch 19/30\n",
            "798/798 [==============================] - 0s 243us/step - loss: 0.0162 - val_loss: 1.1053\n",
            "Epoch 20/30\n",
            "798/798 [==============================] - 0s 252us/step - loss: 0.0169 - val_loss: 1.0913\n",
            "Epoch 21/30\n",
            "798/798 [==============================] - 0s 252us/step - loss: 0.0159 - val_loss: 1.0937\n",
            "Epoch 22/30\n",
            "798/798 [==============================] - 0s 235us/step - loss: 0.0158 - val_loss: 1.0848\n",
            "Epoch 23/30\n",
            "798/798 [==============================] - 0s 243us/step - loss: 0.0164 - val_loss: 1.0929\n",
            "Epoch 24/30\n",
            "798/798 [==============================] - 0s 235us/step - loss: 0.0159 - val_loss: 1.1007\n",
            "Epoch 25/30\n",
            "798/798 [==============================] - 0s 254us/step - loss: 0.0148 - val_loss: 1.0765\n",
            "Epoch 26/30\n",
            "798/798 [==============================] - 0s 250us/step - loss: 0.0137 - val_loss: 1.0802\n",
            "Epoch 27/30\n",
            "798/798 [==============================] - 0s 239us/step - loss: 0.0129 - val_loss: 1.0852\n",
            "Epoch 28/30\n",
            "798/798 [==============================] - 0s 242us/step - loss: 0.0140 - val_loss: 1.0788\n",
            "Epoch 29/30\n",
            "798/798 [==============================] - 0s 237us/step - loss: 0.0139 - val_loss: 1.0778\n",
            "Epoch 30/30\n",
            "798/798 [==============================] - 0s 243us/step - loss: 0.0138 - val_loss: 1.0723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3wU9b3/8deHa7jEcEu9cAsqRwiC\ngClqqQWUetBW/KFUQbDV1lI9tba1p49StdbS+jhqPZbi4XhKW20tUUr1eMdyepQWPbZIsIgiUhAB\ng8hNQRBQEj6/P76TZAmbzSZks2zm/Xw85rEzs9+d+c5uMu/9fmd2xtwdERGJr1bZroCIiGSXgkBE\nJOYUBCIiMacgEBGJOQWBiEjMKQhERGJOQSBNysxam9keM+vTlGWzycxONrMmP8/azMaa2fqE6dVm\ndnY6ZRuxrl+Z2Y2NfX2K5f7EzH7T1MuV5tUm2xWQ7DKzPQmTHYGPgMpo+mvuXtqQ5bl7JdC5qcvG\ngbuf0hTLMbOrganuPjph2Vc3xbKlZVIQxJy7V++Io2+cV7v7/9ZV3szauHtFc9RNRJqHuoYkpajp\n/3sze8jMdgNTzewsM/ubme00s81mNsvM2kbl25iZm1lRND03ev4ZM9ttZn81s34NLRs9f76Z/cPM\ndpnZPWb2f2Z2ZR31TqeOXzOztWb2vpnNSnhtazP7mZntMLN1wLgU789NZjav1rzZZnZ3NH61ma2K\ntufN6Nt6XcsqN7PR0XhHM/tdVLeVwOm1yt5sZuui5a40s/HR/MHAfwBnR91u2xPe21sTXn9NtO07\nzOwxMzs+nfemPmY2IarPTjN7zsxOSXjuRjN7x8w+MLM3Erb1TDN7OZq/xcx+mu76pIm4uwYNuDvA\nemBsrXk/AT4GLiR8cegAfBI4g9CiPBH4B3BdVL4N4EBRND0X2A6UAG2B3wNzG1H2E8Bu4KLouRuA\nA8CVdWxLOnV8HCgAioD3qrYduA5YCfQCugOLw79K0vWcCOwBOiUseytQEk1fGJUx4BxgHzAkem4s\nsD5hWeXA6Gj8LuDPQFegL/B6rbKXAsdHn8nlUR2OjZ67GvhzrXrOBW6Nxs+L6jgUyAP+E3gunfcm\nyfb/BPhNND4wqsc50Wd0I7A6Gh8EbACOi8r2A06MxpcCk6PxfOCMbP8vxG1Qi0DS8YK7P+nuB919\nn7svdfcl7l7h7uuAOcCoFK9/2N3L3P0AUErYATW07OeB5e7+ePTczwihkVSadfw3d9/l7usJO92q\ndV0K/Mzdy919B3B7ivWsA14jBBTAZ4H33b0sev5Jd1/nwXPAs0DSA8K1XAr8xN3fd/cNhG/5ieud\n7+6bo8/kQUKIl6SxXIApwK/cfbm77wemA6PMrFdCmbrem1QmAU+4+3PRZ3Q7IUzOACoIoTMo6l58\nK3rvIAR6fzPr7u673X1JmtshTURBIOl4O3HCzAaY2dNm9q6ZfQDMAHqkeP27CeN7SX2AuK6yJyTW\nw92d8A06qTTrmNa6CN9kU3kQmByNXx5NV9Xj82a2xMzeM7OdhG/jqd6rKsenqoOZXWlmr0RdMDuB\nAWkuF8L2VS/P3T8A3gd6JpRpyGdW13IPEj6jnu6+GvgO4XPYGnU1HhcVvQooBlab2UtmdkGa2yFN\nREEg6ah96uQvCN+CT3b3Y4BbCF0fmbSZ0FUDgJkZh+64ajuSOm4GeidM13d663xgrJn1JLQMHozq\n2AF4GPg3QrdNF+B/0qzHu3XVwcxOBO4FrgW6R8t9I2G59Z3q+g6hu6lqefmELqhNadSrIcttRfjM\nNgG4+1x3H0noFmpNeF9w99XuPonQ/ffvwCNmlneEdZEGUBBIY+QDu4APzWwg8LVmWOdTwHAzu9DM\n2gDfBAozVMf5wLfMrKeZdQe+l6qwu78LvAD8Bljt7muip9oD7YBtQKWZfR44twF1uNHMulj4ncV1\nCc91JuzstxEy8auEFkGVLUCvqoPjSTwEfMXMhphZe8IO+Xl3r7OF1YA6jzez0dG6v0s4rrPEzAaa\n2Zhoffui4SBhA64wsx5RC2JXtG0Hj7Au0gAKAmmM7wBfIvyT/4JwUDej3H0LcBlwN7ADOAn4O+F3\nD01dx3sJffmvEg5kPpzGax4kHPyt7hZy953At4FHCQdcJxICLR0/JLRM1gPPAA8kLHcFcA/wUlTm\nFCCxX/1PwBpgi5kldvFUvf6PhC6aR6PX9yEcNzgi7r6S8J7fSwipccD46HhBe+BOwnGddwktkJui\nl14ArLJwVtpdwGXu/vGR1kfSZ6GrVSS3mFlrQlfERHd/Ptv1EcllahFIzjCzcVFXSXvgB4SzTV7K\ncrVEcp6CQHLJp4F1hG6HfwYmuHtdXUMikiZ1DYmIxJxaBCIiMZdzF53r0aOHFxUVZbsaIiI5Zdmy\nZdvdPekp1zkXBEVFRZSVlWW7GiIiOcXM6vyFvLqGRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQE\nIiIxpyAQEYm5nPsdQS5yhzfegGefha1b039dfj706AHdu4fHqqFLF2ilCBeRJqIgyJBt2+B//xf+\n9KcwlEe3/LA075GV6hJQrVpBt26HBsRJJ8GAAWE45RQoLEx/XVXr27wZVq0KobVqVdiGs86CsWNh\n0KCGLU9EcoeCoIns2wcvvFCz41++PMzv2hXOPRc++9kw9OuX3vLcYc8e2LEDtm8PQ13ja9fCwoWw\nf3/N67t2rQmGqnAYMAD69IGNG2t29lU7/jfegA8+qHl9fn5Yxvz5YfrYY8N2nHtuCIY+9d28UURy\nRs5dfbSkpMQzeYmJjz+Gb34T/vAHaN8e8vKgQ4eax2Tj69bB88+HHXHbtvCpT8F554Ud//Dh0Lp1\nxqpb7eDBmh181bB6dXh897B7VNU44QQYODCEROLj8ceHFsCGDaFLq2rYsiW8rn//mlAYMya0UCAE\n2AcfwPvv1wzvvXfo+L59yeuSrMVRUQEffVQz7N+ffPyjj6BnTygpqRlOOkldaCJVzGyZu5ckfU5B\nUOO99+CSS+DPf4ZJk6Bz57DT2r//0Mfa8woLww7xs5+Fz3wmvO5osnNnTShs3Bi+zQ8cGFoJBQXp\nL8cdVq4MXV7PPhvepz17wg68b1/YvTusq7Ky7mW0bQsdOx6+06/rz7BVqxC27dvXBHPVeOK8du3g\nrbdCS6yqZVRQAKeffmg4FBUduu6DB0NQbtwIb7996OPGjeG5wsLwusShb9/w2KVL+u+fSDYpCNLw\nj3/A5z8fvgHfdx9MOeI7uLZ8Bw7A0qUhGFavDjvFrl1rhm7dDp9OFgJNXafXX4eyspphxYrQ0oNQ\nh2HDQrmNG8Oxm4qKQ5fRuXMIyz594LjjQvfb+vUhaD788NCyBQU14dCzZ9i2AwfCMlM9tmkTWixV\nXXannBLWpxaMZIqCoB6LFoWWQJs28OijMHJkky5esuzjj+G112qCYfny0K3Xpw/07n34Y0FB8rBy\nD63G9euTD5s2hR15mzah5VP7MXH8o4/Cl49du2qWn5cH//RPIRQSA+ITnwjHhLZtC8P27TXjtac7\ndAgH+D/1qTAMHRpaS7ls377wPh13XLZrktsUBCn8+tdwzTXhH/Cpp9I/mCtypNzD6cSrV9d03VWN\nr1sXuq3q0qpVOFussLDmsbAwHIf5619DyxZCuHzykzXBcNZZodzRZP/+UN/EUH3rrZrxquNSI0bA\n1VeHbtv8/KxVN2cpCJKorITvfx9++tNwYHf+/Ib1l4tk0kcfwZtvhlDYvr3mNOGqHX7Xrqm7kTZt\nCoHw4othePnl0CUF4UD/pz4VThTYu7dm2Lcv+fjeveFU5f79w3DyyTXjPXvW351VWRm64NatCzv4\nt96qGV+/Ppy2nKht29A669evptutdWuYOzcco+rUCS67LITCmWfqtOZ0KQhq+fDDcAzg8cfhX/4F\nfv7z0GQXaan27YNly2qC4cUXQ+uhY8fDhw4dDp3OywstlzVrQjh99FHNcvPywrGOqmA48cSw3MQd\n/saNhx6HadUq7OiLisLOPnGH369fOGMt2Zl27rBkCfzqVzBvXvg/Li4OgXDFFSEom4J76IpK7H7b\nti0EzgknhPA74YQQjrkUQgqCBOXlMH48vPIKzJwJ3/hGE1ZOpIU7eDD8D61ZUzOsXVsTElUH5QsL\nw079xBNrdvZV4717h2/9R2L37tCK/9Wv4G9/C8ubMCGEwrnnhrDZvz+cxbZrV93De+8dfrxl+/aa\n1lMq7dvXBENVOFSNFxSEMGvTJvmQ+FzVyRSZDhUFQWTZshACu3eHbxQXXNDElROJscrK0M3TpUvz\nnkL92mvhWN8DD4Qde35+aLVUhVIqBQU13W31DQcPwjvvhG63TZsOHa8a6vqNTH3atAknBRx7bBgS\nxxOn+/WDY45p3DoUBMBjj8Hll4c39MknYfDgDFRORLJm//7Q3bt4cQiigoIQSgUFyYf8/Kb9sWdV\nl9KmTeH3NRUVYaisrBmvPRw4ELrStmwJw9atNeNbthweZrNnh+7sxkgVBLHpGW/XLvzK95FHQrKK\nSMuSlxcOIl92WXbWbxaCp6l+ZFgVLInhMHRo0yy7tti0CCC8sbl0cEdEpKmkahHE6neMCgERkcPF\nKghERORwCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYm5jAWBmd1nZlvN7LU6njczm2Vma81shZkN\nz1RdRESkbplsEfwGGJfi+fOB/tEwDbg3g3UREZE6ZCwI3H0x8F6KIhcBD3jwN6CLmR2fqfqIiEhy\n2TxG0BN4O2G6PJp3GDObZmZlZla2bdu2ZqmciEhc5MTBYnef4+4l7l5SeLTdZ09EJMdlMwg2Ab0T\npntF80REpBllMwieAL4YnT10JrDL3TfX9yIREWlaGbsfgZk9BIwGephZOfBDoC2Au/8XsAC4AFgL\n7AWuylRdRESkbhkLAnefXM/zDnw9U+sXEZH05MTBYhERyRwFgYhIzCkIRERiTkEgIhJzCgIRkZhT\nEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCIiMScgkBEJOYUBCIi\nMacgEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzGU0\nCMxsnJmtNrO1ZjY9yfN9zGyRmf3dzFaY2QWZrI+IiBwuY0FgZq2B2cD5QDEw2cyKaxW7GZjv7sOA\nScB/Zqo+IiKSXCZbBCOAte6+zt0/BuYBF9Uq48Ax0XgB8E4G6yMiIklkMgh6Am8nTJdH8xLdCkw1\ns3JgAfCNZAsys2lmVmZmZdu2bctEXUVEYivbB4snA79x917ABcDvzOywOrn7HHcvcfeSwsLCZq+k\niEhLlskg2AT0TpjuFc1L9BVgPoC7/xXIA3pksE4iIlJLJoNgKdDfzPqZWTvCweAnapXZCJwLYGYD\nCUGgvh8RkWaUsSBw9wrgOmAhsIpwdtBKM5thZuOjYt8BvmpmrwAPAVe6u2eqTiIicrg2mVy4uy8g\nHAROnHdLwvjrwMhM1kFERFLL9sFiERHJMgWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTm\nFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGI\nSMxl9FaVIpL7Dhw4QHl5Ofv37892VSQNeXl59OrVi7Zt26b9GgWBiKRUXl5Ofn4+RUVFmFm2qyMp\nuDs7duygvLycfv36pf06dQ2JSEr79++ne/fuCoEcYGZ07969wa03BYGI1EshkDsa81kpCETkqLZj\nxw6GDh3K0KFDOe644+jZs2f19Mcff5zWMq666ipWr16dsszs2bMpLS1tiirz6U9/muXLlzfJsppD\nLIKgtBSKiqBVq/DYRJ+1iCTR1P9v3bt3Z/ny5SxfvpxrrrmGb3/729XT7dq1A0Lf+MGDB+tcxv33\n388pp5yScj1f//rXmTJlypFVNke1+CAoLYVp02DDBnAPj9OmKQxEMqE5/9/Wrl1LcXExU6ZMYdCg\nQWzevJlp06ZRUlLCoEGDmDFjRnXZqm/oFRUVdOnShenTp3Paaadx1llnsXXrVgBuvvlmZs6cWV1+\n+vTpjBgxglNOOYUXX3wRgA8//JBLLrmE4uJiJk6cSElJSb3f/OfOncvgwYM59dRTufHGGwGoqKjg\niiuuqJ4/a9YsAH72s59RXFzMkCFDmDp1apO/Z3Vp8WcN3XQT7N176Ly9e8P8mIa/SMY09//bG2+8\nwQMPPEBJSQkAt99+O926daOiooIxY8YwceJEiouLD3nNrl27GDVqFLfffjs33HAD9913H9OnTz9s\n2e7OSy+9xBNPPMGMGTP44x//yD333MNxxx3HI488wiuvvMLw4cNT1q+8vJybb76ZsrIyCgoKGDt2\nLE899RSFhYVs376dV199FYCdO3cCcOedd7JhwwbatWtXPa85pNUiMLOTzKx9ND7azK43sy5pvG6c\nma02s7Vmdvg7Hcpcamavm9lKM3uwYdWv38aNDZsvIo3X3P9vJ510UnUIADz00EMMHz6c4cOHs2rV\nKl5//fXDXtOhQwfOP/98AE4//XTWr1+fdNkXX3zxYWVeeOEFJk2aBMBpp53GoEGDUtZvyZIlnHPO\nOfTo0YO2bdty+eWXs3jxYk4++WRWr17N9ddfz8KFCykoKABg0KBBTJ06ldLS0gb9DuBIpds19AhQ\naWYnA3OA3kDKnbaZtQZmA+cDxcBkMyuuVaY/8H1gpLsPAr7VsOrXr0+fhs0XkcZr7v+3Tp06VY+v\nWbOGn//85zz33HOsWLGCcePGJT2Nsuq4AkDr1q2pqKhIuuz27dvXW6axunfvzooVKzj77LOZPXs2\nX/va1wBYuHAh11xzDUuXLmXEiBFUVlY26Xrrkm4QHHT3CmACcI+7fxc4vp7XjADWuvs6d/8YmAdc\nVKvMV4HZ7v4+gLtvTb/q6bntNujY8dB5HTuG+SLStLL5//bBBx+Qn5/PMcccw+bNm1m4cGGTr2Pk\nyJHMnz8fgFdffTVpiyPRGWecwaJFi9ixYwcVFRXMmzePUaNGsW3bNtydL3zhC8yYMYOXX36ZyspK\nysvLOeecc7jzzjvZvn07e2v3s2VIuscIDpjZZOBLwIXRvPraLT2BtxOmy4EzapX5JwAz+z+gNXCr\nu/8xzTqlpapf8qabQvO0T5/wR6njAyJNL5v/b8OHD6e4uJgBAwbQt29fRo4c2eTr+MY3vsEXv/hF\niouLq4eqbp1kevXqxY9//GNGjx6Nu3PhhRfyuc99jpdffpmvfOUruDtmxh133EFFRQWXX345u3fv\n5uDBg/zrv/4r+fn5Tb4NyZi7118odOlcA/zV3R8ys37Ape5+R4rXTATGufvV0fQVwBnufl1CmaeA\nA8ClQC9gMTDY3XfWWtY0YBpAnz59Tt+wYUPDtlJEGm3VqlUMHDgw29U4KlRUVFBRUUFeXh5r1qzh\nvPPOY82aNbRpc3Sdd5PsMzOzZe5ekqx8WrV399eB66OFdQXyU4VAZBPhWEKVXtG8ROXAEnc/ALxl\nZv8A+gNLa61/DuHYBCUlJfUnl4hIBuzZs4dzzz2XiooK3J1f/OIXR10INEZaW2BmfwbGR+WXAVvN\n7P/c/YYUL1sK9I9aD5uAScDltco8BkwG7jezHoSuonUN2gIRkWbSpUsXli1blu1qNLl0DxYXuPsH\nwMXAA+5+BjA21Quig8vXAQuBVcB8d19pZjPMbHxUbCGww8xeBxYB33X3HY3ZEBERaZx02zRtzOx4\nQl/+Teku3N0XAAtqzbslYdyBG6JBRESyIN0WwQzCt/c33X2pmZ0IrMlctUREpLmke7D4D8AfEqbX\nAZdkqlIiItJ80r3ERC8ze9TMtkbDI2bWK9OVExEZM2bMYT8OmzlzJtdee23K13Xu3BmAd955h4kT\nJyYtM3r0aMrKylIuZ+bMmYf8sOuCCy5okusA3Xrrrdx1111HvJymkG7X0P3AE8AJ0fBkNE9EJKMm\nT57MvHnzDpk3b948Jk+enNbrTzjhBB5++OFGr792ECxYsIAuXeq91FpOSTcICt39fneviIbfAIUZ\nrJeICAATJ07k6aefrr4Jzfr163nnnXc4++yzq8/rHz58OIMHD+bxxx8/7PXr16/n1FNPBWDfvn1M\nmjSJgQMHMmHCBPbt21dd7tprr62+hPUPf/hDAGbNmsU777zDmDFjGDNmDABFRUVs374dgLvvvptT\nTz2VU089tfoS1uvXr2fgwIF89atfZdCgQZx33nmHrCeZ5cuXc+aZZzJkyBAmTJjA+++/X73+qstS\nV13s7i9/+Uv1jXmGDRvG7t27G/3eVkn3rKEdZjYVeCiangzoNE+RmPnWt6Cpb7w1dChE+9CkunXr\nxogRI3jmmWe46KKLmDdvHpdeeilmRl5eHo8++ijHHHMM27dv58wzz2T8+PF13q7x3nvvpWPHjqxa\ntYoVK1Ycchnp2267jW7dulFZWcm5557LihUruP7667n77rtZtGgRPXr0OGRZy5Yt4/7772fJkiW4\nO2eccQajRo2ia9eurFmzhoceeohf/vKXXHrppTzyyCMp7y/wxS9+kXvuuYdRo0Zxyy238KMf/YiZ\nM2dy++2389Zbb9G+ffvq7qi77rqL2bNnM3LkSPbs2UNeXl4D3u3k0m0RfJlw6ui7wGZgInDlEa9d\nRCQNid1Did1C7s6NN97IkCFDGDt2LJs2bWLLli11Lmfx4sXVO+QhQ4YwZMiQ6ufmz5/P8OHDGTZs\nGCtXrqz3gnIvvPACEyZMoFOnTnTu3JmLL76Y559/HoB+/foxdOhQIPWlriHcH2Hnzp2MGjUKgC99\n6UssXry4uo5Tpkxh7ty51b9gHjlyJDfccAOzZs1i586dTfLL5nTPGtpA+GVxNTP7FpAix0WkpUn1\nzT2TLrroIr797W/z8ssvs3fvXk4//XQASktL2bZtG8uWLaNt27YUFRUlvfR0fd566y3uuusuli5d\nSteuXbnyyisbtZwqVZewhnAZ6/q6hury9NNPs3jxYp588kluu+02Xn31VaZPn87nPvc5FixYwMiR\nI1m4cCEDBgxodF3hyG5VqR+BiUiz6Ny5M2PGjOHLX/7yIQeJd+3axSc+8Qnatm3LokWLqO+ClJ/5\nzGd48MFwK5XXXnuNFStWAOES1p06daKgoIAtW7bwzDPPVL8mPz8/aT/82WefzWOPPcbevXv58MMP\nefTRRzn77LMbvG0FBQV07dq1ujXxu9/9jlGjRnHw4EHefvttxowZwx133MGuXbvYs2cPb775JoMH\nD+Z73/sen/zkJ3njjTcavM7ajqRNkbwTTkQkAyZPnsyECRMOOYNoypQpXHjhhQwePJiSkpJ6vxlf\ne+21XHXVVQwcOJCBAwdWtyxOO+00hg0bxoABA+jdu/chl7CeNm0a48aN44QTTmDRokXV84cPH86V\nV17JiBEjALj66qsZNmxYym6guvz2t7/lmmuuYe/evZx44oncf//9VFZWMnXqVHbt2oW7c/3119Ol\nSxd+8IMfsGjRIlq1asWgQYOq77Z2JNK6DHXSF5ptdPdmv89XSUmJ13fer4g0HV2GOvc06WWozWw3\nkCwpDOjQ2EqKiMjRI2UQuHvz3B5HRESy5kgOFouISAugIBCRejX2WKI0v8Z8VgoCEUkpLy+PHTt2\nKAxygLuzY8eOBv/aOPdvtikiGdWrVy/Ky8vZtm1btqsiacjLy6NXr4ZdHFpBICIptW3bln79+mW7\nGpJB6hoSEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJuYwGgZmN\nM7PVZrbWzKanKHeJmbmZJb1pgoiIZE7GgsDMWgOzgfOBYmCymRUnKZcPfBNYkqm6iIhI3TLZIhgB\nrHX3de7+MTAPuChJuR8DdwD7M1gXERGpQyaDoCfwdsJ0eTSvmpkNB3q7+9OpFmRm08yszMzKdAVE\nEZGmlbWDxWbWCrgb+E59Zd19jruXuHtJYWFh5isnIhIjmQyCTUDvhOle0bwq+cCpwJ/NbD1wJvCE\nDhiLiDSvTAbBUqC/mfUzs3bAJOCJqifdfZe793D3IncvAv4GjHf3sgzWSUREaslYELh7BXAdsBBY\nBcx395VmNsPMxmdqvSIi0jAZvUOZuy8AFtSad0sdZUdnsi4iIpKcflksIhJzCgIRkZhTEIiIxJyC\nQEQk5hQEIiIxpyAQEYk5BUEtpaVQVAStWoXH0tJs10hEJLMy+juCXFNaCtOmwd69YXrDhjANMGVK\n9uolIpJJahEkuOmmmhCosndvmC8i0lIpCBJs3Niw+SIiLYGCIEGfPg2bLyLSEigIEtx2G3TseOi8\njh3DfBGRlkpBkGDKFJgzB/r2BbPwOGeODhSLSMums4ZqmTJFO34RiRe1CEREYk5BICIScwoCEZGY\nUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEXEaDwMzGmdlq\nM1trZtOTPH+Dmb1uZivM7Fkz65vJ+oiIyOEyFgRm1hqYDZwPFAOTzay4VrG/AyXuPgR4GLgzU/UR\nEZHkMtkiGAGsdfd17v4xMA+4KLGAuy9y96q7BP8N6JXB+oiISBKZDIKewNsJ0+XRvLp8BXgm2RNm\nNs3MysysbNu2bU1YRREROSoOFpvZVKAE+Gmy5919jruXuHtJYWFh81ZORKSFy+QdyjYBvROme0Xz\nDmFmY4GbgFHu/lEG6yMiIklkskWwFOhvZv3MrB0wCXgisYCZDQN+AYx3960ZrIuIiNQhY0Hg7hXA\ndcBCYBUw391XmtkMMxsfFfsp0Bn4g5ktN7Mn6liciIhkSEZvXu/uC4AFtebdkjA+NpPrFxGR+h0V\nB4tFRCR7FAQiIjGnIBARiTkFgYhIzCkIRERiTkFwBEpLoagIWrUKj6Wl2a6RiEjDZfT00ZastBSm\nTYO90SXzNmwI0wBTpmSvXiIiDaUWQSPddFNNCFTZuzfMFxHJJQqCRtq4sWHzRUSOVgqCRurTp2Hz\nRUSOVgqCRrrtNujY8dB5HSM2CPIAAAfnSURBVDuG+SIiuURB0EhTpsCcOdC3L5iFxzlzdKBYRHKP\nzho6AlOmaMcvIrlPLQIRkZhTEIiIxJyCQEQk5hQEIiIxpyBoJroukYgcrXTWUDPQdYlE5GimFkEz\n0HWJRORopiBoBroukYgczRQEzaCh1yXS8QQRaU4KgmbQkOsSVR1P2LAB3GuOJ9QVBg0JjVwKmExt\nV0t9v0SOiLvn1HD66ad7Lpo7171vX3ez8Dh3bvJyffu6hwg4dOjbN/kyO3Y8tFzHjsmX3dCy6dQ1\nU2UzuV0t8f1qyWUbskxJDSjzOvarWd+xN3TI1SBIl1nyIDA7vGxDQiPdskfDjjUT29WS36+WWrYh\ny6wqnysBl8mydVEQ5JCG7KwaEhrpls32jjVT29WS36+WWvZoaR3nUtlUshYEwDhgNbAWmJ7k+fbA\n76PnlwBF9S2zpQdBtr85Z3vHmqntasnvV0st21L/ZjJZNpWsBAHQGngTOBFoB7wCFNcq8y/Af0Xj\nk4Df17fclh4E7tntSz8a/piPhm9WufR+tdSyLbUVmcmyqWQrCM4CFiZMfx/4fq0yC4GzovE2wHbA\nUi03DkHQEE3dz5jtHWumtitTZY+G96ulls126zgXy6aSrSCYCPwqYfoK4D9qlXkN6JUw/SbQI8my\npgFlQFmfPn0atvXSYEfDTjiXHA3vV0stm83WcS6WTSXngyBxUItARJLJdmgdLWXrkioILDzf9Mzs\nLOBWd//naPr7AO7+bwllFkZl/mpmbYB3gUJPUamSkhIvKyvLSJ1FRFoqM1vm7iXJnsvkL4uXAv3N\nrJ+ZtSMcDH6iVpkngC9F4xOB51KFgIiINL2MXYba3SvM7DrCAeHWwH3uvtLMZhCaKE8AvwZ+Z2Zr\ngfcIYSEiIs0oo/cjcPcFwIJa825JGN8PfCGTdRARkdR00TkRkZhTEIiIxFzGzhrKFDPbBmzIdj2O\nQA/CD+dampa6XdByt03blXuOZNv6unthsidyLghynZmV1XUKVy5rqdsFLXfbtF25J1Pbpq4hEZGY\nUxCIiMScgqD5zcl2BTKkpW4XtNxt03blnoxsm44RiIjEnFoEIiIxpyAQEYk5BUEzMrP1ZvaqmS03\ns5y9hKqZ3WdmW83stYR53czsT2a2Jnrsms06NkYd23WrmW2KPrPlZnZBNuvYGGbW28wWmdnrZrbS\nzL4ZzW8Jn1ld25bTn5uZ5ZnZS2b2SrRdP4rm9zOzJWa21sx+H13Q88jXp2MEzcfM1gMl7p7TP3Yx\ns88Ae4AH3P3UaN6dwHvufruZTQe6uvv3slnPhqpju24F9rj7Xdms25Ews+OB4939ZTPLB5YB/w+4\nktz/zOratkvJ4c/NzAzo5O57zKwt8ALwTeAG4L/dfZ6Z/Rfwirvfe6TrU4tAGszdFxOuFpvoIuC3\n0fhvCf+MOaWO7cp57r7Z3V+OxncDq4CetIzPrK5ty2nRvWT2RJNto8GBc4CHo/lN9pkpCJqXA/9j\nZsvMbFq2K9PEjnX3zdH4u8Cx2axME7vOzFZEXUc5132SyMyKgGHAElrYZ1Zr2yDHPzcza21my4Gt\nwJ8Id3Dc6e4VUZFymij0FATN69PuPhw4H/h61BXR4kQ3F2opfY73AicBQ4HNwL9ntzqNZ2adgUeA\nb7n7B4nP5fpnlmTbcv5zc/dKdx8K9AJGAAMytS4FQTNy903R41bgUcKH21Jsifprq/ptt2a5Pk3C\n3bdE/5AHgV+So59Z1M/8CFDq7v8dzW4Rn1mybWspnxuAu+8EFgFnAV2i2/pCCIhNTbEOBUEzMbNO\n0cEszKwTcB7wWupX5ZTE245+CXg8i3VpMlU7ysgEcvAziw48/hpY5e53JzyV859ZXduW65+bmRWa\nWZdovAPwWcLxj0WE2/pCE35mOmuomZjZiYRWAIQ7wz3o7rdlsUqNZmYPAaMJl8TdAvwQeAyYD/Qh\nXCb8UnfPqQOvdWzXaEL3ggPrga8l9KvnBDP7NPA88CpwMJp9I6EvPdc/s7q2bTI5/LmZ2RDCweDW\nhC/s8919RrQfmQd0A/4OTHX3j454fQoCEZF4U9eQiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJA\nJGJmlQlXq1weXYitqZZdlHhVU5GjSZv6i4jExr7oJ/0isaIWgUg9ovtI3BndS+IlMzs5ml9kZs9F\nFzZ71sz6RPOPNbNHo2vJv2Jmn4oW1drMfhldX/5/ol+MYmbXR9fTX2Fm87K0mRJjCgKRGh1qdQ1d\nlvDcLncfDPwHMDOadw/wW3cfApQCs6L5s4C/uPtpwHBgZTS/PzDb3QcBO4FLovnTgWHRcq7J1MaJ\n1EW/LBaJmNked++cZP564Bx3Xxdd4Oxdd+9uZtsJN0U5EM3f7O49zGwb0Cvxp//RJZL/5O79o+nv\nAW3d/Sdm9kfCDXEeAx5LuA69SLNQi0AkPV7HeEMkXhOmkppjdJ8DZhNaD0sTri4p0iwUBCLpuSzh\n8a/R+IvApGh8CuHiZwDPAtdC9c1FCupaqJm1Anq7+yLge0ABcFirRCST9M1DpEaH6I5QVf7o7lWn\nkHY1sxWEb/WTo3nfAO43s+8C24CrovnfBOaY2VcI3/yvJdwcJZnWwNwoLAyYFV1/XqTZ6BiBSD2i\nYwQl7r4923URyQR1DYmIxJxaBCIiMacWgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxNz/B7chz/Sf\nke/CAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.6997358630952379\n",
            "Time:  38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcDsaP2-Amov",
        "colab_type": "code",
        "outputId": "2889a359-3e52-430b-dc69-bbb519472987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "mlp = MLP_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',None,100,9,30,0.3,'euclidean')\n",
        "mlp.fit()\n",
        "# mlp.plot()\n",
        "mlp.get_roc_auc(verbose=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14627 samples, validate on 1462 samples\n",
            "Epoch 1/30\n",
            "14627/14627 [==============================] - 3s 201us/step - loss: 1.1326 - val_loss: 0.7154\n",
            "Epoch 2/30\n",
            "14627/14627 [==============================] - 3s 181us/step - loss: 1.1176 - val_loss: 0.7161\n",
            "Epoch 3/30\n",
            "14627/14627 [==============================] - 3s 181us/step - loss: 1.1028 - val_loss: 0.7183\n",
            "Epoch 4/30\n",
            "14627/14627 [==============================] - 3s 176us/step - loss: 1.0564 - val_loss: 0.7478\n",
            "Epoch 5/30\n",
            "14627/14627 [==============================] - 3s 177us/step - loss: 1.0233 - val_loss: 0.7230\n",
            "Epoch 6/30\n",
            "14627/14627 [==============================] - 3s 178us/step - loss: 0.9856 - val_loss: 0.7284\n",
            "Epoch 7/30\n",
            "14627/14627 [==============================] - 3s 177us/step - loss: 0.9043 - val_loss: 0.7497\n",
            "Epoch 8/30\n",
            "14627/14627 [==============================] - 3s 179us/step - loss: 0.8125 - val_loss: 0.7341\n",
            "Epoch 9/30\n",
            "14627/14627 [==============================] - 3s 176us/step - loss: 0.8483 - val_loss: 0.7293\n",
            "Epoch 10/30\n",
            "14627/14627 [==============================] - 3s 177us/step - loss: 0.8996 - val_loss: 0.7533\n",
            "Epoch 11/30\n",
            "14627/14627 [==============================] - 3s 176us/step - loss: 0.8438 - val_loss: 0.7820\n",
            "Epoch 12/30\n",
            "14627/14627 [==============================] - 3s 177us/step - loss: 0.8167 - val_loss: 0.7674\n",
            "Epoch 13/30\n",
            "14627/14627 [==============================] - 3s 177us/step - loss: 0.7930 - val_loss: 0.7647\n",
            "Epoch 14/30\n",
            "14627/14627 [==============================] - 3s 176us/step - loss: 0.7627 - val_loss: 0.7732\n",
            "Epoch 15/30\n",
            "14627/14627 [==============================] - 3s 179us/step - loss: 0.7076 - val_loss: 0.7853\n",
            "Epoch 16/30\n",
            "14627/14627 [==============================] - 3s 175us/step - loss: 0.6990 - val_loss: 0.7881\n",
            "Epoch 17/30\n",
            "14627/14627 [==============================] - 3s 176us/step - loss: 0.6998 - val_loss: 0.8669\n",
            "Epoch 18/30\n",
            "14627/14627 [==============================] - 3s 179us/step - loss: 0.5872 - val_loss: 0.7395\n",
            "Epoch 19/30\n",
            "14627/14627 [==============================] - 3s 177us/step - loss: 0.6750 - val_loss: 0.7614\n",
            "Epoch 20/30\n",
            "14627/14627 [==============================] - 3s 177us/step - loss: 0.6112 - val_loss: 0.7716\n",
            "Epoch 21/30\n",
            "14627/14627 [==============================] - 3s 175us/step - loss: 0.6915 - val_loss: 0.7861\n",
            "Epoch 22/30\n",
            "14627/14627 [==============================] - 3s 178us/step - loss: 0.7540 - val_loss: 0.7722\n",
            "Epoch 23/30\n",
            "14627/14627 [==============================] - 3s 175us/step - loss: 0.7819 - val_loss: 0.7651\n",
            "Epoch 24/30\n",
            "14627/14627 [==============================] - 3s 176us/step - loss: 0.7639 - val_loss: 0.7817\n",
            "Epoch 25/30\n",
            "14627/14627 [==============================] - 3s 177us/step - loss: 0.7536 - val_loss: 0.7842\n",
            "Epoch 26/30\n",
            "14627/14627 [==============================] - 3s 177us/step - loss: 0.7340 - val_loss: 0.7936\n",
            "Epoch 27/30\n",
            "14627/14627 [==============================] - 3s 176us/step - loss: 0.7278 - val_loss: 0.7751\n",
            "Epoch 28/30\n",
            "14627/14627 [==============================] - 3s 180us/step - loss: 0.7324 - val_loss: 0.7735\n",
            "Epoch 29/30\n",
            "14627/14627 [==============================] - 3s 180us/step - loss: 0.7176 - val_loss: 0.7705\n",
            "Epoch 30/30\n",
            "14627/14627 [==============================] - 3s 177us/step - loss: 0.7075 - val_loss: 0.7677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwhcRCRAqfBGRAKHCFxEJECp8EZEA8f/IOCm6lWcfFQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.47635056535924913\n",
            "Time:  82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnH3vAaOv2JO",
        "colab_type": "text"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_62JcV1v3CG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "seed(42)\n",
        "from keras import regularizers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class CNN_AnomalyDetection:\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
        "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense,distance_function)\n",
        "     \n",
        "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function):\n",
        "        self.distance_function = distance_function\n",
        "        self.dimension = dimension\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "        \n",
        "        self.n_filters = n_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.n_dense = n_dense\n",
        "\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        # self.compute_Errors_RMSE()\n",
        "\n",
        "        return self.history.history\n",
        "\n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
        "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
        "\n",
        "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Conv1D(filters=self.n_filters[0], kernel_size=self.kernel_size, activation='relu', input_shape=(self.window_width,self.dimension ),data_format='channels_first', padding='same'))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Conv1D(filters=self.n_filters[1], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same'))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Conv1D(filters=self.n_filters[2], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same'))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Flatten())\n",
        "        self.model.add(Dense(self.n_dense, activation='relu'))\n",
        "        self.model.add(Dense(self.dimension))\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=0)\n",
        "\n",
        "        # self.plotTraining()\n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8], [4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "# best_auc = [0,0]\n",
        "# histories = []\n",
        "# for f in filters:\n",
        "#     for k in kernelsizes:\n",
        "#         for d in dense:\n",
        "\n",
        "#             cnn = CNN_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,f,k,d)\n",
        "#             hist = cnn.fit()\n",
        "#             histories.append(((f,k,d), hist))\n",
        "#             # cnn.plot()\n",
        "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#             if best_auc[1] < auc:\n",
        "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#                 best_auc = [(f,k,d),auc]\n",
        "#             break\n",
        "#         break\n",
        "#     break\n",
        "# print(best_auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gR7n1Tj4Azd",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiMRRPDH4CfY",
        "colab_type": "text"
      },
      "source": [
        "### Mahalanobis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgSIUWCB4GQV",
        "colab_type": "code",
        "outputId": "1b6e292d-db6b-41d7-a3a4-96b2d5075da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8],2,18, 'mahalanobis')\n",
        "hist = cnn.fit()\n",
        "histories.append(((f,k,d), hist))\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n",
        "#0.757626"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.921954470139039\n",
            "Time:  35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKDy0jyFAwmS",
        "colab_type": "code",
        "outputId": "fcbba22a-f889-460b-bef3-6da352257d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',None,30,9,20,0.3,[8,8,8],2,18, 'mahalanobis')\n",
        "hist = cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n",
        "#0.757626"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.46895499451271505\n",
            "Time:  58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ffTQKop4Eih",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l_QUTwl4FjC",
        "colab_type": "code",
        "outputId": "7899b8b1-72ce-4541-e74d-209c491ca8ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8],2,18, 'euclidean')\n",
        "hist = cnn.fit()\n",
        "histories.append(((f,k,d), hist))\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n",
        "#0.757626"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7735501765002522\n",
            "Time:  35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGsGIIdCA-Wg",
        "colab_type": "code",
        "outputId": "dd4e8468-e191-49df-801e-bff8ca215a61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',None,30,9,20,0.3,[8,8,8],2,18, 'euclidean')\n",
        "hist = cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n",
        "#0.757626"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.4760057352742635\n",
            "Time:  57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQDGfrzl86PG",
        "colab_type": "text"
      },
      "source": [
        "# CNN BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05RPy_NR851p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import keras \n",
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten, Input, BatchNormalization, Activation\n",
        "seed(42)\n",
        "from keras import regularizers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class CNN_Batch_AnomalyDetection:\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
        "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
        "     \n",
        "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function):\n",
        "\n",
        "        self.distance_function = distance_function\n",
        "        self.dimension = dimension\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "        \n",
        "        self.n_filters = n_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.n_dense = n_dense\n",
        "\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        # self.compute_Errors_RMSE()\n",
        "\n",
        "        return self.history.history\n",
        "\n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
        "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
        "\n",
        "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "\n",
        "        channel_pos = 'channels_first'\n",
        "        inp_shape = Input((self.window_width,self.dimension),name='input1')\n",
        "        x = Conv1D(self.n_filters[0], kernel_size=self.kernel_size, padding = 'same', input_shape=(self.window_width,self.dimension),data_format=channel_pos,name='conv2d_Prep')(inp_shape)\n",
        "        x = BatchNormalization(axis=1,name='batch_normalization_prep')(x)\n",
        "        x_a1 = Activation('relu',name='activation_prep')(x)\n",
        "        activated_x = x_a1\n",
        "\n",
        "        #     activated_x, x\n",
        "        nr = 1 *2 -1\n",
        "        x = Conv1D(self.n_filters[1], kernel_size=self.kernel_size, name = 'conv2d_'+str(nr), padding='same',data_format=channel_pos)(activated_x)\n",
        "        x = BatchNormalization(axis=1, name = 'batch_normalization_'+str(nr))(x)\n",
        "        activated_x = Activation('relu',name='activation_'+str(nr+1))(x)\n",
        "        activated_x = Flatten()(activated_x)\n",
        " \n",
        "        activated_x = Dense(self.n_dense)(activated_x)\n",
        "        output = Dense(self.dimension)(activated_x)\n",
        "\n",
        "        from keras.models import Model\n",
        "        self.model = Model(inp_shape,output )\n",
        "\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=0)\n",
        "\n",
        "        # self.plotTraining()\n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8], [4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "# best_auc = [0,0]\n",
        "# histories = []\n",
        "# for f in filters:\n",
        "#     for k in kernelsizes:\n",
        "#         for d in dense:\n",
        "\n",
        "#             cnn = CNN_Resnet_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,f,k,d)\n",
        "#             hist = cnn.fit()\n",
        "#             histories.append(((f,k,d), hist))\n",
        "#             # cnn.plot()\n",
        "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#             if best_auc[1] < auc:\n",
        "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#                 best_auc = [(f,k,d),auc]\n",
        "#             break\n",
        "#         break\n",
        "#     break\n",
        "# print(best_auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-ws_nH32NVI",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRSIoeqO2PGb",
        "colab_type": "text"
      },
      "source": [
        "### Mahalanobis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXKsdYLR3VUW",
        "colab_type": "code",
        "outputId": "293b5069-c300-4805-9d4d-43db9a76744a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_Batch_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8],2,18, 'mahalanobis')\n",
        "hist = cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n",
        "#0.757626"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8943627980693034\n",
            "Time:  36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QF_PTAQBD8Y",
        "colab_type": "code",
        "outputId": "97c1ab64-54f8-46ae-9626-f24ed05ee30d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_Batch_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,30,9,20,0.3,[8,8,8],2,18, 'mahalanobis')\n",
        "hist = cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n",
        "#0.757626"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "AUC:  0.47191968382218996\n",
            "Time:  84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_68oyXh63smW",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSlR7Q9_3t44",
        "colab_type": "code",
        "outputId": "c2373fef-e4b4-4071-c51b-913549319749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_Batch_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8],2,18, 'euclidean')\n",
        "hist = cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n",
        "#0.757626"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7555399466897197\n",
            "Time:  36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovUgTac2BN-5",
        "colab_type": "code",
        "outputId": "108d34d3-174b-44a1-dec8-c431733bc4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_Batch_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,30,9,20,0.3,[8,8,8],2,18, 'euclidean')\n",
        "hist = cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n",
        "#0.757626"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.47473441623186\n",
            "Time:  85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzusEAx47BPq",
        "colab_type": "text"
      },
      "source": [
        "# Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4ttY5es7CXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import keras \n",
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten, Input, BatchNormalization, Activation\n",
        "seed(42)\n",
        "from keras import regularizers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class CNN_Resnet_AnomalyDetection:\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
        "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
        "     \n",
        "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function):\n",
        "        self.distance_function =  distance_function\n",
        "        self.dimension = dimension\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "        \n",
        "        self.n_filters = n_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.n_dense = n_dense\n",
        "\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self, plot = False):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores(plot = plot)\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "        return self.history.history\n",
        "\n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compute_anomalyScores(self, plot = False):\n",
        "\n",
        "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
        "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
        "\n",
        "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "\n",
        "        channel_pos = 'channels_first'\n",
        "        inp_shape = Input((self.window_width,self.dimension),name='input1')\n",
        "        x = Conv1D(self.n_filters[0], kernel_size=self.kernel_size, padding = 'same', input_shape=(self.window_width,self.dimension),data_format=channel_pos,name='conv2d_Prep')(inp_shape)\n",
        "        x = BatchNormalization(axis=1,name='batch_normalization_prep')(x)\n",
        "        x_a1 = Activation('relu',name='activation_prep')(x)\n",
        "        activated_x = x_a1\n",
        "\n",
        "        #     activated_x, x\n",
        "        nr = 1 *2 -1\n",
        "        x = Conv1D(self.n_filters[1], kernel_size=self.kernel_size, name = 'conv2d_'+str(nr), padding='same',data_format=channel_pos)(activated_x)\n",
        "        x = BatchNormalization(axis=1, name = 'batch_normalization_'+str(nr))(x)\n",
        "        x = Activation('relu',name = 'activation_'+str(nr))(x)\n",
        "        x = Conv1D(self.n_filters[2], kernel_size=self.kernel_size, name = 'conv2d_'+str(nr+1),padding = 'same',data_format=channel_pos)(x)\n",
        "        x = BatchNormalization(axis=1, name = 'batch_normalization_'+str(nr+1))(x)\n",
        "        x = keras.layers.add([x,activated_x],name='add_' + str(1))\n",
        "        activated_x = Activation('relu',name='activation_'+str(nr+1))(x)\n",
        "        activated_x = Flatten()(activated_x)\n",
        "        activated_x = Dense(self.n_dense)(activated_x)\n",
        "        output = Dense(self.dimension)(activated_x)\n",
        "\n",
        "        from keras.models import Model\n",
        "        self.model = Model(inp_shape,output )\n",
        "\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=0)\n",
        "\n",
        "        if plot:\n",
        "            self.plotTraining()\n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8], [4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "# best_auc = [0,0]\n",
        "# histories = []\n",
        "# for f in filters:\n",
        "#     for k in kernelsizes:\n",
        "#         for d in dense:\n",
        "\n",
        "#             cnn = CNN_Resnet_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,f,k,d)\n",
        "#             hist = cnn.fit()\n",
        "#             histories.append(((f,k,d), hist))\n",
        "#             # cnn.plot()\n",
        "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#             if best_auc[1] < auc:\n",
        "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#                 best_auc = [(f,k,d),auc]\n",
        "#             break\n",
        "#         break\n",
        "#     break\n",
        "# print(best_auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taiAW0Bk-iVP",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2j6BPtY1b1-",
        "colab_type": "text"
      },
      "source": [
        "### Mahalanobis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAcehPYXCT1e",
        "colab_type": "code",
        "outputId": "322a7677-e7a5-4994-f852-1a4e553af23e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_Resnet_AnomalyDetection.from_DataFrame(df_synthetic,180,5,60,0.3,[3,3,3],1,18,'mahalanobis')\n",
        "hist = cnn.fit(plot=True)\n",
        "histories.append(((f,k,d), hist))\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n",
        "#0.757626"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxykQiIjkuP8PqQhe12PN8sIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.9269403215831787\n",
            "Time:  46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGIn4T1cBSwy",
        "colab_type": "code",
        "outputId": "af98b88d-ac3e-462a-fe3e-743e05b7f995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_Resnet_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,180,9,60,0.3,[3,3,3],1,18,'mahalanobis')\n",
        "hist = cnn.fit(plot=True)\n",
        "# histories.append(((f,k,d), hist))\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/X83njKGs29PmAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.4732414147439452\n",
            "Time:  314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii3VOu4O1f2i",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBTh32Mp1hR0",
        "colab_type": "code",
        "outputId": "02065907-119b-4702-8e8b-1fe5bc995493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_Resnet_AnomalyDetection.from_DataFrame(df_synthetic,180,5,60,0.3,[3,3,3],1,18,'euclidean')\n",
        "hist = cnn.fit(plot=True)\n",
        "histories.append(((f,k,d), hist))\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n",
        "#0.757626"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBHJcwoEIiJ5ToFARCTPKRCIiOS5/w95mPq1p+7VmAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7592029993815709\n",
            "Time:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrmfXw2YBd3o",
        "colab_type": "code",
        "outputId": "2e81e3fc-9dea-49b7-e821-2620cd3f64a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_Resnet_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,180,9,60,0.3,[3,3,3],1,18,'euclidean')\n",
        "hist = cnn.fit(plot=True)\n",
        "# histories.append(((f,k,d), hist))\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncwoEIiIxp0AgIhJzCgQiIjH3/wEUGU1AabtWmwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.4749194173505512\n",
            "Time:  318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Ot34N_-jDv",
        "colab_type": "code",
        "outputId": "2e07a5df-9c59-49e1-c373-a06ef02e98fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "cnn = CNN_Resnet_AnomalyDetection.from_DataFrame(df_synthetic,100,5,50,0.3,[4,4,4],1,18)\n",
        "hist = cnn.fit(plot=True)\n",
        "histories.append(((f,k,d), hist))\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7602232142857143\n",
            "Time:  26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHpVDe_dDGGy",
        "colab_type": "text"
      },
      "source": [
        "# Wavenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66HIkWvPDIjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "seed(42)\n",
        "from keras import regularizers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class WaveNet_AnomalyDetection:\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
        "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
        "     \n",
        "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function):\n",
        "\n",
        "        self.distance_function = distance_function\n",
        "        self.dimension = dimension\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "        \n",
        "        self.n_filters = n_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.n_dense = n_dense\n",
        "\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "        return self.history.history\n",
        "\n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
        "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
        "\n",
        "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "        self.model = Sequential()\n",
        "\n",
        "        self.model.add(Conv1D(filters=self.n_filters[0], kernel_size=self.kernel_size, activation='relu', input_shape=(self.window_width,self.dimension ),data_format='channels_first', padding='same', dilation_rate=1))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Conv1D(filters=self.n_filters[1], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate=2))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Conv1D(filters=self.n_filters[2], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate = 4))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "        self.model.add(Conv1D(filters=self.n_filters[3], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate = 8))\n",
        "        self.model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "        self.model.add(Flatten())\n",
        "        self.model.add(Dense(self.n_dense, activation='relu'))\n",
        "        self.model.add(Dense(self.dimension))\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=0)\n",
        "\n",
        "        # self.plotTraining()\n",
        "        self.predictions = self.model.predict(self.test_X)\n",
        "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "# best_auc = [0,0]\n",
        "# histories = []\n",
        "# for f in filters:\n",
        "#     for k in kernelsizes:\n",
        "#         for d in dense:\n",
        "\n",
        "#             cnn = WaveNet_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,f,k,d)\n",
        "#             hist = cnn.fit()\n",
        "#             histories.append(((f,k,d), hist))\n",
        "#             # cnn.plot()\n",
        "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#             if best_auc[1] < auc:\n",
        "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#                 best_auc = [(f,k,d),auc]\n",
        "#             break\n",
        "#         break\n",
        "#     break\n",
        "\n",
        "# print(best_auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq1_t3wttetJ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecn1JaLvtgls",
        "colab_type": "text"
      },
      "source": [
        "### Mahalanobis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tTJITJCtjOH",
        "colab_type": "code",
        "outputId": "e529d60f-e485-413b-f4b9-065345d7d77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "\n",
        "cnn = WaveNet_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8,8],2,18, 'mahalanobis')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.933632303148188\n",
            "Time:  29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIvSJywNFNOb",
        "colab_type": "code",
        "outputId": "deed9149-bf0e-4f2c-acbc-d93a649f3edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "\n",
        "cnn = WaveNet_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,30,9,20,0.3,[8,8,8,8],2,18, 'mahalanobis')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.47226477686150203\n",
            "Time:  69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J68348ktjyz",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI7URuMQtlNa",
        "colab_type": "code",
        "outputId": "f7b46bff-2a77-4392-b515-1d1d7d29021b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "\n",
        "cnn = WaveNet_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8,8],2,18, 'euclidean')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7758734961458108\n",
            "Time:  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBR3tPzaFdPO",
        "colab_type": "code",
        "outputId": "8bb1cca5-3e2e-4ee9-c229-6abfbb7e912f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "\n",
        "cnn = WaveNet_AnomalyDetection.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,30,9,20,0.3,[8,8,8,8],2,18, 'euclidean')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.4756995340412094\n",
            "Time:  68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuYUXOTxDD9h",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx6_hBnUDFKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "seed(42)\n",
        "from keras import regularizers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class LSTM_AnomalyDetection_ML:\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, distance_function) -> 'LSTM_AnomalyDetection_ML':\n",
        "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, distance_function) -> 'LSTM_AnomalyDetection_ML':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, distance_function)\n",
        "     \n",
        "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, distance_function):\n",
        "\n",
        "        self.dimension = dimension\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "        self.distance_function = distance_function\n",
        "\n",
        "        self.n_filters = n_filters\n",
        "\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "\n",
        "\n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
        "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
        "\n",
        "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "        self.model = Sequential()\n",
        "\n",
        "        import datetime\n",
        "        startTime = datetime.datetime.now()\n",
        "\n",
        "        self.train_X = numpy.reshape(self.train_X, (-1, self.window_width, self.dimension))\n",
        "        self.test_X = numpy.reshape(self.test_X, (-1, self.window_width, self.dimension))\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(LSTM(self.n_filters[0], batch_input_shape=(1, self.window_width, self.dimension), stateful=True, return_sequences=True))\n",
        "        self.model.add(LSTM(self.n_filters[1], batch_input_shape=(1, self.window_width, self.dimension), stateful=True))\n",
        "        self.model.add(Dense(self.dimension))\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        for i in range(self.n_epochs):\n",
        "            print('Epoch',i, '/',self.n_epochs)\n",
        "            self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, batch_size=1, verbose=1, shuffle=False)\n",
        "            self.model.reset_states()\n",
        "        # self.history =self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=2)\n",
        "        \n",
        "        # self.plotTraining()\n",
        "        self.predictions = self.model.predict(self.test_X, batch_size = 1)\n",
        "\n",
        "        endTime = datetime.datetime.now()\n",
        "        diff = endTime - startTime\n",
        "        print('Train and Test time: ',diff.seconds)\n",
        "\n",
        "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "# best_auc = [0,0]\n",
        "# histories = []\n",
        "# for f in filters:\n",
        "#     for k in kernelsizes:\n",
        "#         for d in dense:\n",
        "\n",
        "#             cnn = LSTM_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,f)\n",
        "#             cnn.fit()\n",
        "#             # cnn.plot()\n",
        "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#             if best_auc[1] < auc:\n",
        "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#                 best_auc = [(f,k,d),auc]\n",
        "#             break\n",
        "#         break\n",
        "#     break\n",
        "\n",
        "# print(best_auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAo7V5sypBzq",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9MpTT1JpDNm",
        "colab_type": "text"
      },
      "source": [
        "### Mahalanobis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujhYTewnpFMN",
        "colab_type": "code",
        "outputId": "de23c657-1189-46db-be16-01579d0e0b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "\n",
        "cnn = LSTM_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,[8,8,8,8], 'mahalanobis')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 1\n",
            "Epoch 1/1\n",
            "868/868 [==============================] - 105s 121ms/step - loss: 0.9666\n",
            "Train and Test time:  230\n",
            "AUC:  0.936467113320366\n",
            "Time:  230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDX6Z4QNGWFI",
        "colab_type": "code",
        "outputId": "268101ae-3a08-456f-d1af-3c51c7a435a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "\n",
        "cnn = LSTM_AnomalyDetection_ML.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,30,9,1,0.3,[8,8,8,8], 'mahalanobis')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/1\n",
            "14697/14697 [==============================] - 1442s 98ms/step - loss: 1.1207\n",
            "Train and Test time:  2999\n",
            "AUC:  0.47035573795432223\n",
            "Time:  3001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FddjuzQJpF5K",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti-La97vpG9U",
        "colab_type": "code",
        "outputId": "a719c669-919b-47df-abea-264d4627ffcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "\n",
        "cnn = LSTM_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,[8,8,8,8], 'euclidean')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 1\n",
            "Epoch 1/1\n",
            "868/868 [==============================] - 105s 121ms/step - loss: 0.9675\n",
            "Train and Test time:  229\n",
            "AUC:  0.7589186658021757\n",
            "Time:  229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGpQmmBvGfQd",
        "colab_type": "code",
        "outputId": "a5fc13fa-284b-4d6d-e57c-61dea29df2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "import glob\n",
        "\n",
        "cnn = LSTM_AnomalyDetection_ML.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv', None,30,9,1,0.3,[8,8,8,8], 'euclidean')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 1\n",
            "Epoch 1/1\n",
            "14697/14697 [==============================] - 1464s 100ms/step - loss: 1.1207\n",
            "Train and Test time:  3046\n",
            "AUC:  0.4751280805006092\n",
            "Time:  3048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4muiAAUdp1w",
        "colab_type": "text"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EPaetWYdqxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, GRU\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "seed(42)\n",
        "from keras import regularizers\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class GRU_AnomalyDetection_ML:\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, distance_function) -> 'LSTM_AnomalyDetection_ML':\n",
        "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, distance_function) -> 'LSTM_AnomalyDetection_ML':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, distance_function)\n",
        "     \n",
        "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, distance_function):\n",
        "\n",
        "        self.dimension = dimension\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "        self.distance_function = distance_function\n",
        "        self.n_filters = n_filters\n",
        "\n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        # self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
        "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
        "\n",
        "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "        self.model = Sequential()\n",
        "\n",
        "        # self.model.add(Conv1D(filters=self.n_filters[0], kernel_size=self.kernel_size, activation='relu', input_shape=(self.window_width,self.dimension ),data_format='channels_first', padding='same', dilation_rate=1))\n",
        "        # self.model.add(MaxPooling1D(pool_size=2))\n",
        "        # self.model.add(Conv1D(filters=self.n_filters[1], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate=2))\n",
        "        # self.model.add(MaxPooling1D(pool_size=2))\n",
        "        # self.model.add(Conv1D(filters=self.n_filters[2], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate = 4))\n",
        "        # self.model.add(MaxPooling1D(pool_size=2))\n",
        "        # self.model.add(Conv1D(filters=self.n_filters[3], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate = 8))\n",
        "        # self.model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "        # self.model.add(Flatten())\n",
        "        # self.model.add(Dense(self.n_dense, activation='relu'))\n",
        "        # self.model.add(Dense(self.dimension))\n",
        "        # self.model.compile(optimizer='adam', loss='mse')\n",
        "        # self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=0)\n",
        "        import datetime\n",
        "        startTime = datetime.datetime.now()\n",
        "\n",
        "        self.train_X = numpy.reshape(self.train_X, (-1, self.window_width, self.dimension))\n",
        "        self.test_X = numpy.reshape(self.test_X, (-1, self.window_width, self.dimension))\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(GRU(self.n_filters[0], batch_input_shape=(1, self.window_width, self.dimension), stateful=True, return_sequences=True))\n",
        "        self.model.add(GRU(self.n_filters[1], batch_input_shape=(1, self.window_width, self.dimension), stateful=True))\n",
        "        self.model.add(Dense(self.dimension))\n",
        "        self.model.compile(optimizer='adam', loss='mse')\n",
        "        for i in range(self.n_epochs):\n",
        "            print('Epoch',i, '/',self.n_epochs)\n",
        "            self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, batch_size=1, verbose=1, shuffle=False)\n",
        "            self.model.reset_states()\n",
        "        # self.history =self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=2)\n",
        "        \n",
        "        # self.plotTraining()\n",
        "        self.predictions = self.model.predict(self.test_X, batch_size = 1)\n",
        "\n",
        "        endTime = datetime.datetime.now()\n",
        "        diff = endTime - startTime\n",
        "        print('Train and Test time: ',diff.seconds)\n",
        "\n",
        "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
        "# kernelsizes = [2,3,4,6,8,16]\n",
        "# dense = [18,36,72,144]\n",
        "\n",
        "# best_auc = [0,0]\n",
        "# histories = []\n",
        "# for f in filters:\n",
        "#     for k in kernelsizes:\n",
        "#         for d in dense:\n",
        "\n",
        "#             cnn = LSTM_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,f)\n",
        "#             cnn.fit()\n",
        "#             # cnn.plot()\n",
        "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#             if best_auc[1] < auc:\n",
        "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "#                 best_auc = [(f,k,d),auc]\n",
        "#             break\n",
        "#         break\n",
        "#     break\n",
        "\n",
        "# print(best_auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbbFQY-FntLl",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVfGqbxjnun8",
        "colab_type": "text"
      },
      "source": [
        "### Mahalanobis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYXhN080nwpC",
        "colab_type": "code",
        "outputId": "81105d2f-9283-4aa8-9ae2-fdd543cf4951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "cnn = GRU_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,[8,8,8,8], 'mahalanobis')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 1\n",
            "Epoch 1/1\n",
            "868/868 [==============================] - 89s 103ms/step - loss: 0.9777\n",
            "Train and Test time:  191\n",
            "AUC:  0.9299257978531805\n",
            "Time:  191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW5aA6e_Gj9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "cnn = GRU_AnomalyDetection_ML.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv', None,30,3,1,0.3,[8,8,8,8], 'mahalanobis')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cwC-0roo5na",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pZu3QWZo6nk",
        "colab_type": "code",
        "outputId": "63128b99-760c-4478-c3c0-0f816006d041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "cnn = GRU_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,[8,8,8,8], 'euclidean')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 1\n",
            "Epoch 1/1\n",
            "868/868 [==============================] - 91s 105ms/step - loss: 0.9725\n",
            "Train and Test time:  193\n",
            "AUC:  0.7479036092500541\n",
            "Time:  193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4s7LhygGxnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "cnn = GRU_AnomalyDetection_ML.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv', None,30,3,1,0.3,[8,8,8,8], 'euclidean')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy3Xx__Hfj2e",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av9K33PlflOR",
        "colab_type": "code",
        "outputId": "30230755-4ac8-469a-834a-874218419db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import scipy.linalg\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import numpy as np \n",
        "from matplotlib import pyplot\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)\n",
        "from numpy.random import seed\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, GRU\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "seed(42)\n",
        "from keras import regularizers, Model\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "    \n",
        "class AutoEncoder_AnomalyDetection_ML:\n",
        "    @classmethod\n",
        "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, distance_function) -> 'AutoEncoder_AnomalyDetection_ML':\n",
        "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, distance_function)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, distance_function) -> 'AutoEncoder_AnomalyDetection_ML':\n",
        "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
        "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, distance_function)\n",
        "     \n",
        "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, distance_function):\n",
        "\n",
        "        self.distance_function = distance_function\n",
        "        self.dimension = dimension\n",
        "        self.n_epochs = n_epochs\n",
        "        self.window_width = window_width\n",
        "        \n",
        "        self.df = df\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
        "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
        "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
        "\n",
        "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
        "        self.values = df_sensors\n",
        "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
        "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
        "\n",
        "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
        "        # self.dataframe.columns = ['t', 't+1']\n",
        "\n",
        "        self.train_size = int(len(self.values) * train_rate)  \n",
        "\n",
        "\n",
        "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-look_back-1):\n",
        "            a = dataset[i:(i+look_back),:self.dimension]\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
        "        return numpy.array(dataX), numpy.array(dataY)\n",
        "    \n",
        "    def getWindowedVectors(self, X):\n",
        "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
        "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
        "            vectors[i] = X[i:i+self.window_width]\n",
        "        return vectors\n",
        "\n",
        "    def __build_sets(self):\n",
        "\n",
        "        X = self.dataframe.iloc[:,:-1].values\n",
        "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
        "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
        "\n",
        "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
        "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
        "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
        "\n",
        "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
        "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
        "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
        "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
        "\n",
        "    def standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
        "        X = self.scalar.transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "    def inverse_standardize_dataframe(self):\n",
        "        X = self.dataframe.values\n",
        "        X = self.scalar.inverse_transform(X)\n",
        "        self.dataframe = pd.DataFrame(X)\n",
        "\n",
        "\n",
        "\n",
        "    def model_persistence(self, x):\n",
        "        return x\n",
        "        \n",
        "    def create_persistence(self):\n",
        "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
        "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
        "\n",
        "    def fit(self):\n",
        "        self.create_persistence()\n",
        "        self.standardize_dataframe()\n",
        "        self.__build_sets()\n",
        "                \n",
        "        self.compute_anomalyScores()\n",
        "        self.inverse_standardize_dataframe()\n",
        "        # self.compute_Errors_RMSE()\n",
        "\n",
        "\n",
        "    def plotTraining(self):\n",
        "        history_dict = self.history.history\n",
        "        loss_values = history_dict['loss'][1:]\n",
        "        val_loss_values = history_dict['val_loss'][1:]\n",
        "        self.n_epochs = range(2, self.n_epochs + 1)\n",
        "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
        "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compute_anomalyScores(self):\n",
        "\n",
        "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
        "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
        "\n",
        "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
        "        self.model = Sequential()\n",
        "\n",
        "\n",
        "        self.train_X = numpy.reshape(self.train_X, (-1, self.window_width, self.dimension))\n",
        "        self.test_X = numpy.reshape(self.test_X, (-1, self.window_width, self.dimension))\n",
        "\n",
        "        input_layer = Input(shape=( self.window_width, self.dimension))\n",
        "        encoder = Dense(32, activation=\"relu\")(input_layer)\n",
        "        encoder = Dense(16, activation=\"relu\")(encoder)\n",
        "        decoder = Dense(16, activation=\"relu\")(encoder)\n",
        "        decoder = Dense(32, activation=\"relu\")(decoder)\n",
        "        decoder = Dense(self.dimension, activation=\"linear\")(decoder)\n",
        "        self.model = Model(inputs=input_layer, outputs=decoder)\n",
        "        \n",
        "        self.model.compile(metrics=['accuracy'],\n",
        "                            loss='mean_squared_error',\n",
        "                            optimizer='adam')\n",
        "        channel_pos = 'channels_first'\n",
        "\n",
        "\n",
        "        history = self.model.fit(self.train_X, self.train_X, epochs=self.n_epochs, verbose=2)\n",
        "\n",
        "        # self.plotTraining()\n",
        "        self.predictions = self.model.predict(self.test_X, batch_size = 1)\n",
        "        self.error_vect = (self.test_X.reshape(self.predictions.shape) - self.predictions).reshape(self.test_X.shape[0],-1)\n",
        "        self.compute_errors(self.distance_function)\n",
        "\n",
        "    def compute_Errors_RMSE(self):\n",
        "\n",
        "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
        "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
        "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
        "   \n",
        "\n",
        "    def plot(self):\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
        "        for i, ax in enumerate(axes.flatten()):\n",
        "            data = self.df[self.df.columns[i]].iloc[:200]\n",
        "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
        "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
        "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
        "            ax.legend()\n",
        "            \n",
        "        plt.show()\n",
        "\n",
        "    def compute_errors(self, distance_function):\n",
        "        if distance_function == 'mahalanobis':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
        "        elif distance_function == 'euclidean':\n",
        "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
        "            mean = np.mean(self.error_vect,axis=0)\n",
        "            self.errors = np.zeros((len(self.error_vect),1))\n",
        "            for i,error in enumerate(self.error_vect):\n",
        "                self.errors[i] = distance.euclidean(error,mean)\n",
        "                \n",
        "    def get_roc_auc(self, plot=True, verbose=True):\n",
        "        # self.euclidean_errors = numpy.linalg.norm((self.test_X.reshape(self.predictions.shape) - self.predictions).reshape(self.test_X.shape[0],-1), axis=1)\n",
        "        # get the predicted errors of the anomaly points\n",
        "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
        "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
        "        if len(true_anomaly_predicted_errors) == 0:\n",
        "            return np.nan\n",
        "        # sort them \n",
        "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
        "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
        "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
        "                # now iterate thru the predicted errors from small to big\n",
        "        # for each value look how much other points have equal or bigger error\n",
        "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "        TPR = [] # tp/p\n",
        "        p = len(true_anomaly_predicted_errors)\n",
        "        Thresholds = []\n",
        "        for predictederror in true_anomaly_predicted_errors_extended:\n",
        "            threshold = predictederror\n",
        "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
        "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
        "            \n",
        "            fpr =fp/len(self.errors)\n",
        "            FPR.append(fpr)\n",
        "            TPR.append(tp/p)\n",
        "            if verbose:\n",
        "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        if plot:\n",
        "            plt.figure()\n",
        "            plt.axis([0, 1, 0, 1])\n",
        "            plt.plot(FPR,TPR)\n",
        "            plt.show() \n",
        "\n",
        "        # This is the AUC\n",
        "        from sklearn.metrics import auc\n",
        "        print('AUC: ' ,auc(FPR,TPR)        )\n",
        "        return auc(FPR,TPR)\n",
        "\n",
        "filters = [[8,8,8,8], [4,4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
        "kernelsizes = [2,3,4,6,8,16]\n",
        "dense = [18,36,72,144]\n",
        "\n",
        "best_auc = [0,0]\n",
        "histories = []\n",
        "for f in filters:\n",
        "    for k in kernelsizes:\n",
        "        for d in dense:\n",
        "\n",
        "            cnn = AutoEncoder_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3, 'euclidean')\n",
        "            cnn.fit()\n",
        "            # cnn.plot()\n",
        "            auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "            print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "            if best_auc[1] < auc:\n",
        "                print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
        "                best_auc = [(f,k,d),auc]\n",
        "            break\n",
        "        break\n",
        "    break\n",
        "\n",
        "print(best_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " - 11s - loss: 0.8430 - acc: 0.3319\n",
            "AUC:  0.8780023053094158\n",
            " auc: 0.8780023053094158  - f: [8, 8, 8, 8]  - k: 2  - d: 18\n",
            "New best auc: 0.8780023053094158  - f: [8, 8, 8, 8]  - k: 2  - d: 18\n",
            "[([8, 8, 8, 8], 2, 18), 0.8780023053094158]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIoZnpfmnQv9",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub1g_OkQnSuO",
        "colab_type": "text"
      },
      "source": [
        "### Mahalanobis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEjE8jnhnUlD",
        "colab_type": "code",
        "outputId": "403ba32a-0ab5-4b12-d61f-2c3fe6934617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "cnn = AutoEncoder_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3, 'mahalanobis')\n",
        "cnn.fit()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " - 20s - loss: 0.8559 - acc: 0.2854\n",
            "AUC:  0.892623009869606\n",
            "Time:  34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2GeeyCAG1kx",
        "colab_type": "code",
        "outputId": "1739761c-042d-484b-ce8f-0d50d5294a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "cnn = AutoEncoder_AnomalyDetection_ML.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv', None,30,3,1,0.3, 'mahalanobis')\n",
        "cnn.fit()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-38d4ef6dd4d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoEncoder_AnomalyDetection_ML\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mahalanobis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_roc_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-57b8676e9ad2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_anomalyScores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_standardize_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# self.compute_Errors_RMSE()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-57b8676e9ad2>\u001b[0m in \u001b[0;36mcompute_anomalyScores\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# self.plotTraining()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2959\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 216\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNAAc9oNndlW",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k2hm3fFnfGE",
        "colab_type": "code",
        "outputId": "e1925815-1fe7-4c20-b3f1-bdbf263cf17c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "cnn = AutoEncoder_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3, 'euclidean')\n",
        "cnn.fit()\n",
        "# cnn.plot()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " - 20s - loss: 0.8983 - acc: 0.3422\n",
            "AUC:  0.8726028384122181\n",
            "Time:  34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LCAuGN0HETp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "startTime = datetime.datetime.now()\n",
        "\n",
        "cnn = AutoEncoder_AnomalyDetection_ML.from_file('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40903.csv', None,30,3,1,0.3, 'euclidean')\n",
        "cnn.fit()\n",
        "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
        "\n",
        "endTime = datetime.datetime.now()\n",
        "diff = endTime - startTime\n",
        "print('Time: ',diff.seconds)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
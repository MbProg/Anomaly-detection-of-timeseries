{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "XmSzxnT6JsJg",
    "outputId": "beeb3137-9dae-47ad-e261-5a0dd571980c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YsBQbAYYZyWG"
   },
   "source": [
    "# Create Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "LVbEbFQoJz80",
    "outputId": "b4314b26-7ad1-45f9-9b63-c7ac99d94ce1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.181775</td>\n",
       "      <td>-0.356005</td>\n",
       "      <td>-0.737091</td>\n",
       "      <td>-0.205435</td>\n",
       "      <td>-1.480306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111849</td>\n",
       "      <td>-0.726275</td>\n",
       "      <td>-0.385677</td>\n",
       "      <td>-0.715546</td>\n",
       "      <td>-1.715649</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.371517</td>\n",
       "      <td>-0.564174</td>\n",
       "      <td>1.762981</td>\n",
       "      <td>0.583939</td>\n",
       "      <td>0.411228</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.215548</td>\n",
       "      <td>0.940304</td>\n",
       "      <td>1.203293</td>\n",
       "      <td>-0.545090</td>\n",
       "      <td>2.814054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.565489</td>\n",
       "      <td>1.585782</td>\n",
       "      <td>1.605845</td>\n",
       "      <td>0.396074</td>\n",
       "      <td>4.153190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.159889</td>\n",
       "      <td>-1.004514</td>\n",
       "      <td>0.386416</td>\n",
       "      <td>0.365448</td>\n",
       "      <td>-0.092762</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.035256</td>\n",
       "      <td>0.087646</td>\n",
       "      <td>0.596977</td>\n",
       "      <td>2.013790</td>\n",
       "      <td>1.663157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.870609</td>\n",
       "      <td>0.907198</td>\n",
       "      <td>-0.555105</td>\n",
       "      <td>1.826035</td>\n",
       "      <td>1.307519</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.186550</td>\n",
       "      <td>0.903166</td>\n",
       "      <td>-0.946299</td>\n",
       "      <td>-0.095505</td>\n",
       "      <td>-1.325189</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.079154</td>\n",
       "      <td>0.494633</td>\n",
       "      <td>2.203691</td>\n",
       "      <td>-0.492293</td>\n",
       "      <td>1.126878</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.337874</td>\n",
       "      <td>-0.042516</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>-1.268571</td>\n",
       "      <td>-0.758213</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.288212</td>\n",
       "      <td>-0.214261</td>\n",
       "      <td>-0.156983</td>\n",
       "      <td>-0.643567</td>\n",
       "      <td>-1.303024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.119159</td>\n",
       "      <td>0.228119</td>\n",
       "      <td>0.723742</td>\n",
       "      <td>0.290241</td>\n",
       "      <td>1.361260</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.785178</td>\n",
       "      <td>-0.549138</td>\n",
       "      <td>0.760413</td>\n",
       "      <td>0.245374</td>\n",
       "      <td>1.241826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.087281</td>\n",
       "      <td>-0.906613</td>\n",
       "      <td>-0.825244</td>\n",
       "      <td>0.855888</td>\n",
       "      <td>-0.788688</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.453069</td>\n",
       "      <td>-0.191268</td>\n",
       "      <td>-0.993548</td>\n",
       "      <td>0.387593</td>\n",
       "      <td>-0.344154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.038796</td>\n",
       "      <td>0.716692</td>\n",
       "      <td>0.120268</td>\n",
       "      <td>-1.309434</td>\n",
       "      <td>1.566323</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.665959</td>\n",
       "      <td>-0.571351</td>\n",
       "      <td>0.360335</td>\n",
       "      <td>1.693790</td>\n",
       "      <td>2.148733</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.531250</td>\n",
       "      <td>-1.529956</td>\n",
       "      <td>0.576648</td>\n",
       "      <td>0.630250</td>\n",
       "      <td>0.208192</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.659623</td>\n",
       "      <td>-1.058130</td>\n",
       "      <td>-0.520202</td>\n",
       "      <td>1.085133</td>\n",
       "      <td>-1.152822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.062393</td>\n",
       "      <td>-0.072187</td>\n",
       "      <td>0.365563</td>\n",
       "      <td>0.345386</td>\n",
       "      <td>0.701155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.376729</td>\n",
       "      <td>-0.177471</td>\n",
       "      <td>0.093591</td>\n",
       "      <td>0.199117</td>\n",
       "      <td>0.491966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.202374</td>\n",
       "      <td>-0.530660</td>\n",
       "      <td>-0.489248</td>\n",
       "      <td>-0.844211</td>\n",
       "      <td>-1.661745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.091203</td>\n",
       "      <td>-1.828333</td>\n",
       "      <td>-0.458638</td>\n",
       "      <td>-1.220269</td>\n",
       "      <td>-1.416037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.202434</td>\n",
       "      <td>1.337685</td>\n",
       "      <td>0.299343</td>\n",
       "      <td>0.546000</td>\n",
       "      <td>1.980594</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.063625</td>\n",
       "      <td>-0.057995</td>\n",
       "      <td>0.289480</td>\n",
       "      <td>-0.190860</td>\n",
       "      <td>-0.023001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.861697</td>\n",
       "      <td>0.920512</td>\n",
       "      <td>-0.247726</td>\n",
       "      <td>1.602516</td>\n",
       "      <td>4.136999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.336799</td>\n",
       "      <td>0.109012</td>\n",
       "      <td>3.709249</td>\n",
       "      <td>-0.700638</td>\n",
       "      <td>3.454422</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.218976</td>\n",
       "      <td>-0.130506</td>\n",
       "      <td>2.077594</td>\n",
       "      <td>0.049135</td>\n",
       "      <td>1.777247</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.893711</td>\n",
       "      <td>-1.550867</td>\n",
       "      <td>-1.063140</td>\n",
       "      <td>0.514952</td>\n",
       "      <td>-2.992766</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>0.079341</td>\n",
       "      <td>-1.485660</td>\n",
       "      <td>1.015584</td>\n",
       "      <td>1.712756</td>\n",
       "      <td>1.322020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>0.277878</td>\n",
       "      <td>-0.028807</td>\n",
       "      <td>2.155679</td>\n",
       "      <td>0.146821</td>\n",
       "      <td>2.551570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>0.541843</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>-0.167947</td>\n",
       "      <td>-1.044188</td>\n",
       "      <td>-0.657588</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>1.302534</td>\n",
       "      <td>0.801146</td>\n",
       "      <td>0.087458</td>\n",
       "      <td>0.332154</td>\n",
       "      <td>2.523292</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>0.044131</td>\n",
       "      <td>-1.203305</td>\n",
       "      <td>0.244855</td>\n",
       "      <td>-0.737939</td>\n",
       "      <td>-1.652258</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>0.808294</td>\n",
       "      <td>-0.358657</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>-0.676508</td>\n",
       "      <td>-0.211081</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>1.558797</td>\n",
       "      <td>-0.049406</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>-2.413409</td>\n",
       "      <td>-0.738219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>0.354997</td>\n",
       "      <td>-1.478528</td>\n",
       "      <td>0.854919</td>\n",
       "      <td>0.150772</td>\n",
       "      <td>-0.117840</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>0.110523</td>\n",
       "      <td>-1.761066</td>\n",
       "      <td>-1.648172</td>\n",
       "      <td>1.423354</td>\n",
       "      <td>-1.875361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>0.012986</td>\n",
       "      <td>-0.416292</td>\n",
       "      <td>-0.352519</td>\n",
       "      <td>0.717917</td>\n",
       "      <td>-0.037909</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>-0.500529</td>\n",
       "      <td>-0.382733</td>\n",
       "      <td>0.816490</td>\n",
       "      <td>1.145614</td>\n",
       "      <td>1.078842</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>0.642916</td>\n",
       "      <td>0.202145</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>1.626171</td>\n",
       "      <td>3.119808</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>-2.568811</td>\n",
       "      <td>0.875697</td>\n",
       "      <td>0.488133</td>\n",
       "      <td>-0.627753</td>\n",
       "      <td>-1.832733</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>-3.136419</td>\n",
       "      <td>-0.305585</td>\n",
       "      <td>0.521747</td>\n",
       "      <td>0.172973</td>\n",
       "      <td>-2.747284</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>0.041884</td>\n",
       "      <td>1.738227</td>\n",
       "      <td>0.407524</td>\n",
       "      <td>-2.271629</td>\n",
       "      <td>-0.083994</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>0.594498</td>\n",
       "      <td>-0.531132</td>\n",
       "      <td>-2.275810</td>\n",
       "      <td>1.079577</td>\n",
       "      <td>-1.132867</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>0.286670</td>\n",
       "      <td>-1.537843</td>\n",
       "      <td>-0.258182</td>\n",
       "      <td>-0.672514</td>\n",
       "      <td>-2.181868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>-0.728498</td>\n",
       "      <td>1.708552</td>\n",
       "      <td>-0.942082</td>\n",
       "      <td>0.093489</td>\n",
       "      <td>0.131462</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>-0.456666</td>\n",
       "      <td>0.115543</td>\n",
       "      <td>-0.093219</td>\n",
       "      <td>0.357004</td>\n",
       "      <td>-0.077338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>0.784019</td>\n",
       "      <td>-1.358110</td>\n",
       "      <td>0.213079</td>\n",
       "      <td>-0.700660</td>\n",
       "      <td>-1.061673</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>-1.252037</td>\n",
       "      <td>0.765576</td>\n",
       "      <td>-0.313340</td>\n",
       "      <td>0.241847</td>\n",
       "      <td>-0.557954</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>-0.218972</td>\n",
       "      <td>-0.481817</td>\n",
       "      <td>0.450742</td>\n",
       "      <td>-0.689487</td>\n",
       "      <td>-0.939535</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>0.359318</td>\n",
       "      <td>1.122220</td>\n",
       "      <td>0.523262</td>\n",
       "      <td>1.948448</td>\n",
       "      <td>3.953248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>0.042116</td>\n",
       "      <td>-1.225083</td>\n",
       "      <td>-0.137050</td>\n",
       "      <td>1.014213</td>\n",
       "      <td>-0.305804</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>0.379184</td>\n",
       "      <td>1.158189</td>\n",
       "      <td>-0.958376</td>\n",
       "      <td>-0.485413</td>\n",
       "      <td>0.093584</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>1.466658</td>\n",
       "      <td>1.154215</td>\n",
       "      <td>1.176732</td>\n",
       "      <td>1.110451</td>\n",
       "      <td>4.908056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>1.385552</td>\n",
       "      <td>0.304047</td>\n",
       "      <td>0.575068</td>\n",
       "      <td>-0.415130</td>\n",
       "      <td>1.849536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>-1.546057</td>\n",
       "      <td>0.079860</td>\n",
       "      <td>0.443156</td>\n",
       "      <td>0.194019</td>\n",
       "      <td>-0.829022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.384378</td>\n",
       "      <td>0.385925</td>\n",
       "      <td>-0.488339</td>\n",
       "      <td>-2.303341</td>\n",
       "      <td>-2.021377</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>1.045501</td>\n",
       "      <td>0.609786</td>\n",
       "      <td>-0.614734</td>\n",
       "      <td>-0.507653</td>\n",
       "      <td>0.532900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1        V2        V3        V4        V5  is_anomaly\n",
       "0    -0.181775 -0.356005 -0.737091 -0.205435 -1.480306         0.0\n",
       "1     0.111849 -0.726275 -0.385677 -0.715546 -1.715649         0.0\n",
       "2    -1.371517 -0.564174  1.762981  0.583939  0.411228         0.0\n",
       "3     1.215548  0.940304  1.203293 -0.545090  2.814054         0.0\n",
       "4     0.565489  1.585782  1.605845  0.396074  4.153190         0.0\n",
       "5     0.159889 -1.004514  0.386416  0.365448 -0.092762         0.0\n",
       "6    -1.035256  0.087646  0.596977  2.013790  1.663157         0.0\n",
       "7    -0.870609  0.907198 -0.555105  1.826035  1.307519         0.0\n",
       "8    -1.186550  0.903166 -0.946299 -0.095505 -1.325189         0.0\n",
       "9    -1.079154  0.494633  2.203691 -0.492293  1.126878         0.0\n",
       "10    0.337874 -0.042516  0.215000 -1.268571 -0.758213         0.0\n",
       "11   -0.288212 -0.214261 -0.156983 -0.643567 -1.303024         0.0\n",
       "12    0.119159  0.228119  0.723742  0.290241  1.361260         0.0\n",
       "13    0.785178 -0.549138  0.760413  0.245374  1.241826         0.0\n",
       "14    0.087281 -0.906613 -0.825244  0.855888 -0.788688         0.0\n",
       "15    0.453069 -0.191268 -0.993548  0.387593 -0.344154         0.0\n",
       "16    2.038796  0.716692  0.120268 -1.309434  1.566323         0.0\n",
       "17    0.665959 -0.571351  0.360335  1.693790  2.148733         0.0\n",
       "18    0.531250 -1.529956  0.576648  0.630250  0.208192         0.0\n",
       "19   -0.659623 -1.058130 -0.520202  1.085133 -1.152822         0.0\n",
       "20    0.062393 -0.072187  0.365563  0.345386  0.701155         0.0\n",
       "21    0.376729 -0.177471  0.093591  0.199117  0.491966         0.0\n",
       "22    0.202374 -0.530660 -0.489248 -0.844211 -1.661745         0.0\n",
       "23    2.091203 -1.828333 -0.458638 -1.220269 -1.416037         0.0\n",
       "24   -0.202434  1.337685  0.299343  0.546000  1.980594         0.0\n",
       "25   -0.063625 -0.057995  0.289480 -0.190860 -0.023001         0.0\n",
       "26    1.861697  0.920512 -0.247726  1.602516  4.136999         0.0\n",
       "27    0.336799  0.109012  3.709249 -0.700638  3.454422         0.0\n",
       "28   -0.218976 -0.130506  2.077594  0.049135  1.777247         0.0\n",
       "29   -0.893711 -1.550867 -1.063140  0.514952 -2.992766         0.0\n",
       "...        ...       ...       ...       ...       ...         ...\n",
       "2970  0.079341 -1.485660  1.015584  1.712756  1.322020         0.0\n",
       "2971  0.277878 -0.028807  2.155679  0.146821  2.551570         0.0\n",
       "2972  0.541843  0.012704 -0.167947 -1.044188 -0.657588         0.0\n",
       "2973  1.302534  0.801146  0.087458  0.332154  2.523292         0.0\n",
       "2974  0.044131 -1.203305  0.244855 -0.737939 -1.652258         0.0\n",
       "2975  0.808294 -0.358657  0.015789 -0.676508 -0.211081         0.0\n",
       "2976  1.558797 -0.049406  0.165800 -2.413409 -0.738219         0.0\n",
       "2977  0.354997 -1.478528  0.854919  0.150772 -0.117840         0.0\n",
       "2978  0.110523 -1.761066 -1.648172  1.423354 -1.875361         0.0\n",
       "2979  0.012986 -0.416292 -0.352519  0.717917 -0.037909         0.0\n",
       "2980 -0.500529 -0.382733  0.816490  1.145614  1.078842         0.0\n",
       "2981  0.642916  0.202145  0.648575  1.626171  3.119808         0.0\n",
       "2982 -2.568811  0.875697  0.488133 -0.627753 -1.832733         0.0\n",
       "2983 -3.136419 -0.305585  0.521747  0.172973 -2.747284         0.0\n",
       "2984  0.041884  1.738227  0.407524 -2.271629 -0.083994         0.0\n",
       "2985  0.594498 -0.531132 -2.275810  1.079577 -1.132867         0.0\n",
       "2986  0.286670 -1.537843 -0.258182 -0.672514 -2.181868         0.0\n",
       "2987 -0.728498  1.708552 -0.942082  0.093489  0.131462         0.0\n",
       "2988 -0.456666  0.115543 -0.093219  0.357004 -0.077338         0.0\n",
       "2989  0.784019 -1.358110  0.213079 -0.700660 -1.061673         0.0\n",
       "2990 -1.252037  0.765576 -0.313340  0.241847 -0.557954         0.0\n",
       "2991 -0.218972 -0.481817  0.450742 -0.689487 -0.939535         0.0\n",
       "2992  0.359318  1.122220  0.523262  1.948448  3.953248         0.0\n",
       "2993  0.042116 -1.225083 -0.137050  1.014213 -0.305804         0.0\n",
       "2994  0.379184  1.158189 -0.958376 -0.485413  0.093584         0.0\n",
       "2995  1.466658  1.154215  1.176732  1.110451  4.908056         0.0\n",
       "2996  1.385552  0.304047  0.575068 -0.415130  1.849536         0.0\n",
       "2997 -1.546057  0.079860  0.443156  0.194019 -0.829022         0.0\n",
       "2998  0.384378  0.385925 -0.488339 -2.303341 -2.021377         0.0\n",
       "2999  1.045501  0.609786 -0.614734 -0.507653  0.532900         0.0\n",
       "\n",
       "[3000 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "n = int(3000)\n",
    "# alpha1 = 0.666, alpha2 = -.333\n",
    "alphas = np.array([.1])\n",
    "betas = np.array([0.])\n",
    "\n",
    "# Python requires us to specify the zero-lag value which is 1\n",
    "# Also note that the alphas for the AR model must be negated\n",
    "# We also set the betas for the MA equal to 0 for an AR(p) model\n",
    "# For more information see the examples at statsmodels.org\n",
    "ar = np.r_[1, -alphas]\n",
    "ma = np.r_[1, betas]\n",
    "# # AR(2)\n",
    "# ar2 = arma_generate_sample(ar=ar, ma=ma, nsample=n) \n",
    "# plt.figure(figsize=(20,5))\n",
    "# plt.plot( ar2)\n",
    "\n",
    "T_1 =  arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
    "T_2 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
    "T_3 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
    "T_4 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
    "T_5 = arma_generate_sample(ar=ar, ma=ma, nsample=n).reshape(-1,1)\n",
    "M =[[1 , 0 , 0 , 0 , 1],\n",
    "[0 , 1 , 0 , 0 , 1],\n",
    "[0 , 0 , 1 , 0 , 1],\n",
    "[0 , 0 , 0 , 1 , 1],\n",
    "[1 , -1 , 0 , 0 , 1]]\n",
    "delta = np.zeros((n,1))\n",
    "delta_anomal = np.zeros((n,1))\n",
    "delta_anomal[300:320]   = np.ones((20,1))\n",
    "delta_anomal[600:610]   = np.full((10,1),-0.7)\n",
    "delta_anomal[1300:1320] = np.full((20,1),2)\n",
    "delta_anomal[2100:2150] = np.full((50,1),-1.5)\n",
    "\n",
    "# delta_anomal[41:50] = np.ones((9,1))\n",
    "N = np.concatenate((T_1,T_2,T_3,T_4,delta), axis=1)\n",
    "N_anomal =  np.concatenate((T_1,T_2,T_3,T_4,delta_anomal), axis=1)\n",
    "B = N@M\n",
    "B_anomal = N_anomal@M\n",
    "\n",
    "T_1 = B[:,0]\n",
    "T_2 = B[:,1]\n",
    "T_3 = B[:,2]\n",
    "T_4 = B[:,3]\n",
    "T_5 = B[:,4]\n",
    "\n",
    "\n",
    "T_1_anomal = B_anomal[:,0]\n",
    "T_2_anomal = B_anomal[:,1]\n",
    "T_3_anomal = B_anomal[:,2]\n",
    "T_4_anomal = B_anomal[:,3]\n",
    "T_5_anomal = B_anomal[:,4]\n",
    "\n",
    "MD_T = np.concatenate((T_1.reshape((-1,1)),T_2.reshape((-1,1)),T_3.reshape((-1,1)),T_4.reshape((-1,1)),T_5.reshape((-1,1))),axis=1)\n",
    "MD_T_anomaly = np.concatenate((T_1_anomal.reshape((-1,1)),T_2_anomal.reshape((-1,1)),T_3_anomal.reshape((-1,1)),T_4_anomal.reshape((-1,1)),T_5_anomal.reshape((-1,1))),axis=1)\n",
    "MD_T.shape,MD_T_anomaly.shape\n",
    "\n",
    "labels = np.zeros((n,1))\n",
    "labels[300:320]     = 1\n",
    "labels[600:610]     = 1\n",
    "labels[1300:1320]   = 1\n",
    "labels[2100:2150]   = 1\n",
    "df_synthetic = pd.DataFrame(np.concatenate((MD_T_anomaly,labels), axis = 1))\n",
    "df_synthetic.columns =  np.r_[np.array(['V'+str(i) for i in range(1,6)]),['is_anomaly']]\n",
    "df_synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cEnz4cDKJ4tM"
   },
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NzlcPjDWJ6D0"
   },
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np \n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from numpy.random import seed\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "seed(42)\n",
    "from keras import regularizers\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    \n",
    "class MLP_AnomalyDetection:\n",
    "    @classmethod\n",
    "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
    "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, distance_function)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
    "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
    "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, distance_function)\n",
    "     \n",
    "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, distance_function):\n",
    "\n",
    "        self.distance_function = distance_function\n",
    "        self.dimension = dimension\n",
    "        self.n_epochs = n_epochs\n",
    "        self.window_width = window_width\n",
    "\n",
    "        self.df = df\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
    "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
    "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
    "\n",
    "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
    "        self.values = df_sensors\n",
    "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
    "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
    "\n",
    "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
    "        # self.dataframe.columns = ['t', 't+1']\n",
    "\n",
    "        self.train_size = int(len(self.values) * train_rate)  \n",
    "\n",
    "\n",
    "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back),:self.dimension]\n",
    "            dataX.append(a.reshape(-1))\n",
    "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
    "        return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "\n",
    "    def __build_sets(self):\n",
    "\n",
    "        X = self.dataframe.iloc[:,:-1].values\n",
    "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
    "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
    "\n",
    "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
    "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
    "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
    "\n",
    "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
    "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
    "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
    "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
    "\n",
    "    def standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
    "        X = self.scalar.transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "    def inverse_standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        X = self.scalar.inverse_transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "\n",
    "    def model_persistence(self, x):\n",
    "        return x\n",
    "        \n",
    "    def create_persistence(self):\n",
    "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
    "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
    "\n",
    "    def fit(self):\n",
    "        self.create_persistence()\n",
    "        self.standardize_dataframe()\n",
    "        self.__build_sets()\n",
    "                \n",
    "        self.compute_anomalyScores()\n",
    "        self.inverse_standardize_dataframe()\n",
    "        # self.compute_Errors_RMSE()\n",
    "\n",
    "\n",
    "    def plotTraining(self):\n",
    "        history_dict = self.history.history\n",
    "        loss_values = history_dict['loss'][1:]\n",
    "        val_loss_values = history_dict['val_loss'][1:]\n",
    "        self.n_epochs = range(2, self.n_epochs + 1)\n",
    "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
    "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def compute_anomalyScores(self):\n",
    "        set_random_seed(42)\n",
    "        seed(42)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(300, activation='relu', input_dim=self.window_width*self.dimension))\n",
    "        self.model.add(Dense(400, activation='relu'))\n",
    "        self.model.add(Dense(200, activation='relu'))\n",
    "        self.model.add(Dense(self.dimension))\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "        self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=1)\n",
    "\n",
    "        self.plotTraining()\n",
    "\n",
    "        self.predictions = self.model.predict(self.test_X)\n",
    "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
    "        self.compute_errors(self.distance_function)\n",
    "\n",
    "        # xgb = XGBRegressor()\n",
    "        # xgb.fit(self.train_X.reshape(-1,1),self.train_y.reshape(-1,1))\n",
    "\n",
    "        # rmse = sqrt(mean_squared_error(self.test, self.predictions))\n",
    "        # self.errors = np.absolute(self.test - np.array(self.predictions))\n",
    "        # print('Prediction Test RMSE: %.3f' % rmse)\n",
    "\n",
    "    def compute_errors(self, distance_function):\n",
    "        if distance_function == 'mahalanobis':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
    "        elif distance_function == 'euclidean':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.euclidean(error,mean)\n",
    "\t\t\t\t\n",
    "    def compute_Errors_RMSE(self):\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
    "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
    "        # print('Prediction Test RMS        E: %.3f' % rmse)        \n",
    "   \n",
    "\n",
    "    def plot(self):\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            data = self.df[self.df.columns[i]].iloc[:200]\n",
    "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
    "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
    "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
    "            ax.legend()\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    def get_roc_auc(self, plot=True, verbose=True):\n",
    "\n",
    "        # get the predicted errors of the anomaly points\n",
    "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
    "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
    "        if len(true_anomaly_predicted_errors) == 0:\n",
    "            return np.nan\n",
    "        # sort them \n",
    "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
    "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
    "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
    "                # now iterate thru the predicted errors from small to big\n",
    "        # for each value look how much other points have equal or bigger error\n",
    "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "        TPR = [] # tp/p\n",
    "        p = len(true_anomaly_predicted_errors)\n",
    "        Thresholds = []\n",
    "        for predictederror in true_anomaly_predicted_errors_extended:\n",
    "            threshold = predictederror\n",
    "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
    "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
    "            \n",
    "            fpr =fp/len(self.errors)\n",
    "            FPR.append(fpr)\n",
    "            TPR.append(tp/p)\n",
    "            if verbose:\n",
    "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.axis([0, 1, 0, 1])\n",
    "            plt.plot(FPR,TPR)\n",
    "            plt.show() \n",
    "\n",
    "        # This is the AUC\n",
    "        from sklearn.metrics import auc\n",
    "        print('AUC: ' ,auc(FPR,TPR)        )\n",
    "        return auc(FPR,TPR)\n",
    "\n",
    "# # mlp = MLP_AnomalyDetection('drive/My Drive/MT/Experiments/Multivariate/NASA_Shuttle/40902.csv',100,9,30,0.3)\n",
    "# mlp = MLP_AnomalyDetection.from_DataFrame(df_synthetic,100,5,30,0.3)\n",
    "# mlp.fit()\n",
    "# # mlp.plot()\n",
    "# mlp.get_roc_auc(verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AoeJ2EIs7XL"
   },
   "outputs": [],
   "source": [
    "0.46719427454831985"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0PrfNR87tT_"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lBk_V0R7vk8"
   },
   "source": [
    "### Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bUVzcvVZ7xGJ",
    "outputId": "858a8c8a-1234-4f8f-c60a-275a9e53783e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 798 samples, validate on 79 samples\n",
      "Epoch 1/30\n",
      "798/798 [==============================] - 22s 28ms/step - loss: 1.1077 - val_loss: 0.9955\n",
      "Epoch 2/30\n",
      "798/798 [==============================] - 0s 252us/step - loss: 0.6104 - val_loss: 1.0685\n",
      "Epoch 3/30\n",
      "798/798 [==============================] - 0s 246us/step - loss: 0.2988 - val_loss: 1.1171\n",
      "Epoch 4/30\n",
      "798/798 [==============================] - 0s 235us/step - loss: 0.1113 - val_loss: 1.1238\n",
      "Epoch 5/30\n",
      "798/798 [==============================] - 0s 241us/step - loss: 0.0476 - val_loss: 1.1320\n",
      "Epoch 6/30\n",
      "798/798 [==============================] - 0s 251us/step - loss: 0.0279 - val_loss: 1.1200\n",
      "Epoch 7/30\n",
      "798/798 [==============================] - 0s 249us/step - loss: 0.0223 - val_loss: 1.1215\n",
      "Epoch 8/30\n",
      "798/798 [==============================] - 0s 268us/step - loss: 0.0218 - val_loss: 1.1252\n",
      "Epoch 9/30\n",
      "798/798 [==============================] - 0s 247us/step - loss: 0.0180 - val_loss: 1.1349\n",
      "Epoch 10/30\n",
      "798/798 [==============================] - 0s 246us/step - loss: 0.0176 - val_loss: 1.1145\n",
      "Epoch 11/30\n",
      "798/798 [==============================] - 0s 250us/step - loss: 0.0164 - val_loss: 1.1148\n",
      "Epoch 12/30\n",
      "798/798 [==============================] - 0s 247us/step - loss: 0.0173 - val_loss: 1.1136\n",
      "Epoch 13/30\n",
      "798/798 [==============================] - 0s 262us/step - loss: 0.0185 - val_loss: 1.1233\n",
      "Epoch 14/30\n",
      "798/798 [==============================] - 0s 241us/step - loss: 0.0223 - val_loss: 1.1079\n",
      "Epoch 15/30\n",
      "798/798 [==============================] - 0s 266us/step - loss: 0.0261 - val_loss: 1.0929\n",
      "Epoch 16/30\n",
      "798/798 [==============================] - 0s 248us/step - loss: 0.0241 - val_loss: 1.1026\n",
      "Epoch 17/30\n",
      "798/798 [==============================] - 0s 255us/step - loss: 0.0239 - val_loss: 1.0874\n",
      "Epoch 18/30\n",
      "798/798 [==============================] - 0s 263us/step - loss: 0.0237 - val_loss: 1.0995\n",
      "Epoch 19/30\n",
      "798/798 [==============================] - 0s 254us/step - loss: 0.0223 - val_loss: 1.0639\n",
      "Epoch 20/30\n",
      "798/798 [==============================] - 0s 247us/step - loss: 0.0196 - val_loss: 1.0878\n",
      "Epoch 21/30\n",
      "798/798 [==============================] - 0s 263us/step - loss: 0.0179 - val_loss: 1.0645\n",
      "Epoch 22/30\n",
      "798/798 [==============================] - 0s 250us/step - loss: 0.0170 - val_loss: 1.0800\n",
      "Epoch 23/30\n",
      "798/798 [==============================] - 0s 263us/step - loss: 0.0156 - val_loss: 1.0591\n",
      "Epoch 24/30\n",
      "798/798 [==============================] - 0s 254us/step - loss: 0.0142 - val_loss: 1.0737\n",
      "Epoch 25/30\n",
      "798/798 [==============================] - 0s 254us/step - loss: 0.0140 - val_loss: 1.0543\n",
      "Epoch 26/30\n",
      "798/798 [==============================] - 0s 248us/step - loss: 0.0144 - val_loss: 1.0622\n",
      "Epoch 27/30\n",
      "798/798 [==============================] - 0s 237us/step - loss: 0.0130 - val_loss: 1.0673\n",
      "Epoch 28/30\n",
      "798/798 [==============================] - 0s 263us/step - loss: 0.0127 - val_loss: 1.0581\n",
      "Epoch 29/30\n",
      "798/798 [==============================] - 0s 255us/step - loss: 0.0132 - val_loss: 1.0605\n",
      "Epoch 30/30\n",
      "798/798 [==============================] - 0s 265us/step - loss: 0.0134 - val_loss: 1.0629\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZgU1b3/8feX3QEEBOLCCIPKlV2W\nCehFBNSboF4lGDQgrtGg/mKMmuSRuIfEJ25XDUq8IQsaGUWiwSViiDeiqEmQRUQBUUTQAZQlLCKi\nDHx/f5zqmWbomekZpqfpqc/reerpqlOnq051zdS3zjm1mLsjIiLx1SDbBRARkexSIBARiTkFAhGR\nmFMgEBGJOQUCEZGYUyAQEYk5BQKpVWbW0My2m1nH2sybTWZ2jJnV+nXWZnaqma1Kml5uZoPTyVuD\ndf3OzG6o6fcrWe4vzOzh2l6u1K1G2S6AZJeZbU+azAO+BHZH05e7e1F1lufuu4EWtZ03Dtz92NpY\njpldBpzv7kOTln1ZbSxb6icFgphz99IDcXTGeZm7/19F+c2skbuX1EXZRKRuqGlIKhVV/Z8ws8fN\n7DPgfDM7wcz+ZWZbzGydmU00s8ZR/kZm5mZWEE1Pjea/YGafmdk/zaxzdfNG808zs/fMbKuZPWBm\nr5vZxRWUO50yXm5mK8xss5lNTPpuQzO7z8w2mdlKYHglv8+NZjatXNokM7s3Gr/MzJZF2/NBdLZe\n0bKKzWxoNJ5nZo9GZVsC9C+X9yYzWxktd4mZnRWl9wIeBAZHzW4bk37b25K+f0W07ZvM7GkzOzyd\n36YqZjYyKs8WM3vJzI5NmneDma01s21m9m7Sth5vZguj9E/N7O501ye1xN01aMDdAVYBp5ZL+wXw\nFXAm4cThIODrwEBCjfIo4D3gqih/I8CBgmh6KrARKAQaA08AU2uQ92vAZ8CIaN51wC7g4gq2JZ0y\nPgO0AgqAfye2HbgKWALkA22BOeFfJeV6jgK2A82Tlr0eKIymz4zyGHAy8AXQO5p3KrAqaVnFwNBo\n/B7gZaAN0AlYWi7vucDh0T45LyrDodG8y4CXy5VzKnBbNP6NqIx9gGbAr4GX0vltUmz/L4CHo/Fu\nUTlOjvbRDcDyaLwHsBo4LMrbGTgqGp8HjInGWwIDs/2/ELdBNQJJx2vu/py773H3L9x9nrvPdfcS\nd18JTAaGVPL9J919vrvvAooIB6Dq5v1vYJG7PxPNu48QNFJKs4y/dPet7r6KcNBNrOtc4D53L3b3\nTcAdlaxnJfAOIUAB/Bew2d3nR/Ofc/eVHrwE/B1I2SFczrnAL9x9s7uvJpzlJ693uruvi/bJY4Qg\nXpjGcgHGAr9z90XuvhMYDwwxs/ykPBX9NpUZDTzr7i9F++gOQjAZCJQQgk6PqHnxw+i3gxDQu5hZ\nW3f/zN3nprkdUksUCCQdHydPmFlXM3vezD4xs23ABKBdJd//JGl8B5V3EFeU94jkcri7E86gU0qz\njGmti3AmW5nHgDHR+HnRdKIc/21mc83s32a2hXA2XtlvlXB4ZWUws4vN7K2oCWYL0DXN5ULYvtLl\nufs2YDPQISlPdfZZRcvdQ9hHHdx9OfAjwn5YHzU1HhZlvQToDiw3szfM7PQ0t0NqiQKBpKP8pZO/\nIZwFH+PuBwO3EJo+MmkdoakGADMz9j5wlbc/ZVwHHJk0XdXlrdOBU82sA6Fm8FhUxoOAJ4FfEppt\nWgN/S7Mcn1RUBjM7CngIuBJoGy333aTlVnWp61pCc1NieS0JTVBr0ihXdZbbgLDP1gC4+1R3H0Ro\nFmpI+F1w9+XuPprQ/Pc/wFNm1mw/yyLVoEAgNdES2Ap8bmbdgMvrYJ1/AfqZ2Zlm1gj4IdA+Q2Wc\nDlxjZh3MrC1wfWWZ3f0T4DXgYWC5u78fzWoKNAE2ALvN7L+BU6pRhhvMrLWF+yyuSprXgnCw30CI\nid8j1AgSPgXyE53jKTwOXGpmvc2sKeGA/Kq7V1jDqkaZzzKzodG6f0Lo15lrZt3MbFi0vi+iYQ9h\nAy4ws3ZRDWJrtG179rMsUg0KBFITPwIuIvyT/4bQqZtR7v4p8B3gXmATcDTwJuG+h9ou40OEtvy3\nCR2ZT6bxnccInb+lzULuvgW4FphB6HAdRQho6biVUDNZBbwA/DFpuYuBB4A3ojzHAsnt6i8C7wOf\nmllyE0/i+38lNNHMiL7fkdBvsF/cfQnhN3+IEKSGA2dF/QVNgbsI/TqfEGogN0ZfPR1YZuGqtHuA\n77j7V/tbHkmfhaZWkdxiZg0JTRGj3P3VbJdHJJepRiA5w8yGR00lTYGbCVebvJHlYonkPAUCySUn\nAisJzQ7fBEa6e0VNQyKSJjUNiYjEnGoEIiIxl3MPnWvXrp0XFBRkuxgiIjllwYIFG9095SXXORcI\nCgoKmD9/fraLISKSU8yswjvk1TQkIhJzCgQiIjGnQCAiEnMKBCIiMadAICIScwoEIiIxp0AgIhJz\nOXcfgWTW5s3w7rth2LQJvvEN6NULLNOvnRGRrFEgqGVffgmrVsHKlamHgw+Gfv32HvLz6/ZAu2cP\nfPxx2QF/2bKy8U8/3TvvT34CXbrAOeeE4bjjFBRE6puce+hcYWGhZ+vOYnfYtg2Ki/cekg/8a9aE\nfAnNmsFRR4Whc+dwxr1wYTjo7onewdS+/b7BoXPnfQ+47rB7N3z1VQg4ic8vv4TPPoMtW2Dr1oo/\nt26FjRthxQrYsaNsuW3aQLdu0LVr2WfXrtC8OTz7LDz5JMyeHdZ9zDEwalQICn37ZjcouMMnn4Tf\ncvny8DuedFL4FJG9mdkCdy9MOU+BYF9r1sDzz5cd6D/+uGx8+/Z98x92GBx9dBgSB/3EcNhhqQ+W\nn38OixfDm2+GwLBwIbzzDuzaFea3agUtWux70K/u7mrZMiyrdevw2aZNOJgnH/Dbt6/6gL5hAzz9\ndAgKf/97CApHHRWCwqhRUFiYuaCwaxd88MHeNZfEsG3bvvl79IChQ8MwZIgCgwgoEFTLiy/CmDGh\nfbxBAzj88NB0U9FwxBHQpEntrPvLL2HJkhAUFi2CnTvDsps23fszVdrBB+99wG/VKqQ1bFg7ZUu2\naRM88wz86U/wf/8HJSVhfY0ahUBV0QDh0wwaNw75Gzfedzx5euPGEARKSsrW36HDvrWX//iPEMBf\nfjkMr70Wgi0oMIiAAkFa3OHOO+HGG8MBpqgoHEAaqRelUps3h6Awb16YNqt8gPBbl5SEM/1du/Ye\nLz/dqlXYH4mD/rHHhlpOVXbtggULKg4MQ4aEZqSTTgrBXqS+UyCowrZtcMkl8Oc/w3e+A7/7XWiW\nkfpj165Q03r55dDf8frrZc18XbqUBYWTToJ0nnL++eehXyK5mWrNGujTJ9Q8TjoJDj10/8rsDh9+\nGJrhunTZv2WJKBBUYtkyOPtseP99uPtuuOYaXRUTByUlofltzpyyYfPmMK9jx7KgMHBgaAorf4XV\nxx+XLatBg9BfcuihYZmJmkfXrqHmkRiOOKLi8uzeHf4GE/1FiWHr1jD/ggvgl78MzWIiNaFAUIGn\nnoKLL4a8PHjiiXAmJ/G0Z0/on5kzB155JXyWv5S2efOyPonE0K1b6Hxv2jTkSTRJJZbx2mtlHdrH\nHFMWFLp2haVLQ95En1AigDRtGi7TTVxBtnIl3Hdf6O+54Qa47jo46KD9294NG0KzZ5s2+7ccyR0K\nBOWUlMBNN4U+gYEDw5Uw+fm1VECpF9zDGfq8eeFMv2vXcDZe3dpiSQm89VYIDK+8Aq++WlbzgBBc\n+vbd+9Lhrl1DR3mylSvDPR1//nNourrnnlCTrU55du2CmTPh978Pnw0awJlnhmbR4cPVH1bfKRAk\n2bgRRo8Ol0Befjn86ldlZ3MimbZnD7z9driXo0eP0PZfnSu7Zs8OzZeLF4eaxa9+FWoPlXnvvXDw\nf+SRUMs5/HC46KJwSfKjj4bawaGHhuanSy6B7t2rt01btoQA9/LLMHcu9OwZ+tpOOikzV61JzVQW\nCHD3nBr69+/vNTVvnnvHju5Nm7r//vc1XoxIVu3a5f7QQ+5t27o3aOB++eXu69fvnWf7dveHH3Yf\nPDhcvNuwofuIEe7PPhu+n/DVV+5PPx3mNWoU8g4Y4P7rX7v/+9+p179li/tzz7n/6Efu/fuHMoB7\nkybhu3l5YfrQQ92//333OXPcd++u/nZu2eI+c6b7T3/qPmqU+8SJ7qtXV385EgDzvYLjamxqBI89\nBt/9bjjzeeqpcAOUSC7bvBkmTIAHHwxNTLfeCv/5nzBlCjz+eOib6NIFLr0ULryw6stk168Pl01P\nmRJqLU2bwsiRofawe3fZpbgLF4aaTZMmcMIJZfdoDBwY+i527Ag3ZD7xRPjcuTN0lJ9zTqgpDBwY\nmqXKW7s29Km8+moYFi8OTXSNGoWyJzro+/eHb30rlK1799q7uCPx5IANG1IPjRuH+1USQzo3Yh5I\n1DREqFLfeSdMnQrt2mWgYCJZ8u67cO218Ne/humDDgoH3UsvhcGDq3+wcg8H+4cfDoEh0afRpAkc\nf3w46A8bVnbgr8z27fDcczB9OrzwQrhp8sgj4dxz4YwzQt9H4sC/cmX4Tl5eCDCDB4dh4MAQ6JYv\nD3e3P/00/OtfIe8xx4SA8K1vhbKlCjAQAte6deFy3MSwalV4WsCGDSEIbtwYmstSycsru7cloXXr\nvQPDsceGzy5dQv4vvwxBMTF8/vne06mGivIk0m++Ofx2NaFAEEnc1SpSH734YriXYeTIcCNebfjy\nS/jb38KB+IQT9u9qpW3bwrOrnngCZs0qO6i2axcO+CeeGD779Nm3s7y8tWvDsmbMgJdeCp3yhx4K\nI0aEWtG6deFAnzjor16970H+8MNDUPra18LZfeIz1ZCXF9bx0UchIL33XhgS48mXE0M4zlT30GoW\n1lPZcPnl8M1vVm+5ZctXIBCRA0iig7lLl3AmvT8naFu2hNrGjBnhM3GjYNu24eGNnTuHK60S4507\nQ6dO4YGQtWXHjnABQCIw7NxZdvBu3nzvg3ny9EEHlU03a5bZE1UFAhGJhZ07Qw0gPz+9R5HESWWB\nQFcOi0i90axZuMlPqkevqhQRiTkFAhGRmFMgEBGJOQUCEZGYy1ggMLM/mNl6M3ungvlmZhPNbIWZ\nLTazfpkqi4iIVCyTNYKHgeGVzD8N6BIN44CHMlgWERGpQMYCgbvPAf5dSZYRwB+j5yH9C2htZnpp\noIhIHctmH0EHIPnG7OIobR9mNs7M5pvZ/A0bNtRJ4URE4iInOovdfbK7F7p7Yfv27bNdHBGReiWb\ngWANcGTSdH6UJiIidSibgeBZ4MLo6qHjga3uvi6L5RERiaWMPWvIzB4HhgLtzKwYuBVoDODu/wvM\nBE4HVgA7gEsyVRYREalYxgKBu4+pYr4D38/U+kVEJD050VksIiKZo0AgIhJzCgQiIjGnQCAiEnMK\nBCIiMadAICIScwoEIiIxp0AgIhJzCgQiIjGnQCAiEnMKBCIiMadAICIScwoEIiIxp0AgIhJzCgQi\nIjGnQCAiEnMKBCIiMadAICIScwoEIiIxp0AgIhJzCgQiIjGnQCAiEnMKBCIiMadAICIScwoEIiIx\np0AgIhJzGQ0EZjbczJab2QozG59ifkczm21mb5rZYjM7PZPlERGRfWUsEJhZQ2AScBrQHRhjZt3L\nZbsJmO7ufYHRwK8zVR4REUktkzWCAcAKd1/p7l8B04AR5fI4cHA03gpYm8HyiIhICpkMBB2Aj5Om\ni6O0ZLcB55tZMTAT+EGqBZnZODObb2bzN2zYkImyiojEVrY7i8cAD7t7PnA68KiZ7VMmd5/s7oXu\nXti+ffs6L6SISH2WyUCwBjgyaTo/Skt2KTAdwN3/CTQD2mWwTCIiUk4mA8E8oIuZdTazJoTO4GfL\n5fkIOAXAzLoRAoHafkRE6lDGAoG7lwBXAbOAZYSrg5aY2QQzOyvK9iPge2b2FvA4cLG7e6bKJCIi\n+2qUyYW7+0xCJ3By2i1J40uBQZksg4iIVC7bncUiIpJlCgQiIjGnQCAiEnMKBCIiMadAICIScwoE\nIiIxp0AgIhJzCgQiIjGnQCAiEnMKBCIiMadAICIScwoEIiIxp0AgIhJzCgQiIjGnQCAiEnMKBCIi\nMadAICIScwoEIiIxl9FXVYpI7tu1axfFxcXs3Lkz20WRNDRr1oz8/HwaN26c9ncUCESkUsXFxbRs\n2ZKCggLMLNvFkUq4O5s2baK4uJjOnTun/T01DYlIpXbu3Enbtm0VBHKAmdG2bdtq194UCESkSgoC\nuaMm+0qBQEQOaJs2baJPnz706dOHww47jA4dOpROf/XVV2kt45JLLmH58uWV5pk0aRJFRUW1UWRO\nPPFEFi1aVCvLqgvqIxCRWlVUBDfeCB99BB07wu23w9ixNV9e27ZtSw+qt912Gy1atODHP/7xXnnc\nHXenQYPU57ZTpkypcj3f//73a17IHKcagYjUmqIiGDcOVq8G9/A5blxIr20rVqyge/fujB07lh49\nerBu3TrGjRtHYWEhPXr0YMKECaV5E2foJSUltG7dmvHjx3PcccdxwgknsH79egBuuukm7r///tL8\n48ePZ8CAARx77LH84x//AODzzz/n29/+Nt27d2fUqFEUFhZWeeY/depUevXqRc+ePbnhhhsAKCkp\n4YILLihNnzhxIgD33Xcf3bt3p3fv3px//vm1/ptVJBaBoKgICgqgQYPwmYk/ShEJNYEdO/ZO27Ej\npGfCu+++y7XXXsvSpUvp0KEDd9xxB/Pnz+ett97ixRdfZOnSpft8Z+vWrQwZMoS33nqLE044gT/8\n4Q8pl+3uvPHGG9x9992lQeWBBx7gsMMOY+nSpdx88828+eablZavuLiYm266idmzZ/Pmm2/y+uuv\n85e//IUFCxawceNG3n77bd555x0uvPBCAO666y4WLVrE4sWLefDBB/fz10lfWoHAzI42s6bR+FAz\nu9rMWqfxveFmttzMVpjZ+ArynGtmS81siZk9Vr3iV60uz1BE4u6jj6qXvr+OPvpoCgsLS6cff/xx\n+vXrR79+/Vi2bFnKQHDQQQdx2mmnAdC/f39WrVqVctlnn332Pnlee+01Ro8eDcBxxx1Hjx49Ki3f\n3LlzOfnkk2nXrh2NGzfmvPPOY86cORxzzDEsX76cq6++mlmzZtGqVSsAevTowfnnn09RUVG17gPY\nX+nWCJ4CdpvZMcBk4Eig0oO2mTUEJgGnAd2BMWbWvVyeLsBPgUHu3gO4pnrFr1pdn6GIxFnHjtVL\n31/NmzcvHX///ff51a9+xUsvvcTixYsZPnx4yssomzRpUjresGFDSkpKUi67adOmVeapqbZt27J4\n8WIGDx7MpEmTuPzyywGYNWsWV1xxBfPmzWPAgAHs3r27VtdbkXQDwR53LwFGAg+4+0+Aw6v4zgBg\nhbuvdPevgGnAiHJ5vgdMcvfNAO6+Pv2ip6euz1BE4uz22yEvb++0vLyQnmnbtm2jZcuWHHzwwaxb\nt45Zs2bV+joGDRrE9OnTAXj77bdT1jiSDRw4kNmzZ7Np0yZKSkqYNm0aQ4YMYcOGDbg755xzDhMm\nTGDhwoXs3r2b4uJiTj75ZO666y42btzIjvJnsRmS7lVDu8xsDHARcGaUVlW9pQPwcdJ0MTCwXJ7/\nADCz14GGwG3u/tfyCzKzccA4gI7VPLXo2DE0B6VKF5Halbg6qDavGkpXv3796N69O127dqVTp04M\nGjSo1tfxgx/8gAsvvJDu3buXDolmnVTy8/P5+c9/ztChQ3F3zjzzTM444wwWLlzIpZdeirtjZtx5\n552UlJRw3nnn8dlnn7Fnzx5+/OMf07Jly1rfhpQSl11VNhCadiYCY6LpzsD1VXxnFPC7pOkLgAfL\n5fkLMIMQVDoTAkfrypbbv39/r46pU93z8txDD0EY8vJCuohUbenSpdkuwgFj165d/sUXX7i7+3vv\nvecFBQW+a9euLJdqX6n2GTDfKziuplUjcPelwNUAZtYGaOnud1bxtTWEvoSE/CgtWTEw1913AR+a\n2XtAF2BeOuVKRzbPUESkftm+fTunnHIKJSUluDu/+c1vaNQo92/HSmsLzOxl4Kwo/wJgvZm97u7X\nVfK1eUAXM+tMCACjgfPK5XkaGANMMbN2hKaildXagjSMHasDv4jsv9atW7NgwYJsF6PWpdtZ3Mrd\ntwFnA39094HAqZV9wUPn8lXALGAZMN3dl5jZBDM7K8o2C9hkZkuB2cBP3H1TTTZERERqJt06TSMz\nOxw4F0j7wkt3nwnMLJd2S9K4A9dFg4iIZEG6NYIJhLP3D9x9npkdBbyfuWKJiEhdSbez+E/An5Km\nVwLfzlShRESk7qT7iIl8M5thZuuj4Skzy8904UREhg0bts/NYffffz9XXnllpd9r0aIFAGvXrmXU\nqFEp8wwdOpT58+dXupz7779/rxu7Tj/9dLZs2ZJO0St12223cc899+z3cmpDuk1DU4BngSOi4bko\nTUQko8aMGcO0adP2Sps2bRpjxoxJ6/tHHHEETz75ZI3XXz4QzJw5k9atq3zUWk5JNxC0d/cp7l4S\nDQ8D7TNYLhERAEaNGsXzzz9f+hKaVatWsXbtWgYPHlx6XX+/fv3o1asXzzzzzD7fX7VqFT179gTg\niy++YPTo0XTr1o2RI0fyxRdflOa78sorSx9hfeuttwIwceJE1q5dy7Bhwxg2bBgABQUFbNy4EYB7\n772Xnj170rNnz9JHWK9atYpu3brxve99jx49evCNb3xjr/WksmjRIo4//nh69+7NyJEj2bx5c+n6\nE4+lTjzs7pVXXil9MU/fvn357LPPavzbJqR71dAmMzsfeDyaHgPoMk+RmLnmGqjtF2/16QPRMTSl\nQw45hAEDBvDCCy8wYsQIpk2bxrnnnouZ0axZM2bMmMHBBx/Mxo0bOf744znrrLMqfF3jQw89RF5e\nHsuWLWPx4sX069evdN7tt9/OIYccwu7duznllFNYvHgxV199Nffeey+zZ8+mXbt2ey1rwYIFTJky\nhblz5+LuDBw4kCFDhtCmTRvef/99Hn/8cX77299y7rnn8tRTT1X6foELL7yQBx54gCFDhnDLLbfw\ns5/9jPvvv5877riDDz/8kKZNm5Y2R91zzz1MmjSJQYMGsX37dpo1a1aNXzu1dGsE3yVcOvoJsI7w\n+IiL93vtIiJpSG4eSm4WcnduuOEGevfuzamnnsqaNWv49NNPK1zOnDlzSg/IvXv3pnfv3qXzpk+f\nTr9+/ejbty9Lliyp8oFyr732GiNHjqR58+a0aNGCs88+m1dffRWAzp0706dPH6DyR11DeD/Cli1b\nGDJkCAAXXXQRc+bMKS3j2LFjmTp1aukdzIMGDeK6665j4sSJbNmypVbubE73qqHVhDuLS5nZNUAl\ncVxE6pvKztwzacSIEVx77bUsXLiQHTt20L9/fwCKiorYsGEDCxYsoHHjxhQUFKR89HRVPvzwQ+65\n5x7mzZtHmzZtuPjii2u0nITEI6whPMa6qqahijz//PPMmTOH5557jttvv523336b8ePHc8YZZzBz\n5kwGDRrErFmz6Nq1a43LCvv3hjLdBCYidaJFixYMGzaM7373u3t1Em/dupWvfe1rNG7cmNmzZ7M6\n1aOGk5x00kk89lh4lco777zD4sWLgfAI6+bNm9OqVSs+/fRTXnjhhdLvtGzZMmU7/ODBg3n66afZ\nsWMHn3/+OTNmzGDw4MHV3rZWrVrRpk2b0trEo48+ypAhQ9izZw8ff/wxw4YN484772Tr1q1s376d\nDz74gF69enH99dfz9a9/nXfffbfa6yxvf+oUqRvhREQyYMyYMYwcOXKvK4jGjh3LmWeeSa9evSgs\nLKzyzPjKK6/kkksuoVu3bnTr1q20ZnHcccfRt29funbtypFHHrnXI6zHjRvH8OHDOeKII5g9e3Zp\ner9+/bj44osZMGAAAJdddhl9+/attBmoIo888ghXXHEFO3bs4KijjmLKlCns3r2b888/n61bt+Lu\nXH311bRu3Zqbb76Z2bNn06BBA3r06FH6trX9YeEpDzX4otlH7l7nT/UvLCz0qq77FZHas2zZMrp1\n65btYkg1pNpnZrbA3QtT5a+0RmBmnwGpIoUBB9W0kCIicuCoNBC4ex29HkdERLJlfzqLRUSkHlAg\nEJEq1bQvUepeTfaVAoGIVKpZs2Zs2rRJwSAHuDubNm2q9t3Guf+yTRHJqPz8fIqLi9mwYUO2iyJp\naNasGfn51Xs4tAKBiFSqcePGdO7cOdvFkAxS05CISMwpEIiIxJwCgYhIzCkQiIjEnAKBiEjMKRCI\niMScAoGISMwpEIiIxJwCgYhIzGU0EJjZcDNbbmYrzGx8Jfm+bWZuZilfmiAiIpmTsUBgZg2BScBp\nQHdgjJl1T5GvJfBDYG6myiIiIhXLZI1gALDC3Ve6+1fANGBEinw/B+4EdmawLCIiUoFMBoIOwMdJ\n08VRWikz6wcc6e7PV7YgMxtnZvPNbL6egCgiUruy1llsZg2Ae4EfVZXX3Se7e6G7F7Zv3z7zhRMR\niZFMBoI1wJFJ0/lRWkJLoCfwspmtAo4HnlWHsYhI3cpkIJgHdDGzzmbWBBgNPJuY6e5b3b2duxe4\newHwL+Asd5+fwTKJiEg5GQsE7l4CXAXMApYB0919iZlNMLOzMrVeERGpnoy+oczdZwIzy6XdUkHe\noZksi4iIpKY7i0VEYk6BQEQk5hQIRERiToFARCTmFAhERGJOgUBEJOYUCEREYk6BQEQk5hQIRERi\nToGgnKIiKCiABg3CZ1FRtkskIpJZGX3ERK4pKoJx42DHjjC9enWYBhg7NnvlEhHJJNUIktx4Y1kQ\nSNixI6SLiNRXCgRJPvqoeukiIvWBAkGSjh2rly4iUh8oECS5/XbIy9s7LS8vpIuI1FcKBEnGjoXJ\nk6FTJzALn5Mnq6NYROo3XTVUztixOvCLSLyoRiAiEnMKBCIiMadAICIScwoEIiIxp0AgIhJzCgQi\nIjGnQCAiEnMKBCIiMadAICIScxkNBGY23MyWm9kKMxufYv51ZrbUzBab2d/NrFMmyyMiIvvKWCAw\ns4bAJOA0oDswxsy6l8v2JvrypzAAAAleSURBVFDo7r2BJ4G7MlUeERFJLZM1ggHACndf6e5fAdOA\nEckZ3H22uydeBfMvID+D5RERkRQyGQg6AB8nTRdHaRW5FHgh1QwzG2dm881s/oYNG2qxiCIickB0\nFpvZ+UAhcHeq+e4+2d0L3b2wffv2dVs4EZF6LpOPoV4DHJk0nR+l7cXMTgVuBIa4+5cZLI+IiKSQ\nyRrBPKCLmXU2sybAaODZ5Axm1hf4DXCWu6/PYFlERKQCGQsE7l4CXAXMApYB0919iZlNMLOzomx3\nAy2AP5nZIjN7toLFiYhIhmT0DWXuPhOYWS7tlqTxUzO5fhERqdoB0VksIiLZo0AgIhJzCgQiIjGn\nQCAiEnMKBCIiMadAICIScwoEIiIxp0CwH4qKoKAAGjQIn0VF2S6RiEj1ZfSGsvqsqAjGjYMd0UO0\nV68O0wBjx2avXCIi1aUaQQ3deGNZEEjYsSOki4jkEgWCGvroo+qli4gcqBQIaqhjx+qli4gcqBQI\nauj22yEvb++0vLyQLiKSSxQIamjsWJg8GTp1ArPwOXmyOopFJPfoqqH9MHasDvwikvtUIxARiTkF\nAhGRmFMgEBGJOQWCOqLHUYjIgUqdxXVAj6MQkQOZagR1QI+jEJEDmQJBHaju4yjUjCQidUmBoA5U\n53EUiWak1avBvawZqaJgUJ2goQCTmd8rU/tA+1bqjLvn1NC/f3/PNVOnuufluYdDexjy8kJ6eZ06\n7Z0vMXTqtH/LrW7eTp3czcJnqjy5mDcTv1cm90Em8lbn9zpQ8krtAOZ7BcfVrB/YqzvkYiBwT/8P\n3yx1IDDbN291gka6eQ+Eg1Wm8mbi98rEMjOZ90DYDzopyWzeiigQ5JDq/FNXJ2ikm/dAOFhlKm8m\nfq9MLDOTeQ+E/aCTkszW+CqStUAADAeWAyuA8SnmNwWeiObPBQqqWmZ9DwTZPsM9EA5WuXQQzPbB\nsrp5D4T9oJOSzOWtTFYCAdAQ+AA4CmgCvAV0L5fn/wH/G42PBp6oarn1PRC4Z7fN+0D4Y86lZpED\n4Sww2ycPmcqb7UCUi3krk61AcAIwK2n6p8BPy+WZBZwQjTcCNgJW2XLjEAiqo7bbGQ+Eg1WudZQe\nCO3C2Tx5yFTebAeiXMxbmWwFglHA75KmLwAeLJfnHSA/afoDoF2KZY0D5gPzO3bsWL2tl2rL9sEq\nk3nlwNgPcT8piU0fQW0GguRBNQKR+MiVoHUg5a1IZYHAwvzaZ2YnALe5+zej6Z8CuPsvk/LMivL8\n08waAZ8A7b2SQhUWFvr8+fMzUmYRkfrKzBa4e2GqeZm8s3ge0MXMOptZE0Jn8LPl8jwLXBSNjwJe\nqiwIiIhI7cvY00fdvcTMriJ0CDcE/uDuS8xsAqGK8izwe+BRM1sB/JsQLEREpA5l9DHU7j4TmFku\n7Zak8Z3AOZksg4iIVE4PnRMRiTkFAhGRmMvYVUOZYmYbgNXZLsd+aEe4ca6+qa/bBfV327RduWd/\ntq2Tu7dPNSPnAkGuM7P5FV3Clcvq63ZB/d02bVfuydS2qWlIRCTmFAhERGJOgaDuTc52ATKkvm4X\n1N9t03blnoxsm/oIRERiTjUCEZGYUyAQEYk5BYI6ZGarzOxtM1tkZjn7CFUz+4OZrTezd5LSDjGz\nF83s/eizTTbLWBMVbNdtZrYm2meLzOz0bJaxJszsSDObbWZLzWyJmf0wSq8P+6yibcvp/WZmzczs\nDTN7K9qun0Xpnc1srpmtMLMnogd67v/61EdQd8xsFVDo7jl9s4uZnQRsB/7o7j2jtLuAf7v7HWY2\nHmjj7tdns5zVVcF23QZsd/d7slm2/WFmhwOHu/tCM2sJLAC+BVxM7u+zirbtXHJ4v5mZAc3dfbuZ\nNQZeA34IXAf82d2nmdn/Am+5+0P7uz7VCKTa3H0O4WmxyUYAj0TjjxD+GXNKBduV89x9nbsvjMY/\nA5YBHagf+6yibctp0btktkeTjaPBgZOBJ6P0WttnCgR1y4G/mdkCMxuX7cLUskPdfV00/glwaDYL\nU8uuMrPFUdNRzjWfJDOzAqAvMJd6ts/KbRvk+H4zs4ZmtghYD7xIeIPjFncvibIUU0tBT4Ggbp3o\n7v2A04DvR00R9U70cqH60ub4EHA00AdYB/xPdotTc2bWAngKuMbdtyXPy/V9lmLbcn6/uftud+8D\n5AMDgK6ZWpcCQR1y9zXR53pgBmHn1hefRu21iXbb9VkuT61w90+jf8g9wG/J0X0WtTM/BRS5+5+j\n5Hqxz1JtW33ZbwDuvgWYDZwAtI5e6wshQKypjXUoENQRM2sedWZhZs2BbwDvVP6tnJL82tGLgGey\nWJZakzhQRkaSg/ss6nj8PbDM3e9NmpXz+6yibcv1/WZm7c2sdTR+EPBfhP6P2YTX+kIt7jNdNVRH\nzOwoQi0AwpvhHnP327NYpBozs8eBoYRH4n4K3Ao8DUwHOhIeE36uu+dUx2sF2zWU0LzgwCrg8qR2\n9ZxgZicCrwJvA3ui5BsIbem5vs8q2rYx5PB+M7PehM7ghoQT9unuPiE6jkwDDgHeBM539y/3e30K\nBCIi8aamIRGRmFMgEBGJOQUCEZGYUyAQEYk5BQIRkZhTIBCJmNnupKdVLooexFZbyy5IfqqpyIGk\nUdVZRGLji+iWfpFYUY1ApArReyTuit4l8YaZHROlF5jZS9GDzf5uZh2j9EPNbEb0LPm3zOw/o0U1\nNLPfRs+X/1t0xyhmdnX0PP3FZjYtS5spMaZAIFLmoHJNQ99JmrfV3XsBDwL3R2kPAI+4e2+gCJgY\npU8EXnH344B+wJIovQswyd17AFuAb0fp44G+0XKuyNTGiVREdxaLRMxsu7u3SJG+CjjZ3VdGDzj7\nxN3bmtlGwktRdkXp69y9nZltAPKTb/2PHpH8ort3iaavBxq7+y/M7K+EF+I8DTyd9Bx6kTqhGoFI\neryC8epIfibMbsr66M4AJhFqD/OSni4pUicUCETS852kz39G4/8ARkfjYwkPPwP4O3AllL5cpFVF\nCzWzBsCR7j4buB5oBexTKxHJJJ15iJQ5KHojVMJf3T1xCWkbM1tMOKsfE6X9AJhiZj8BNgCXROk/\nBCab2aWEM/8rCS9HSaUhMDUKFgZMjJ4/L1Jn1EcgUoWoj6DQ3TdmuywimaCmIRGRmFONQEQk5lQj\nEBGJOQUCEZGYUyAQEYk5BQIRkZhTIBARibn/D+X1MQ9Kt8DcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8559486607142855\n",
      "Time:  37\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "mlp = MLP_AnomalyDetection.from_DataFrame(df_synthetic,100,5,30,0.3,'mahalanobis')\n",
    "mlp.fit()\n",
    "# mlp.plot()\n",
    "mlp.get_roc_auc(verbose=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bUVzcvVZ7xGJ",
    "outputId": "858a8c8a-1234-4f8f-c60a-275a9e53783e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 798 samples, validate on 79 samples\n",
      "Epoch 1/30\n",
      "798/798 [==============================] - 4s 5ms/step - loss: 1.1239 - val_loss: 1.0200\n",
      "Epoch 2/30\n",
      "798/798 [==============================] - 0s 199us/step - loss: 0.6205 - val_loss: 1.1462\n",
      "Epoch 3/30\n",
      "798/798 [==============================] - 0s 200us/step - loss: 0.3025 - val_loss: 1.1949\n",
      "Epoch 4/30\n",
      "798/798 [==============================] - 0s 195us/step - loss: 0.1096 - val_loss: 1.2040\n",
      "Epoch 5/30\n",
      "798/798 [==============================] - 0s 191us/step - loss: 0.0454 - val_loss: 1.2283\n",
      "Epoch 6/30\n",
      "798/798 [==============================] - 0s 186us/step - loss: 0.0273 - val_loss: 1.1940\n",
      "Epoch 7/30\n",
      "798/798 [==============================] - 0s 185us/step - loss: 0.0205 - val_loss: 1.1989\n",
      "Epoch 8/30\n",
      "798/798 [==============================] - 0s 187us/step - loss: 0.0201 - val_loss: 1.2199\n",
      "Epoch 9/30\n",
      "798/798 [==============================] - 0s 191us/step - loss: 0.0197 - val_loss: 1.2012\n",
      "Epoch 10/30\n",
      "798/798 [==============================] - 0s 194us/step - loss: 0.0194 - val_loss: 1.1985\n",
      "Epoch 11/30\n",
      "798/798 [==============================] - 0s 186us/step - loss: 0.0199 - val_loss: 1.1923\n",
      "Epoch 12/30\n",
      "798/798 [==============================] - 0s 189us/step - loss: 0.0212 - val_loss: 1.1994\n",
      "Epoch 13/30\n",
      "798/798 [==============================] - ETA: 0s - loss: 0.025 - 0s 190us/step - loss: 0.0237 - val_loss: 1.1977\n",
      "Epoch 14/30\n",
      "798/798 [==============================] - 0s 189us/step - loss: 0.0274 - val_loss: 1.1977\n",
      "Epoch 15/30\n",
      "798/798 [==============================] - 0s 194us/step - loss: 0.0266 - val_loss: 1.1716\n",
      "Epoch 16/30\n",
      "798/798 [==============================] - 0s 199us/step - loss: 0.0273 - val_loss: 1.1870\n",
      "Epoch 17/30\n",
      "798/798 [==============================] - 0s 190us/step - loss: 0.0285 - val_loss: 1.1593\n",
      "Epoch 18/30\n",
      "798/798 [==============================] - 0s 190us/step - loss: 0.0261 - val_loss: 1.1825\n",
      "Epoch 19/30\n",
      "798/798 [==============================] - 0s 191us/step - loss: 0.0234 - val_loss: 1.1692\n",
      "Epoch 20/30\n",
      "798/798 [==============================] - 0s 190us/step - loss: 0.0213 - val_loss: 1.1629\n",
      "Epoch 21/30\n",
      "798/798 [==============================] - 0s 189us/step - loss: 0.0190 - val_loss: 1.1627\n",
      "Epoch 22/30\n",
      "798/798 [==============================] - 0s 186us/step - loss: 0.0167 - val_loss: 1.1637\n",
      "Epoch 23/30\n",
      "798/798 [==============================] - 0s 191us/step - loss: 0.0150 - val_loss: 1.1671\n",
      "Epoch 24/30\n",
      "798/798 [==============================] - 0s 195us/step - loss: 0.0138 - val_loss: 1.1564\n",
      "Epoch 25/30\n",
      "798/798 [==============================] - 0s 200us/step - loss: 0.0130 - val_loss: 1.1485\n",
      "Epoch 26/30\n",
      "798/798 [==============================] - 0s 204us/step - loss: 0.0121 - val_loss: 1.1554\n",
      "Epoch 27/30\n",
      "798/798 [==============================] - 0s 346us/step - loss: 0.0100 - val_loss: 1.1500\n",
      "Epoch 28/30\n",
      "798/798 [==============================] - 0s 327us/step - loss: 0.0109 - val_loss: 1.1515\n",
      "Epoch 29/30\n",
      "798/798 [==============================] - 0s 312us/step - loss: 0.0122 - val_loss: 1.1443\n",
      "Epoch 30/30\n",
      "798/798 [==============================] - 0s 227us/step - loss: 0.0127 - val_loss: 1.1417\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8712016369047619\n",
      "Time:  11\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "mlp = MLP_AnomalyDetection.from_DataFrame(df_synthetic,100,5,30,0.3,'mahalanobis')\n",
    "mlp.fit()\n",
    "# mlp.plot()\n",
    "mlp.get_roc_auc(verbose=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DvAnHO0rAXf_",
    "outputId": "949610fe-3334-49b2-ae33-131b3f17137f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14627 samples, validate on 1462 samples\n",
      "Epoch 1/10\n",
      "14627/14627 [==============================] - 13s 882us/step - loss: 1.1327 - val_loss: 0.7145\n",
      "Epoch 2/10\n",
      "14627/14627 [==============================] - 4s 282us/step - loss: 1.1200 - val_loss: 0.7155\n",
      "Epoch 3/10\n",
      "14627/14627 [==============================] - 4s 281us/step - loss: 1.1050 - val_loss: 0.7173\n",
      "Epoch 4/10\n",
      "14627/14627 [==============================] - 4s 281us/step - loss: 1.0561 - val_loss: 0.7632\n",
      "Epoch 5/10\n",
      "14627/14627 [==============================] - 4s 281us/step - loss: 0.9777 - val_loss: 0.7452\n",
      "Epoch 6/10\n",
      "14627/14627 [==============================] - 4s 302us/step - loss: 0.8523 - val_loss: 0.7685\n",
      "Epoch 7/10\n",
      " 9408/14627 [==================>...........] - ETA: 1s - loss: 0.9106"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "mlp = MLP_AnomalyDetection.from_file('Multivariate/NASA_Shuttle/40902.csv',None,100,9,10,0.3,'mahalanobis')\n",
    "mlp.fit()\n",
    "# mlp.plot()\n",
    "mlp.get_roc_auc(verbose=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O5p7NRhm75L-"
   },
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PSymEs6-76Tf",
    "outputId": "a3725bbe-0016-43b4-c74b-ac704d695bc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 798 samples, validate on 79 samples\n",
      "Epoch 1/30\n",
      "798/798 [==============================] - 4s 5ms/step - loss: 1.1239 - val_loss: 1.0200\n",
      "Epoch 2/30\n",
      "798/798 [==============================] - 0s 222us/step - loss: 0.6205 - val_loss: 1.1462\n",
      "Epoch 3/30\n",
      "798/798 [==============================] - 0s 326us/step - loss: 0.3025 - val_loss: 1.1949\n",
      "Epoch 4/30\n",
      "798/798 [==============================] - 0s 156us/step - loss: 0.1096 - val_loss: 1.2040\n",
      "Epoch 5/30\n",
      "798/798 [==============================] - 0s 179us/step - loss: 0.0454 - val_loss: 1.2283\n",
      "Epoch 6/30\n",
      "798/798 [==============================] - 0s 191us/step - loss: 0.0273 - val_loss: 1.1940\n",
      "Epoch 7/30\n",
      "798/798 [==============================] - 0s 186us/step - loss: 0.0205 - val_loss: 1.1989\n",
      "Epoch 8/30\n",
      "798/798 [==============================] - 0s 200us/step - loss: 0.0201 - val_loss: 1.2199\n",
      "Epoch 9/30\n",
      "798/798 [==============================] - 0s 191us/step - loss: 0.0197 - val_loss: 1.2012\n",
      "Epoch 10/30\n",
      "798/798 [==============================] - 0s 355us/step - loss: 0.0194 - val_loss: 1.1985\n",
      "Epoch 11/30\n",
      "798/798 [==============================] - 0s 177us/step - loss: 0.0199 - val_loss: 1.1923\n",
      "Epoch 12/30\n",
      "798/798 [==============================] - 0s 187us/step - loss: 0.0212 - val_loss: 1.1994\n",
      "Epoch 13/30\n",
      "798/798 [==============================] - 0s 179us/step - loss: 0.0237 - val_loss: 1.1977\n",
      "Epoch 14/30\n",
      "798/798 [==============================] - 0s 205us/step - loss: 0.0274 - val_loss: 1.1977\n",
      "Epoch 15/30\n",
      "798/798 [==============================] - 0s 391us/step - loss: 0.0266 - val_loss: 1.1716\n",
      "Epoch 16/30\n",
      "798/798 [==============================] - 0s 357us/step - loss: 0.0273 - val_loss: 1.1870\n",
      "Epoch 17/30\n",
      "798/798 [==============================] - 0s 276us/step - loss: 0.0285 - val_loss: 1.1593\n",
      "Epoch 18/30\n",
      "798/798 [==============================] - 0s 329us/step - loss: 0.0261 - val_loss: 1.1825\n",
      "Epoch 19/30\n",
      "798/798 [==============================] - 0s 170us/step - loss: 0.0234 - val_loss: 1.1692\n",
      "Epoch 20/30\n",
      "798/798 [==============================] - 0s 189us/step - loss: 0.0213 - val_loss: 1.1629\n",
      "Epoch 21/30\n",
      "798/798 [==============================] - 0s 200us/step - loss: 0.0190 - val_loss: 1.1627\n",
      "Epoch 22/30\n",
      "798/798 [==============================] - 0s 189us/step - loss: 0.0167 - val_loss: 1.1637\n",
      "Epoch 23/30\n",
      "798/798 [==============================] - 0s 190us/step - loss: 0.0150 - val_loss: 1.1671\n",
      "Epoch 24/30\n",
      "798/798 [==============================] - 0s 184us/step - loss: 0.0138 - val_loss: 1.1564\n",
      "Epoch 25/30\n",
      "798/798 [==============================] - 0s 195us/step - loss: 0.0130 - val_loss: 1.1485\n",
      "Epoch 26/30\n",
      "798/798 [==============================] - 0s 200us/step - loss: 0.0121 - val_loss: 1.1554\n",
      "Epoch 27/30\n",
      "798/798 [==============================] - 0s 190us/step - loss: 0.0100 - val_loss: 1.1500\n",
      "Epoch 28/30\n",
      "798/798 [==============================] - 0s 197us/step - loss: 0.0109 - val_loss: 1.1515\n",
      "Epoch 29/30\n",
      "798/798 [==============================] - 0s 201us/step - loss: 0.0122 - val_loss: 1.1443\n",
      "Epoch 30/30\n",
      "798/798 [==============================] - 0s 189us/step - loss: 0.0127 - val_loss: 1.1417\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXwV9b3/8dfHALIKCLiBLC5VFgOEFLGggPqzoHXfQFyrUmxtbW1/P7lqW2vrvdZ61Yu1KrViKxHq1brUqnSRFpdbNXgRRURQAQMUAspmUEz4/P74TsIhOQknIZOTk3k/H495nJk53/Od75xJ5j37MXdHRESSa69sN0BERLJLQSAiknAKAhGRhFMQiIgknIJARCThFAQiIgmnIJBGZWZ5ZrbVzHo3ZtlsMrPDzKzRr7M2sxPNbHnK8BIzOzaTsg2Y1gNmdn1DP19HvT8zs4cau15pWq2y3QDJLjPbmjLYHvgcqIiGv+HuRfWpz90rgI6NXTYJ3P2IxqjHzK4ALnT3MSl1X9EYdUvLpCBIOHevWhFHW5xXuPtfaytvZq3cvbwp2iYiTUOHhqRO0a7/781slpltAS40s2PM7J9mttHM1pjZNDNrHZVvZWZuZn2j4ZnR+8+Z2RYz+x8z61ffstH7483sPTPbZGZ3m9nLZnZpLe3OpI3fMLNlZvaJmU1L+Wyemd1pZhvM7H1gXB3fz41mNrvauHvM7I6o/wozWxzNz/vR1nptdZWY2Ziov72ZPRy1bREwLM10P4jqXWRmp0XjjwJ+CRwbHXZbn/Ld3pTy+SnRvG8wsyfN7MBMvpvdMbMzovZsNLMXzOyIlPeuN7PVZrbZzN5NmdcRZvZGNH6tmf0i0+lJI3F3depwd4DlwInVxv0M2A6cSthwaAd8GTiasEd5CPAecHVUvhXgQN9oeCawHigEWgO/B2Y2oOx+wBbg9Oi9a4EvgEtrmZdM2vgU0BnoC3xcOe/A1cAioBfQDZgX/lXSTucQYCvQIaXudUBhNHxqVMaA44FtQH703onA8pS6SoAxUf/twN+BrkAf4J1qZc8DDoyWyQVRG/aP3rsC+Hu1ds4Ebor6T4raOARoC/wKeCGT7ybN/P8MeCjq7x+14/hoGV0ffe+tgYHACuCAqGw/4JCo/3VgYtTfCTg62/8LSeu0RyCZeMnd/+juO9x9m7u/7u6vunu5u38ATAdG1/H5x9y92N2/AIoIK6D6lv0asMDdn4reu5MQGmll2Mb/cPdN7r6csNKtnNZ5wJ3uXuLuG4Bb65jOB8DbhIAC+D/ARncvjt7/o7t/4MELwN+AtCeEqzkP+Jm7f+LuKwhb+anTfdTd10TL5BFCiBdmUC/AJOABd1/g7p8BU4HRZtYrpUxt301dJgBPu/sL0TK6FdiHEMjlhNAZGB1e/DD67iAE+uFm1s3dt7j7qxnOhzQSBYFk4qPUATM70sz+ZGb/MrPNwM1A9zo+/6+U/jLqPkFcW9mDUtvh7k7Ygk4rwzZmNC3ClmxdHgEmRv0XEAKssh1fM7NXzexjM9tI2Bqv67uqdGBdbTCzS83szegQzEbgyAzrhTB/VfW5+2bgE6BnSpn6LLPa6t1BWEY93X0J8H3CclgXHWo8ICp6GTAAWGJmr5nZyRnOhzQSBYFkovqlk/cTtoIPc/d9gB8RDn3EaQ3hUA0AZmbsuuKqbk/auAY4OGV4d5e3/h44MdqiPp0QDJhZO+Ax4D8Ih226AH/OsB3/qq0NZnYIcC9wFdAtqvfdlHp3d6nrasLhpsr6OhEOQa3KoF31qXcvwjJbBeDuM919JOGwUB7he8Hdl7j7BMLhv/8EHjeztnvYFqkHBYE0RCdgE/CpmfUHvtEE03wGKDCzU82sFXAN0COmNj4KfNfMeppZN+C6ugq7+1rgJWAGsMTdl0Zv7Q20AUqBCjP7GnBCPdpwvZl1sXCfxdUp73UkrOxLCZl4BWGPoNJaoFflyfE0ZgGXm1m+me1NWCG/6O617mHVo82nmdmYaNr/l3Be51Uz629mY6PpbYu6CsIMXGRm3aM9iE3RvO3Yw7ZIPSgIpCG+D1xC+Ce/n7BFHKtoZXs+cAewATgU+F/CfQ+N3cZ7Ccfy3yKcyHwsg888Qjj5+0hKmzcC3wOeIJxwPYcQaJn4MWHPZDnwHPC7lHoXAtOA16IyRwKpx9X/AiwF1ppZ6iGeys8/TzhE80T0+d6E8wZ7xN0XEb7zewkhNQ44LTpfsDdwG+G8zr8IeyA3Rh89GVhs4aq024Hz3X37nrZHMmfhUKtIbjGzPMKhiHPc/cVst0ckl2mPQHKGmY0zs87R4YUfEq5EeS3LzRLJeQoCySWjgA8IhxfGAWe4e22HhkQkQzo0JCKScNojEBFJuJx76Fz37t29b9++2W6GiEhOmT9//np3T3vJdc4FQd++fSkuLs52M0REcoqZ1XqHvA4NiYgknIJARCThFAQiIgmnIBARSTgFgYhIwikIREQSTkEgIpJwOXcfQa7auhWeegr23hvOPBPy8rLdIhGRQHsEMaqogDlz4MILYf/9w+u558JRR8F//zfsyMJPb6xbF9olIlJJQdDI3GHBAvj+96FXLxg3Dv70J7joInjppRAAZnDeeTB0aNhLiPO5f+4wfz788IchgPbfH/bbDyZMgIcegjVr4pu2iOSG2J4+amYPAl8D1rn7oDTvT2LnTwBuBa5y9zd3V29hYaE3x0dMrFoFRUXw8MPw9tvQujWcckoIgFNOCYeEKlVUwOzZcNNNsGwZFBbCT38KX/1qCIk9VV4OL74ITzwBTz4JH30Ee+0Fxx0HJ50E770Hzz8P/4p+uyo/PwTWuHEwciS0abPnbRCR5sXM5rt7Ydr3YgyC4wgr+N/VEgRfARa7+ydmNh64yd2P3l29zSEIPv4YPvgA3n8/dC+8EDp3GDECLr44bPF361Z3PeXlIThuvhmWL4evfCUEwvHH179NZWXw5z+Hlf8zz4Q2tm0bwuWMM+BrX4Pu3XeWd4eFC0MgzJkT9la++AI6dAjT/+pX4cQTw95Dhw4h2BojpEQkO7ISBNGE+wLPpAuCauW6Am+7e8/d1dlUQVBSErbWK1f2qd3GjbuWPewwuOCCcA7g8MPrP63t22HGjBACq1bBmDGhf+RI2LIFNmzY2X388a7DGzbA2rXwyiuwbRt07QqnnhpW/iedFFbimdiyBebODaHw3HPw4Ye7vp+XB+3bh/pSXyv7O3YMh5323x8OOCB0lf377Qetarks4Ysvwp5JSUmY9+rdli1hD6VNm7BXVVd/bdNIF2AFBeE7St1TE2nJciEIfgAc6e5X1PL+ZGAyQO/evYetWFHrQ/T22Mcfw5VXwh/+sHNcq1bQpw8cemjN7pBDMl/Z7s5nn8H06fDv/x5W7q1ahb2G2nTuHPY6unWDo48OVyMde2zYet8T7iEEX3oJNm2CTz8NexyVr6n9la+bN4cT0Vu21KzPLLSxMiDatYPVq8OKfu3amudI2rSBnj1D17lzCIvPPw+BuX37zv7q49KdBE/3511REers1i0curv8chhU51+oSO5r1kFgZmOBXwGj3H3D7uqMc49g3jyYNCmsnP7t32DUqLCy79279q3NOJSVwW9+E1aWlSv66l3Xrk3bpkx9+mn4/tauDVv6lV3q8LZtcNBBO1f2PXuGE+uV/d26xXsYqqIC/vY3eOCBcA7liy9CkF5xBZx/PnTqlHldH30EL78curfeCntzV14Z5qMxuIeQa9u2ceqT5Gq2QWBm+cATwHh3fy+TOuMIgvLycCjmZz8LW/izZ8OwYY06CWmmSkth5swQCu+8E/buJkwIoXD00bsGUkVFOK9SueJ/+eUQBBA+d/jh4YqxvLxw2Omb34SxYxsWasuWwaxZ4W/xnXfC3+WwYeGQ1rBhodt338b5DiQZmmUQmFlv4AXgYnd/JdM6GzsIVqwIewEvvwyXXAJ3312/LUJpGdzhn/8MgTB7dtgrGzAALr009L/8cni/8tDXQQeFczijRoXXwYPDHtqyZXD//fDgg+Ew45FHwlVXhQsIunSpuw0lJfD734fpV/6JH3ssjB4N774bLgNOPXfTt+/OUKgMidQLAkRSZeuqoVnAGKA7sBb4MdAawN3vM7MHgLOBygP+5bU1MlVjBsFjj4Xd+IoKuPfeEAgimzeHFfJvfgOvvhq26I86KqzwK7s+fere0t+2Ldwz8qtfhTratw9/X9/8JgwZsrNcaWn4O5w9O1zy6x5W6hMnhivPDj5413o//hjeeCOEQmX3wQc73z/ggBBSledjqncHHhheO3Zs3O8MQtsrKkJwbtmya7d1a81xn34a2tq/f+j69AmXOUs8srZHEIfGCIKyMvje98KJ2eHD4ZFHwrkAkeqWLw/nYzp3bngd8+eHDY1HHgkBccwx4dDR3Lnwl7+ElWf//mHlf/758KUv1a/+Tz6B//3fMJ3Fi3c9H7N2bfqT6B06wD77hDCr3kHNcTt2hHrKy0OX2l85XJ871s3CeY9t23aOa9cOjjgi7EVVhkP//uGQm67u2nMKghQLF4ZjwIsXw3XXhXMDe3qVjUgmPvkEfvvbEArvvRcO7UyYELr8/HhOkO/YES4xTj1xX9lt3hy24lM7qDnOPWypt2oVury82vvz8nZeTtypU+1d+/ahzg0bwv9iZffuu+F1+fKd87DXXuEcSb9+4cKNyq5Pn/Daq1fdQeEeprNq1c6r1SpfN28O51q6d4cePXa+VvZ3716/Gyx37AhXsbVu3fyeJ6YgIPwx3HMP/OAHYQvv4YfDDVMiTc0dVq4MKzHdpJdeWRksWbJrQKxcGbrKO+JTHXDAzmDo0SMccktd6W/fXvMzPXqEvaJPPgmH3Gqzzz6hbMeO4Qqz7dt3vqb2f/HFzr2ivLzQptQr4lKvjKvsb9eucb6vTCgICCcBr7wSTj45PGOnR4/Gb5uIxO+zz8KJ9cpgWLkyXPRR2b9uXbiJsfIS5eqvPXuGlXTqXkR5eQiD0lJYvz68pvavXx/OabRpE7b2K29mTNffunUom3pjZElJ2PuormvXcLl05c2Zu+uOOSY8KqYh6gqCZnglejwuuigsoIsv1laYSC5r2zbczX/YYY1XZ6tWITz226/x6qxuy5aa4bBqVXhSQeWNmmVlNYcrOwj3NzU0COqSmCDYe+9weaiISDZ06hROhB95ZP0/6x72hOKSmCAQEclVZvGeT9BVuyIiCacgEBFJOAWBiEjCKQhERBJOQSAiknAKAhGRhFMQiIgknIJARCThFAQiIgmnIBARSTgFgYhIwikIREQSTkEgIpJwCgIRkYRTEIiIJJyCQEQk4RQEIiIJF1sQmNmDZrbOzN6u5X0zs2lmtszMFppZQVxtERGR2sW5R/AQMK6O98cDh0fdZODeGNsiIiK1iC0I3H0e8HEdRU4HfufBP4EuZnZgXO0REZH0snmOoCfwUcpwSTSuBjObbGbFZlZcWlraJI0TEUmKbAaBpRnn6Qq6+3R3L3T3wh49esTcLBGRZMlmEJQAB6cM9wJWZ6ktIiKJlc0geBq4OLp6aASwyd3XZLE9IiKJ1Cquis1sFjAG6G5mJcCPgdYA7n4f8CxwMrAMKAMui6stIiJSu9iCwN0n7uZ9B74V1/RFRCQzurNYRCThFAQiIgmnIBARSTgFgYhIwikIREQSTkEgIpJwCgIRkYRTEIiIJJyCQEQk4RQEIiIJpyAQEUk4BYGISMIpCEREEk5BICKScAoCEZGEUxCIiCScgkBEJOEUBCIiCacgEBFJOAWBiEjCKQhERBJOQSAiknAKAhGRhFMQiIgkXKxBYGbjzGyJmS0zs6lp3u9sZn80szfNbJGZXRZne0REpKbYgsDM8oB7gPHAAGCimQ2oVuxbwDvuPhgYA/ynmbWJq00iIlJTnHsEw4Fl7v6Bu28HZgOnVyvjQCczM6Aj8DFQHmObRESkmjiDoCfwUcpwSTQu1S+B/sBq4C3gGnffUb0iM5tsZsVmVlxaWhpXe0VEEinOILA047za8FeBBcBBwBDgl2a2T40PuU9390J3L+zRo0fjt1REJMHiDIIS4OCU4V6ELf9UlwF/8GAZ8CFwZIxtEhGRauIMgteBw82sX3QCeALwdLUyK4ETAMxsf+AI4IMY2yQiItW0iqtidy83s6uBOUAe8KC7LzKzKdH79wE/BR4ys7cIh5Kuc/f1cbVJRERqii0IANz9WeDZauPuS+lfDZwUZxtERKRuurNYRCThFAQiIgmnIBARSTgFgYhIwikIREQSTkEgIpJwCgIRkYSL9T4CEcl9X3zxBSUlJXz22WfZbopkoG3btvTq1YvWrVtn/BkFgYjUqaSkhE6dOtG3b1/CE+OluXJ3NmzYQElJCf369cv4czo0JCJ1+uyzz+jWrZtCIAeYGd26dav33puCQER2SyGQOxqyrBQEItKsbdiwgSFDhjBkyBAOOOAAevbsWTW8ffv2jOq47LLLWLJkSZ1l7rnnHoqKihqjyYwaNYoFCxY0Sl1NQecIRKRRFRXBDTfAypXQuzfccgtMmtTw+rp161a1Ur3pppvo2LEjP/jBD3Yp4+64O3vtlX7bdsaMGbudzre+9a2GNzLHaY9ARBpNURFMngwrVoB7eJ08OYxvbMuWLWPQoEFMmTKFgoIC1qxZw+TJkyksLGTgwIHcfPPNVWUrt9DLy8vp0qULU6dOZfDgwRxzzDGsW7cOgBtvvJG77rqrqvzUqVMZPnw4RxxxBK+88goAn376KWeffTaDBw9m4sSJFBYW7nbLf+bMmRx11FEMGjSI66+/HoDy8nIuuuiiqvHTpk0D4M4772TAgAEMHjyYCy+8sNG/s9poj0BEGs0NN0BZ2a7jysrC+D3ZK6jNO++8w4wZM7jvvvB0+1tvvZV9992X8vJyxo4dyznnnMOAAQN2+cymTZsYPXo0t956K9deey0PPvggU6dOrVG3u/Paa6/x9NNPc/PNN/P8889z9913c8ABB/D444/z5ptvUlBQUGf7SkpKuPHGGykuLqZz586ceOKJPPPMM/To0YP169fz1ltvAbBx40YAbrvtNlasWEGbNm2qxjWFjPYIzOxQM9s76h9jZt8xsy7xNk1Ecs3KlfUbv6cOPfRQvvzlL1cNz5o1i4KCAgoKCli8eDHvvPNOjc+0a9eO8ePHAzBs2DCWL1+etu6zzjqrRpmXXnqJCRMmADB48GAGDhxYZ/teffVVjj/+eLp3707r1q254IILmDdvHocddhhLlizhmmuuYc6cOXTu3BmAgQMHcuGFF1JUVFSv+wD2VKaHhh4HKszsMOA3QD/gkdhaJSI5qXfv+o3fUx06dKjqX7p0Kf/1X//FCy+8wMKFCxk3blzayyjbtGlT1Z+Xl0d5eXnauvfee+8aZdy9Xu2rrXy3bt1YuHAho0aNYtq0aXzjG98AYM6cOUyZMoXXXnuNwsJCKioq6jW9hso0CHa4ezlwJnCXu38PODC+ZolILrrlFmjfftdx7duH8XHbvHkznTp1Yp999mHNmjXMmTOn0acxatQoHn30UQDeeuuttHscqUaMGMHcuXPZsGED5eXlzJ49m9GjR1NaWoq7c+655/KTn/yEN954g4qKCkpKSjj++OP5xS9+QWlpKWXVj7PFJNNzBF+Y2UTgEuDUaFzT7beISE6oPA/QmFcNZaqgoIABAwYwaNAgDjnkEEaOHNno0/j2t7/NxRdfTH5+PgUFBQwaNKjqsE46vXr14uabb2bMmDG4O6eeeiqnnHIKb7zxBpdffjnujpnx85//nPLyci644AK2bNnCjh07uO666+jUqVOjz0M6lsmujpkNAKYA/+Pus8ysH3C+u98adwOrKyws9OLi4qaerEhiLV68mP79+2e7Gc1CeXk55eXltG3blqVLl3LSSSexdOlSWrVqXtfdpFtmZjbf3QvTlc/o0JC7v+Pu34lCoCvQKRsh0FBFRdC3L+y1V3iN41I2EWn5tm7dysiRIxk8eDBnn302999/f7MLgYbIaA7M7O/AaVH5BUCpmf3D3a+NsW2NovK65spDbZXXNUPT7K6KSMvRpUsX5s+fn+1mNLpMTxZ3dvfNwFnADHcfBpwYX7MaT13XNYuISOZB0MrMDgTOA57JtHIzG2dmS8xsmZnVvGODqvsSFpjZIjP7R6Z1Z6qpr2sWEck1mQbBzcAc4H13f93MDgGW1vUBM8sD7gHGAwOAidFJ59QyXYBfAae5+0Dg3Hq2f7ea+rpmEZFck+nJ4v9293x3vyoa/sDdz97Nx4YDy6Ky24HZwOnVylwA/MHdV0b1rqtf83cvm9c1i4jkgkwfMdHLzJ4ws3VmttbMHjezXrv5WE/go5Thkmhcqi8BXc3s72Y238wurmX6k82s2MyKS0tLM2lylUmTYPp06NMHzMLr9Ok6USySK8aMGVPj5rC77rqLb37zm3V+rmPHjgCsXr2ac845p9a6d3c5+l133bXLjV0nn3xyozwH6KabbuL222/f43oaQ6aHhmYATwMHEVbmf4zG1SXdryNUv2mhFTAMOAX4KvBDM/tSjQ+5T3f3Qncv7NGjR4ZN3mnSJFi+HHbsCK8KAZHcMXHiRGbPnr3LuNmzZzNx4sSMPn/QQQfx2GOPNXj61YPg2WefpUuXlvWotUyDoIe7z3D38qh7CNjdGrkEODhluBewOk2Z5939U3dfD8wDBmfYJhFJgHPOOYdnnnmGzz//HIDly5ezevVqRo0axdatWznhhBMoKCjgqKOO4qmnnqrx+eXLlzNo0CAAtm3bxoQJE8jPz+f8889n27ZtVeWuuuqqqkdY//jHPwZg2rRprF69mrFjxzJ27FgA+vbty/r16wG44447GDRoEIMGDap6hPXy5cvp378/V155JQMHDuSkk07aZTrpLFiwgBEjRpCfn8+ZZ57JJ598UjX9AQMGkJ+fX/Wwu3/84x9VP8wzdOhQtmzZ0uDvtlKmd0KsN7MLgVnR8ERgw24+8zpweHQX8ipgAuGcQKqngF+aWSugDXA0cGeGbRKRJvbd70Jj//DWkCEQrUPT6tatG8OHD+f555/n9NNPZ/bs2Zx//vmYGW3btuWJJ55gn332Yf369YwYMYLTTjut1p9rvPfee2nfvj0LFy5k4cKFuzxG+pZbbmHfffeloqKCE044gYULF/Kd73yHO+64g7lz59K9e/dd6po/fz4zZszg1Vdfxd05+uijGT16NF27dmXp0qXMmjWLX//615x33nk8/vjjdf6+wMUXX8zdd9/N6NGj+dGPfsRPfvIT7rrrLm699VY+/PBD9t5776rDUbfffjv33HMPI0eOZOvWrbRt27Ye33Z6me4RfJ1w6ei/gDXAOcBldX0gekjd1YSrjRYDj7r7IjObYmZTojKLgeeBhcBrwAPu/nZDZkREWq7Uw0Oph4Xcneuvv578/HxOPPFEVq1axdq1a2utZ968eVUr5Pz8fPLz86vee/TRRykoKGDo0KEsWrRotw+Ue+mllzjzzDPp0KEDHTt25KyzzuLFF18EoF+/fgwZMgSo+1HXEH4fYePGjYwePRqASy65hHnz5lW1cdKkScycObPqDuaRI0dy7bXXMm3aNDZu3NgodzZnVEN0Vc9pqePM7LtAHTkO7v4s8Gy1cfdVG/4F8ItM2iEi2VXXlnuczjjjDK699lreeOMNtm3bVrUlX1RURGlpKfPnz6d169b07ds37aOnU6XbW/jwww+5/fbbef311+natSuXXnrpbuup6zltlY+whvAY690dGqrNn/70J+bNm8fTTz/NT3/6UxYtWsTUqVM55ZRTePbZZxkxYgR//etfOfLIIxtUf6U9+anKZv94CRFpGTp27MiYMWP4+te/vstJ4k2bNrHffvvRunVr5s6dy4oVK+qs57jjjqv6gfq3336bhQsXAuER1h06dKBz586sXbuW5557ruoznTp1Snsc/rjjjuPJJ5+krKyMTz/9lCeeeIJjjz223vPWuXNnunbtWrU38fDDDzN69Gh27NjBRx99xNixY7ntttvYuHEjW7du5f333+eoo47iuuuuo7CwkHfffbfe06xuT/Yp0h+EExGJwcSJEznrrLN2uYJo0qRJnHrqqRQWFjJkyJDdbhlfddVVXHbZZeTn5zNkyBCGDx8OhF8bGzp0KAMHDqzxCOvJkyczfvx4DjzwQObOnVs1vqCggEsvvbSqjiuuuIKhQ4fWeRioNr/97W+ZMmUKZWVlHHLIIcyYMYOKigouvPBCNm3ahLvzve99jy5duvDDH/6QuXPnkpeXx4ABA6p+bW1PZPQY6rQfNFvp7k1+f64eQy3StPQY6txT38dQ17lHYGZbqHntP4S9gXYNbaSIiDQfdQaBuzfNz+OIiEjW7MnJYhERaQEUBCKyWw09lyhNryHLSkEgInVq27YtGzZsUBjkAHdnw4YN9b7bOPd/bFNEYtWrVy9KSkqo75N/JTvatm1Lr167ezj0rhQEIlKn1q1b069fv2w3Q2KkQ0MiIgmnIBARSTgFgYhIwikIREQSTkEgIpJwCgIRkYRTEIiIJJyCQEQk4RQEIiIJpyAQEUk4BYGISMIpCEREEk5BICKScLEGgZmNM7MlZrbMzKbWUe7LZlZhZufE2R4REakptiAwszzgHmA8MACYaGYDain3c2BOXG0REZHaxblHMBxY5u4fuPt2YDZweppy3wYeB9bF2BYREalFnEHQE/goZbgkGlfFzHoCZwL3xdgOERGpQ5xBYGnGVf/R07uA69y9os6KzCabWbGZFevn8kREGlecP1VZAhycMtwLWF2tTCEw28wAugMnm1m5uz+ZWsjdpwPTAQoLC/UL2iIijSjOIHgdONzM+gGrgAnABakF3L3qh1DN7CHgmeohICIi8YotCNy93MyuJlwNlAc86O6LzGxK9L7OC4iINANx7hHg7s8Cz1YblzYA3P3SONsiIiLp6c5iEZGEUxCIiCScgkBEJOEUBCIiCacgEBFJOAWBiEjCKQhERBJOQVBNURH07Qt77RVei4qy3SIRkXjFekNZrikqgsmToawsDK9YEYYBJk3KXrtEROKkPYIUN9ywMwQqlZWF8SIiLZWCIMXKlfUbLyLSEigIUvTuXbs2tEQAAAmYSURBVL/xIiItgYIgxS23QPv2u45r3z6MFxFpqRQEKSZNgunToU8fMAuv06frRLGItGy6aqiaSZO04heRZNEegYhIwikIREQSTkEgIpJwCgIRkYRTEIiIJJyCQEQk4RQEIiIJpyAQEUk4BYGISMLFGgRmNs7MlpjZMjObmub9SWa2MOpeMbPBcbZHRERqii0IzCwPuAcYDwwAJprZgGrFPgRGu3s+8FNgelztERGR9OLcIxgOLHP3D9x9OzAbOD21gLu/4u6fRIP/BHrF2B4REUkjziDoCXyUMlwSjavN5cBz6d4ws8lmVmxmxaWlpY3YRBERiTMILM04T1vQbCwhCK5L9767T3f3Qncv7NGjRyM2UURE4nwMdQlwcMpwL2B19UJmlg88AIx39w0xtkdERNKIc4/gdeBwM+tnZm2ACcDTqQXMrDfwB+Aid38vxraIiEgtYtsjcPdyM7samAPkAQ+6+yIzmxK9fx/wI6Ab8CszAyh398K42iQiIjWZe9rD9s1WYWGhFxcXZ7sZIiI5xczm17ahrTuLRUQSTkEgIpJwCgIRkYRTEIiIJJyCQEQk4RQEIiIJpyDYA0VF0Lcv7LVXeC0qynaLRETqL85HTLRoRUUweTKUlYXhFSvCMMCkSdlrl4hIfWmPoIFuuGFnCFQqKwvjRURyiYKggVaurN94EZHmSkHQQL1712+8iEhzpSBooFtugfbtdx3Xvn0YLyKSSxQEDTRpEkyfDn36gFl4nT5dJ4pFJPfoqqE9MGmSVvwikvu0RyAiknAKAhGRhFMQNBHdhSwizZXOETQB3YUsIs2Z9giagO5CFpHmTEHQBOp7F7IOI8WnPt9tHGXjmr7IHnH3nOqGDRvmuaZPH3eo2fXpU7PszJnu7dvvWq59+zA+nZkzQz1m4bW2cnGVzfb069vWTL/bOMrGNf24vq/6lpXmDSj2WtarWV+x17fLxSCozz91XKGRSyu2uMrW57uNo2xc028O321l+WwHfUsNrcaYNwVBM5DpgjRLvwIwq1m2pa7Y4ipbn+82jrJxTb85fLfZDqNcC636lK3vvNUma0EAjAOWAMuAqWneN2Ba9P5CoGB3deZqEGRKK7aWu8JsqQEX57zF8d1mO7TqW7Y+81aXrAQBkAe8DxwCtAHeBAZUK3My8FwUCCOAV3dXb0sPAh3q0FZrfcs2h+8222GUS6FV37L1mbe6ZCsIjgHmpAz/G/Bv1crcD0xMGV4CHFhXvS09CNx18lPHsetfZ7a/22yvMHMptOpbNtf3CM4BHkgZvgj4ZbUyzwCjUob/BhTWVW8SgqA+WuKKLc6yLVW2v9tsh1EuhVZ9y+b0OQLg3DRBcHe1Mn9KEwTD0tQ1GSgGinv37l2/uReRJtEcwigXQqu+Zeszb3XRoSERkRTZDq36lm0MdQWBhfcbn5m1At4DTgBWAa8DF7j7opQypwBXE04aHw1Mc/fhddVbWFjoxcXFsbRZRKSlMrP57l6Y7r3YHjrn7uVmdjUwh3AF0YPuvsjMpkTv3wc8SwiBZUAZcFlc7RERkfRiffqouz9LWNmnjrsvpd+Bb8XZBhERqZseOiciknAKAhGRhFMQiIgkXGxXDcXFzEqBFdluxx7oDqzPdiNi0FLnC1ruvGm+cs+ezFsfd++R7o2cC4JcZ2bFtV3Clcta6nxBy503zVfuiWvedGhIRCThFAQiIgmnIGh607PdgJi01PmCljtvmq/cE8u86RyBiEjCaY9ARCThFAQiIgmnIGhCZrbczN4yswVmlrOPUDWzB81snZm9nTJuXzP7i5ktjV67ZrONDVHLfN1kZquiZbbAzE7OZhsbwswONrO5ZrbYzBaZ2TXR+JawzGqbt5xebmbW1sxeM7M3o/n6STQ+lmWmcwRNyMyWE36BLadvdjGz44CtwO/cfVA07jbgY3e/1cymAl3d/bpstrO+apmvm4Ct7n57Ntu2J8zsQMLvfLxhZp2A+cAZwKXk/jKrbd7OI4eXm5kZ0MHdt5pZa+Al4BrgLGJYZtojkHpz93nAx9VGnw78Nur/LeGfMafUMl85z93XuPsbUf8WYDHQk5axzGqbt5wW/ZbM1miwddQ5MS0zBUHTcuDPZjbfzCZnuzGNbH93XwPhnxPYL8vtaUxXm9nC6NBRzh0+SWVmfYGhwKu0sGVWbd4gx5ebmeWZ2QJgHfAXd49tmSkImtZIdy8AxgPfig5FSPN2L3AoMARYA/xndpvTcGbWEXgc+K67b852expTmnnL+eXm7hXuPgToBQw3s0FxTUtB0ITcfXX0ug54AqjzZzlzzNroeG3lcdt1WW5Po3D3tdE/5A7g1+ToMouOMz8OFLn7H6LRLWKZpZu3lrLcANx9I/B3YBwxLTMFQRMxsw7RySzMrANwEvB23Z/KKU8Dl0T9lwBPZbEtjabyny5yJjm4zKITj78BFrv7HSlv5fwyq23ecn25mVkPM+sS9bcDTgTeJaZlpquGmoiZHULYC4DwE6GPuPstWWxSg5nZLGAM4ZG4a4EfA08CjwK9gZXAue6eUydea5mvMYTDCw4sB75ReYw2V5jZKOBF4C1gRzT6esKx9FxfZrXN20RyeLmZWT7hZHAeYYP9UXe/2cy6EcMyUxCIiCScDg2JiCScgkBEJOEUBCIiCacgEBFJOAWBiEjCKQhEImZWkfK0ygXRQ70aq+6+qU81FWlOWmW7ASLNyLboln6RRNEegchuRL8j8fPo+fCvmdlh0fg+Zva36MFmfzOz3tH4/c3siehZ8m+a2VeiqvLM7NfR8+X/HN0xipl9x8zeieqZnaXZlARTEIjs1K7aoaHzU97b7O7DgV8Cd0Xjfkn47YJ8oAiYFo2fBvzD3QcDBcCiaPzhwD3uPhDYCJwdjZ8KDI3qmRLXzInURncWi0TMbKu7d0wzfjlwvLt/ED3g7F/u3s3M1hN+FOWLaPwad+9uZqVAL3f/PKWOvoRHCR8eDV8HtHb3n5nZ84QfxHkSeDLlOfQiTUJ7BCKZ8Vr6ayuTzucp/RXsPEd3CnAPMAyYb2Y6dydNSkEgkpnzU17/J+p/BZgQ9U8i/JwgwN+Aq6Dqx0X2qa1SM9sLONjd5wL/D+gC1NgrEYmTtjxEdmoX/SJUpefdvfIS0r3N7FXCxtPEaNx3gAfN7P8CpcBl0fhrgOlmdjlhy/8qwo+jpJMHzDSzzoABd0bPnxdpMjpHILIb0TmCQndfn+22iMRBh4ZERBJOewQiIgmnPQIRkYRTEIiIJJyCQEQk4RQEIiIJpyAQEUm4/w89fPQwPruk/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6878906250000001\n",
      "Time:  11\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "mlp = MLP_AnomalyDetection.from_DataFrame(df_synthetic,100,5,30,0.3,'euclidean')\n",
    "mlp.fit()\n",
    "# mlp.plot()\n",
    "mlp.get_roc_auc(verbose=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YcDsaP2-Amov",
    "outputId": "09e0cf37-380b-4b34-8999-e0c67ba2ce62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28444 samples, validate on 2844 samples\n",
      "Epoch 1/30\n",
      "28444/28444 [==============================] - 8s 268us/step - loss: 1.5961 - val_loss: 0.3059\n",
      "Epoch 2/30\n",
      "28444/28444 [==============================] - 5s 173us/step - loss: 1.4237 - val_loss: 0.3037\n",
      "Epoch 3/30\n",
      "28444/28444 [==============================] - 5s 172us/step - loss: 1.4138 - val_loss: 0.2979\n",
      "Epoch 4/30\n",
      "28444/28444 [==============================] - 5s 172us/step - loss: 1.2980 - val_loss: 0.3079\n",
      "Epoch 5/30\n",
      "28444/28444 [==============================] - 5s 169us/step - loss: 1.2291 - val_loss: 0.3333\n",
      "Epoch 6/30\n",
      "28444/28444 [==============================] - 5s 172us/step - loss: 1.2106 - val_loss: 0.3116\n",
      "Epoch 7/30\n",
      "28444/28444 [==============================] - 5s 172us/step - loss: 1.0943 - val_loss: 0.3109\n",
      "Epoch 8/30\n",
      "28444/28444 [==============================] - 5s 170us/step - loss: 1.1414 - val_loss: 0.3088\n",
      "Epoch 9/30\n",
      "28444/28444 [==============================] - 5s 172us/step - loss: 1.0482 - val_loss: 0.3202\n",
      "Epoch 10/30\n",
      "28444/28444 [==============================] - 5s 170us/step - loss: 0.9941 - val_loss: 0.3083\n",
      "Epoch 11/30\n",
      "28444/28444 [==============================] - 5s 172us/step - loss: 0.9943 - val_loss: 0.3210\n",
      "Epoch 12/30\n",
      "28444/28444 [==============================] - 5s 172us/step - loss: 1.0309 - val_loss: 0.3076\n",
      "Epoch 13/30\n",
      "28444/28444 [==============================] - 5s 173us/step - loss: 0.8321 - val_loss: 0.3087\n",
      "Epoch 14/30\n",
      "28444/28444 [==============================] - 5s 171us/step - loss: 0.6381 - val_loss: 0.3265\n",
      "Epoch 15/30\n",
      "28444/28444 [==============================] - 5s 167us/step - loss: 0.7502 - val_loss: 0.3141\n",
      "Epoch 16/30\n",
      "28444/28444 [==============================] - 5s 174us/step - loss: 0.6020 - val_loss: 0.3012\n",
      "Epoch 17/30\n",
      "28444/28444 [==============================] - 5s 173us/step - loss: 0.2764 - val_loss: 0.3224\n",
      "Epoch 18/30\n",
      "28444/28444 [==============================] - 5s 173us/step - loss: 0.5096 - val_loss: 0.3139\n",
      "Epoch 19/30\n",
      "28444/28444 [==============================] - 5s 173us/step - loss: 0.4906 - val_loss: 0.3244\n",
      "Epoch 20/30\n",
      "28444/28444 [==============================] - 5s 189us/step - loss: 0.6354 - val_loss: 0.3039\n",
      "Epoch 21/30\n",
      "28444/28444 [==============================] - 5s 193us/step - loss: 0.7297 - val_loss: 0.3145\n",
      "Epoch 22/30\n",
      "28444/28444 [==============================] - 6s 220us/step - loss: 0.2631 - val_loss: 0.3100\n",
      "Epoch 23/30\n",
      "28444/28444 [==============================] - 6s 202us/step - loss: 0.2453 - val_loss: 0.3216\n",
      "Epoch 24/30\n",
      "28444/28444 [==============================] - 5s 181us/step - loss: 0.3630 - val_loss: 0.3095\n",
      "Epoch 25/30\n",
      "28444/28444 [==============================] - 5s 187us/step - loss: 0.5264 - val_loss: 0.3092\n",
      "Epoch 26/30\n",
      "28444/28444 [==============================] - 5s 185us/step - loss: 0.8353 - val_loss: 0.3340\n",
      "Epoch 27/30\n",
      "28444/28444 [==============================] - 8s 284us/step - loss: 0.2983 - val_loss: 0.3145\n",
      "Epoch 28/30\n",
      "28444/28444 [==============================] - 5s 189us/step - loss: 0.4186 - val_loss: 0.3174\n",
      "Epoch 29/30\n",
      "28444/28444 [==============================] - 5s 192us/step - loss: 0.5519 - val_loss: 0.3247\n",
      "Epoch 30/30\n",
      "28444/28444 [==============================] - 5s 181us/step - loss: 0.1975 - val_loss: 0.3177\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6076916280530905\n",
      "Time:  166\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "mlp = MLP_AnomalyDetection.from_file('Multivariate/NASA_Shuttle/40903.csv',None,100,3,30,0.3,'euclidean')\n",
    "mlp.fit()\n",
    "# mlp.plot()\n",
    "mlp.get_roc_auc(verbose=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VnH3vAaOv2JO"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "K_62JcV1v3CG",
    "outputId": "ac9920fa-4e09-4ddd-bb31-dc30ede7bd1b"
   },
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np \n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from numpy.random import seed\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "seed(42)\n",
    "from keras import regularizers\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    \n",
    "class CNN_AnomalyDetection:\n",
    "    @classmethod\n",
    "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
    "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
    "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
    "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense,distance_function)\n",
    "     \n",
    "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function):\n",
    "        self.distance_function = distance_function\n",
    "        self.dimension = dimension\n",
    "        self.n_epochs = n_epochs\n",
    "        self.window_width = window_width\n",
    "        \n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_dense = n_dense\n",
    "\n",
    "        self.df = df\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
    "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
    "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
    "\n",
    "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
    "        self.values = df_sensors\n",
    "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
    "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
    "\n",
    "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
    "        # self.dataframe.columns = ['t', 't+1']\n",
    "\n",
    "        self.train_size = int(len(self.values) * train_rate)  \n",
    "\n",
    "\n",
    "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back),:self.dimension]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
    "        return numpy.array(dataX), numpy.array(dataY)\n",
    "    \n",
    "    def getWindowedVectors(self, X):\n",
    "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
    "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
    "            vectors[i] = X[i:i+self.window_width]\n",
    "        return vectors\n",
    "\n",
    "    def __build_sets(self):\n",
    "\n",
    "        X = self.dataframe.iloc[:,:-1].values\n",
    "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
    "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
    "\n",
    "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
    "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
    "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
    "\n",
    "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
    "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
    "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
    "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
    "\n",
    "    def standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
    "        X = self.scalar.transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "    def inverse_standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        X = self.scalar.inverse_transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "\n",
    "    def model_persistence(self, x):\n",
    "        return x\n",
    "        \n",
    "    def create_persistence(self):\n",
    "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
    "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
    "\n",
    "    def fit(self):\n",
    "        self.create_persistence()\n",
    "        self.standardize_dataframe()\n",
    "        self.__build_sets()\n",
    "                \n",
    "        self.compute_anomalyScores()\n",
    "        self.inverse_standardize_dataframe()\n",
    "        # self.compute_Errors_RMSE()\n",
    "\n",
    "        return self.history.history\n",
    "\n",
    "    def plotTraining(self):\n",
    "        history_dict = self.history.history\n",
    "        loss_values = history_dict['loss'][1:]\n",
    "        val_loss_values = history_dict['val_loss'][1:]\n",
    "        self.n_epochs = range(2, self.n_epochs + 1)\n",
    "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
    "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def compute_anomalyScores(self):\n",
    "\n",
    "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
    "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
    "\n",
    "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv1D(filters=self.n_filters[0], kernel_size=self.kernel_size, activation='relu', input_shape=(self.window_width,self.dimension ),data_format='channels_first', padding='same'))\n",
    "        self.model.add(MaxPooling1D(pool_size=2))\n",
    "        self.model.add(Conv1D(filters=self.n_filters[1], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same'))\n",
    "        self.model.add(MaxPooling1D(pool_size=2))\n",
    "        self.model.add(Conv1D(filters=self.n_filters[2], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same'))\n",
    "        self.model.add(MaxPooling1D(pool_size=2))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(self.n_dense, activation='relu'))\n",
    "        self.model.add(Dense(self.dimension))\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "        self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=0)\n",
    "\n",
    "        # self.plotTraining()\n",
    "        self.predictions = self.model.predict(self.test_X)\n",
    "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
    "        self.compute_errors(self.distance_function)\n",
    "\n",
    "    def compute_errors(self, distance_function):\n",
    "        if distance_function == 'mahalanobis':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
    "        elif distance_function == 'euclidean':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.euclidean(error,mean)\n",
    "\n",
    "    def compute_Errors_RMSE(self):\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
    "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
    "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
    "   \n",
    "\n",
    "    def plot(self):\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            data = self.df[self.df.columns[i]].iloc[:200]\n",
    "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
    "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
    "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
    "            ax.legend()\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    def get_roc_auc(self, plot=True, verbose=True):\n",
    "\n",
    "        # get the predicted errors of the anomaly points\n",
    "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
    "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
    "        if len(true_anomaly_predicted_errors) == 0:\n",
    "            return np.nan\n",
    "        # sort them \n",
    "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
    "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
    "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
    "                # now iterate thru the predicted errors from small to big\n",
    "        # for each value look how much other points have equal or bigger error\n",
    "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "        TPR = [] # tp/p\n",
    "        p = len(true_anomaly_predicted_errors)\n",
    "        Thresholds = []\n",
    "        for predictederror in true_anomaly_predicted_errors_extended:\n",
    "            threshold = predictederror\n",
    "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
    "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
    "            \n",
    "            fpr =fp/len(self.errors)\n",
    "            FPR.append(fpr)\n",
    "            TPR.append(tp/p)\n",
    "            if verbose:\n",
    "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.axis([0, 1, 0, 1])\n",
    "            plt.plot(FPR,TPR)\n",
    "            plt.show() \n",
    "\n",
    "        # This is the AUC\n",
    "        from sklearn.metrics import auc\n",
    "        print('AUC: ' ,auc(FPR,TPR)        )\n",
    "        return auc(FPR,TPR)\n",
    "\n",
    "# filters = [[8,8,8], [4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
    "# kernelsizes = [2,3,4,6,8,16]\n",
    "# dense = [18,36,72,144]\n",
    "\n",
    "# best_auc = [0,0]\n",
    "# histories = []\n",
    "# for f in filters:\n",
    "#     for k in kernelsizes:\n",
    "#         for d in dense:\n",
    "\n",
    "#             cnn = CNN_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,f,k,d)\n",
    "#             hist = cnn.fit()\n",
    "#             histories.append(((f,k,d), hist))\n",
    "#             # cnn.plot()\n",
    "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#             if best_auc[1] < auc:\n",
    "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#                 best_auc = [(f,k,d),auc]\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "# print(best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gR7n1Tj4Azd"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UiMRRPDH4CfY"
   },
   "source": [
    "### Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "MgSIUWCB4GQV",
    "outputId": "1b6e292d-db6b-41d7-a3a4-96b2d5075da6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9225127872631653\n",
      "Time:  15\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8],2,18, 'mahalanobis')\n",
    "hist = cnn.fit()\n",
    "histories.append(((f,k,d), hist))\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n",
    "#0.757626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IKDy0jyFAwmS",
    "outputId": "3f31554a-c90c-4995-aa23-e181d7a9d674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.4890084617436606\n",
      "Time:  141\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_AnomalyDetection.from_file('Multivariate/NASA_Shuttle/40903.csv',None,30,3,20,0.3,[8,8,8],2,18, 'mahalanobis')\n",
    "hist = cnn.fit()\n",
    "histories.append(((f,k,d), hist))\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n",
    "#0.757626"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ffTQKop4Eih"
   },
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "8l_QUTwl4FjC",
    "outputId": "7899b8b1-72ce-4541-e74d-209c491ca8ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7457243714429796\n",
      "Time:  7\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8],2,18, 'euclidean')\n",
    "hist = cnn.fit()\n",
    "histories.append(((f,k,d), hist))\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n",
    "#0.757626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YGsGIIdCA-Wg",
    "outputId": "39ca4b44-a5a8-4fdb-c331-90e2d9330e14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5709200626098417\n",
      "Time:  117\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_AnomalyDetection.from_file('Multivariate/NASA_Shuttle/40903.csv',None,30,3,20,0.3,[8,8,8],2,18, 'euclidean')\n",
    "hist = cnn.fit()\n",
    "histories.append(((f,k,d), hist))\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n",
    "#0.757626"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQDGfrzl86PG"
   },
   "source": [
    "# CNN BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05RPy_NR851p"
   },
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "from scipy.spatial import distance\n",
    "import keras \n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np \n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from numpy.random import seed\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten, Input, BatchNormalization, Activation\n",
    "seed(42)\n",
    "from keras import regularizers\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    \n",
    "class CNN_Batch_AnomalyDetection:\n",
    "    @classmethod\n",
    "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
    "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
    "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
    "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
    "     \n",
    "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function):\n",
    "\n",
    "        self.distance_function = distance_function\n",
    "        self.dimension = dimension\n",
    "        self.n_epochs = n_epochs\n",
    "        self.window_width = window_width\n",
    "        \n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_dense = n_dense\n",
    "\n",
    "        self.df = df\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
    "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
    "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
    "\n",
    "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
    "        self.values = df_sensors\n",
    "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
    "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
    "\n",
    "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
    "        # self.dataframe.columns = ['t', 't+1']\n",
    "\n",
    "        self.train_size = int(len(self.values) * train_rate)  \n",
    "\n",
    "\n",
    "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back),:self.dimension]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
    "        return numpy.array(dataX), numpy.array(dataY)\n",
    "    \n",
    "    def getWindowedVectors(self, X):\n",
    "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
    "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
    "            vectors[i] = X[i:i+self.window_width]\n",
    "        return vectors\n",
    "\n",
    "    def __build_sets(self):\n",
    "\n",
    "        X = self.dataframe.iloc[:,:-1].values\n",
    "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
    "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
    "\n",
    "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
    "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
    "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
    "\n",
    "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
    "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
    "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
    "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
    "\n",
    "    def standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
    "        X = self.scalar.transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "    def inverse_standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        X = self.scalar.inverse_transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "\n",
    "    def model_persistence(self, x):\n",
    "        return x\n",
    "        \n",
    "    def create_persistence(self):\n",
    "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
    "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
    "\n",
    "    def fit(self):\n",
    "        self.create_persistence()\n",
    "        self.standardize_dataframe()\n",
    "        self.__build_sets()\n",
    "                \n",
    "        self.compute_anomalyScores()\n",
    "        self.inverse_standardize_dataframe()\n",
    "        # self.compute_Errors_RMSE()\n",
    "\n",
    "        return self.history.history\n",
    "\n",
    "    def plotTraining(self):\n",
    "        history_dict = self.history.history\n",
    "        loss_values = history_dict['loss'][1:]\n",
    "        val_loss_values = history_dict['val_loss'][1:]\n",
    "        self.n_epochs = range(2, self.n_epochs + 1)\n",
    "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
    "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def compute_anomalyScores(self):\n",
    "\n",
    "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
    "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
    "\n",
    "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "\n",
    "        channel_pos = 'channels_first'\n",
    "        inp_shape = Input((self.window_width,self.dimension),name='input1')\n",
    "        x = Conv1D(self.n_filters[0], kernel_size=self.kernel_size, padding = 'same', input_shape=(self.window_width,self.dimension),data_format=channel_pos,name='conv2d_Prep')(inp_shape)\n",
    "        x = BatchNormalization(axis=1,name='batch_normalization_prep')(x)\n",
    "        x_a1 = Activation('relu',name='activation_prep')(x)\n",
    "        activated_x = x_a1\n",
    "\n",
    "        #     activated_x, x\n",
    "        nr = 1 *2 -1\n",
    "        x = Conv1D(self.n_filters[1], kernel_size=self.kernel_size, name = 'conv2d_'+str(nr), padding='same',data_format=channel_pos)(activated_x)\n",
    "        x = BatchNormalization(axis=1, name = 'batch_normalization_'+str(nr))(x)\n",
    "        activated_x = Activation('relu',name='activation_'+str(nr+1))(x)\n",
    "        activated_x = Flatten()(activated_x)\n",
    " \n",
    "        activated_x = Dense(self.n_dense)(activated_x)\n",
    "        output = Dense(self.dimension)(activated_x)\n",
    "\n",
    "        from keras.models import Model\n",
    "        self.model = Model(inp_shape,output )\n",
    "\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "        self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=0)\n",
    "\n",
    "        # self.plotTraining()\n",
    "        self.predictions = self.model.predict(self.test_X)\n",
    "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
    "        self.compute_errors(self.distance_function)\n",
    "\n",
    "    def compute_errors(self, distance_function):\n",
    "        if distance_function == 'mahalanobis':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
    "        elif distance_function == 'euclidean':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.euclidean(error,mean)\n",
    "\n",
    "    def compute_Errors_RMSE(self):\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
    "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
    "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
    "   \n",
    "\n",
    "    def plot(self):\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            data = self.df[self.df.columns[i]].iloc[:200]\n",
    "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
    "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
    "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
    "            ax.legend()\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    def get_roc_auc(self, plot=True, verbose=True):\n",
    "\n",
    "        # get the predicted errors of the anomaly points\n",
    "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
    "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
    "        if len(true_anomaly_predicted_errors) == 0:\n",
    "            return np.nan\n",
    "        # sort them \n",
    "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
    "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
    "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
    "                # now iterate thru the predicted errors from small to big\n",
    "        # for each value look how much other points have equal or bigger error\n",
    "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "        TPR = [] # tp/p\n",
    "        p = len(true_anomaly_predicted_errors)\n",
    "        Thresholds = []\n",
    "        for predictederror in true_anomaly_predicted_errors_extended:\n",
    "            threshold = predictederror\n",
    "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
    "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
    "            \n",
    "            fpr =fp/len(self.errors)\n",
    "            FPR.append(fpr)\n",
    "            TPR.append(tp/p)\n",
    "            if verbose:\n",
    "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.axis([0, 1, 0, 1])\n",
    "            plt.plot(FPR,TPR)\n",
    "            plt.show() \n",
    "\n",
    "        # This is the AUC\n",
    "        from sklearn.metrics import auc\n",
    "        print('AUC: ' ,auc(FPR,TPR)        )\n",
    "        return auc(FPR,TPR)\n",
    "\n",
    "# filters = [[8,8,8], [4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
    "# kernelsizes = [2,3,4,6,8,16]\n",
    "# dense = [18,36,72,144]\n",
    "\n",
    "# best_auc = [0,0]\n",
    "# histories = []\n",
    "# for f in filters:\n",
    "#     for k in kernelsizes:\n",
    "#         for d in dense:\n",
    "\n",
    "#             cnn = CNN_Resnet_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,f,k,d)\n",
    "#             hist = cnn.fit()\n",
    "#             histories.append(((f,k,d), hist))\n",
    "#             # cnn.plot()\n",
    "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#             if best_auc[1] < auc:\n",
    "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#                 best_auc = [(f,k,d),auc]\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "# print(best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-ws_nH32NVI"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRSIoeqO2PGb"
   },
   "source": [
    "### Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "oXKsdYLR3VUW",
    "outputId": "293b5069-c300-4805-9d4d-43db9a76744a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9118507312153304\n",
      "Time:  11\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_Batch_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8],2,18, 'mahalanobis')\n",
    "hist = cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n",
    "#0.757626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "id": "1QF_PTAQBD8Y",
    "outputId": "2ef4ca17-36f5-49c6-8074-3da152787e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7102951214536781\n",
      "Time:  151\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_Batch_AnomalyDetection.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,20,0.3,[8,8,8],2,18, 'mahalanobis')\n",
    "hist = cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n",
    "#0.757626"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_68oyXh63smW"
   },
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "QSlR7Q9_3t44",
    "outputId": "c2373fef-e4b4-4071-c51b-913549319749"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7545565881420647\n",
      "Time:  10\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_Batch_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8],2,18, 'euclidean')\n",
    "hist = cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n",
    "#0.757626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ovUgTac2BN-5",
    "outputId": "8bcca040-b053-4a6b-d4f0-71308253cb82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5494136211712277\n",
      "Time:  158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_Batch_AnomalyDetection.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,20,0.3,[8,8,8],2,18, 'euclidean')\n",
    "hist = cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n",
    "#0.757626"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JzusEAx47BPq"
   },
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4ttY5es7CXR"
   },
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "from scipy.spatial import distance\n",
    "import keras \n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np \n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from numpy.random import seed\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten, Input, BatchNormalization, Activation\n",
    "seed(42)\n",
    "from keras import regularizers\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    \n",
    "class CNN_Resnet_AnomalyDetection:\n",
    "    @classmethod\n",
    "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
    "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
    "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
    "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
    "     \n",
    "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function):\n",
    "        self.distance_function =  distance_function\n",
    "        self.dimension = dimension\n",
    "        self.n_epochs = n_epochs\n",
    "        self.window_width = window_width\n",
    "        \n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_dense = n_dense\n",
    "\n",
    "        self.df = df\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
    "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
    "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
    "\n",
    "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
    "        self.values = df_sensors\n",
    "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
    "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
    "\n",
    "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
    "        # self.dataframe.columns = ['t', 't+1']\n",
    "\n",
    "        self.train_size = int(len(self.values) * train_rate)  \n",
    "\n",
    "\n",
    "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back),:self.dimension]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
    "        return numpy.array(dataX), numpy.array(dataY)\n",
    "    \n",
    "    def getWindowedVectors(self, X):\n",
    "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
    "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
    "            vectors[i] = X[i:i+self.window_width]\n",
    "        return vectors\n",
    "\n",
    "    def __build_sets(self):\n",
    "\n",
    "        X = self.dataframe.iloc[:,:-1].values\n",
    "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
    "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
    "\n",
    "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
    "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
    "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
    "\n",
    "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
    "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
    "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
    "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
    "\n",
    "    def standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
    "        X = self.scalar.transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "    def inverse_standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        X = self.scalar.inverse_transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "\n",
    "    def model_persistence(self, x):\n",
    "        return x\n",
    "        \n",
    "    def create_persistence(self):\n",
    "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
    "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
    "\n",
    "    def fit(self, plot = False):\n",
    "        self.create_persistence()\n",
    "        self.standardize_dataframe()\n",
    "        self.__build_sets()\n",
    "                \n",
    "        self.compute_anomalyScores(plot = plot)\n",
    "        self.inverse_standardize_dataframe()\n",
    "\n",
    "        return self.history.history\n",
    "\n",
    "    def plotTraining(self):\n",
    "        history_dict = self.history.history\n",
    "        loss_values = history_dict['loss'][1:]\n",
    "        val_loss_values = history_dict['val_loss'][1:]\n",
    "        self.n_epochs = range(2, self.n_epochs + 1)\n",
    "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
    "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def compute_anomalyScores(self, plot = False):\n",
    "\n",
    "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
    "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
    "\n",
    "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "\n",
    "        channel_pos = 'channels_first'\n",
    "        inp_shape = Input((self.window_width,self.dimension),name='input1')\n",
    "        x = Conv1D(self.n_filters[0], kernel_size=self.kernel_size, padding = 'same', input_shape=(self.window_width,self.dimension),data_format=channel_pos,name='conv2d_Prep')(inp_shape)\n",
    "        x = BatchNormalization(axis=1,name='batch_normalization_prep')(x)\n",
    "        x_a1 = Activation('relu',name='activation_prep')(x)\n",
    "        activated_x = x_a1\n",
    "\n",
    "        #     activated_x, x\n",
    "        nr = 1 *2 -1\n",
    "        x = Conv1D(self.n_filters[1], kernel_size=self.kernel_size, name = 'conv2d_'+str(nr), padding='same',data_format=channel_pos)(activated_x)\n",
    "        x = BatchNormalization(axis=1, name = 'batch_normalization_'+str(nr))(x)\n",
    "        x = Activation('relu',name = 'activation_'+str(nr))(x)\n",
    "        x = Conv1D(self.n_filters[2], kernel_size=self.kernel_size, name = 'conv2d_'+str(nr+1),padding = 'same',data_format=channel_pos)(x)\n",
    "        x = BatchNormalization(axis=1, name = 'batch_normalization_'+str(nr+1))(x)\n",
    "        x = keras.layers.add([x,activated_x],name='add_' + str(1))\n",
    "        activated_x = Activation('relu',name='activation_'+str(nr+1))(x)\n",
    "        activated_x = Flatten()(activated_x)\n",
    "        activated_x = Dense(self.n_dense)(activated_x)\n",
    "        output = Dense(self.dimension)(activated_x)\n",
    "\n",
    "        from keras.models import Model\n",
    "        self.model = Model(inp_shape,output )\n",
    "\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "        self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=0)\n",
    "\n",
    "        if plot:\n",
    "            self.plotTraining()\n",
    "        self.predictions = self.model.predict(self.test_X)\n",
    "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
    "        self.compute_errors(self.distance_function)\n",
    "\n",
    "    def compute_errors(self, distance_function):\n",
    "        if distance_function == 'mahalanobis':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
    "        elif distance_function == 'euclidean':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.euclidean(error,mean)\n",
    "\n",
    "    def compute_Errors_RMSE(self):\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
    "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
    "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
    "   \n",
    "\n",
    "    def plot(self):\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            data = self.df[self.df.columns[i]].iloc[:200]\n",
    "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
    "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
    "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
    "            ax.legend()\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    def get_roc_auc(self, plot=True, verbose=True):\n",
    "        # get the predicted errors of the anomaly points\n",
    "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
    "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
    "        if len(true_anomaly_predicted_errors) == 0:\n",
    "            return np.nan\n",
    "        # sort them \n",
    "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
    "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
    "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
    "                # now iterate thru the predicted errors from small to big\n",
    "        # for each value look how much other points have equal or bigger error\n",
    "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "        TPR = [] # tp/p\n",
    "        p = len(true_anomaly_predicted_errors)\n",
    "        Thresholds = []\n",
    "        for predictederror in true_anomaly_predicted_errors_extended:\n",
    "            threshold = predictederror\n",
    "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
    "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
    "            \n",
    "            fpr =fp/len(self.errors)\n",
    "            FPR.append(fpr)\n",
    "            TPR.append(tp/p)\n",
    "            if verbose:\n",
    "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.axis([0, 1, 0, 1])\n",
    "            plt.plot(FPR,TPR)\n",
    "            plt.show() \n",
    "\n",
    "        # This is the AUC\n",
    "        from sklearn.metrics import auc\n",
    "        print('AUC: ' ,auc(FPR,TPR)        )\n",
    "        return auc(FPR,TPR)\n",
    "\n",
    "# filters = [[8,8,8], [4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
    "# kernelsizes = [2,3,4,6,8,16]\n",
    "# dense = [18,36,72,144]\n",
    "\n",
    "# best_auc = [0,0]\n",
    "# histories = []\n",
    "# for f in filters:\n",
    "#     for k in kernelsizes:\n",
    "#         for d in dense:\n",
    "\n",
    "#             cnn = CNN_Resnet_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,f,k,d)\n",
    "#             hist = cnn.fit()\n",
    "#             histories.append(((f,k,d), hist))\n",
    "#             # cnn.plot()\n",
    "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#             if best_auc[1] < auc:\n",
    "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#                 best_auc = [(f,k,d),auc]\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "# print(best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "taiAW0Bk-iVP"
   },
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a2j6BPtY1b1-"
   },
   "source": [
    "### Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "SAcehPYXCT1e",
    "outputId": "322a7677-e7a5-4994-f852-1a4e553af23e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9297503092145949\n",
      "Time:  21\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_Resnet_AnomalyDetection.from_DataFrame(df_synthetic,180,5,60,0.3,[3,3,3],1,18,'mahalanobis')\n",
    "hist = cnn.fit(plot=True)\n",
    "histories.append(((f,k,d), hist))\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n",
    "#0.757626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "pGIn4T1cBSwy",
    "outputId": "9209b225-2928-4272-e2de-dcd1ba28e4f7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5737006234962968\n",
      "Time:  578\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_Resnet_AnomalyDetection.from_file('Multivariate/NASA_Shuttle/40903.csv', None,180,3,60,0.3,[3,3,3],1,18,'mahalanobis')\n",
    "hist = cnn.fit(plot=True)\n",
    "histories.append(((f,k,d), hist))\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ii3VOu4O1f2i"
   },
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "nBTh32Mp1hR0",
    "outputId": "02065907-119b-4702-8e8b-1fe5bc995493"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7051484230055659\n",
      "Time:  25\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_Resnet_AnomalyDetection.from_DataFrame(df_synthetic,180,5,60,0.3,[3,3,3],1,18,'euclidean')\n",
    "hist = cnn.fit(plot=True)\n",
    "histories.append(((f,k,d), hist))\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n",
    "#0.757626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "UrmfXw2YBd3o",
    "outputId": "ba25a3e9-bdf5-4361-c2cd-f82b29bc4308"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.4976142224773167\n",
      "Time:  597\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_Resnet_AnomalyDetection.from_file('Multivariate/NASA_Shuttle/40903.csv', None,180,3,60,0.3,[3,3,3],1,18,'euclidean')\n",
    "hist = cnn.fit(plot=True)\n",
    "histories.append(((f,k,d), hist))\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "v8Ot34N_-jDv",
    "outputId": "2e07a5df-9c59-49e1-c373-a06ef02e98fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7602232142857143\n",
      "Time:  26\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "cnn = CNN_Resnet_AnomalyDetection.from_DataFrame(df_synthetic,100,5,50,0.3,[4,4,4],1,18)\n",
    "hist = cnn.fit(plot=True)\n",
    "histories.append(((f,k,d), hist))\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHpVDe_dDGGy"
   },
   "source": [
    "# Wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66HIkWvPDIjG"
   },
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np \n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from numpy.random import seed\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "seed(42)\n",
    "from keras import regularizers\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    \n",
    "class WaveNet_AnomalyDetection:\n",
    "    @classmethod\n",
    "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
    "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function) -> 'XGB_AnomalyDetection_ML':\n",
    "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
    "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function)\n",
    "     \n",
    "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, kernel_size, n_dense, distance_function):\n",
    "\n",
    "        self.distance_function = distance_function\n",
    "        self.dimension = dimension\n",
    "        self.n_epochs = n_epochs\n",
    "        self.window_width = window_width\n",
    "        \n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_dense = n_dense\n",
    "\n",
    "        self.df = df\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
    "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
    "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
    "\n",
    "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
    "        self.values = df_sensors\n",
    "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
    "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
    "\n",
    "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
    "        # self.dataframe.columns = ['t', 't+1']\n",
    "\n",
    "        self.train_size = int(len(self.values) * train_rate)  \n",
    "\n",
    "\n",
    "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back),:self.dimension]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
    "        return numpy.array(dataX), numpy.array(dataY)\n",
    "    \n",
    "    def getWindowedVectors(self, X):\n",
    "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
    "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
    "            vectors[i] = X[i:i+self.window_width]\n",
    "        return vectors\n",
    "\n",
    "    def __build_sets(self):\n",
    "\n",
    "        X = self.dataframe.iloc[:,:-1].values\n",
    "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
    "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
    "\n",
    "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
    "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
    "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
    "\n",
    "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
    "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
    "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
    "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
    "\n",
    "    def standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
    "        X = self.scalar.transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "    def inverse_standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        X = self.scalar.inverse_transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "\n",
    "    def model_persistence(self, x):\n",
    "        return x\n",
    "        \n",
    "    def create_persistence(self):\n",
    "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
    "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
    "\n",
    "    def fit(self):\n",
    "        self.create_persistence()\n",
    "        self.standardize_dataframe()\n",
    "        self.__build_sets()\n",
    "                \n",
    "        self.compute_anomalyScores()\n",
    "        self.inverse_standardize_dataframe()\n",
    "\n",
    "        return self.history.history\n",
    "\n",
    "    def plotTraining(self):\n",
    "        history_dict = self.history.history\n",
    "        loss_values = history_dict['loss'][1:]\n",
    "        val_loss_values = history_dict['val_loss'][1:]\n",
    "        self.n_epochs = range(2, self.n_epochs + 1)\n",
    "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
    "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def compute_anomalyScores(self):\n",
    "\n",
    "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
    "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
    "\n",
    "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "        self.model = Sequential()\n",
    "\n",
    "        self.model.add(Conv1D(filters=self.n_filters[0], kernel_size=self.kernel_size, activation='relu', input_shape=(self.window_width,self.dimension ),data_format='channels_first', padding='same', dilation_rate=1))\n",
    "        self.model.add(MaxPooling1D(pool_size=2))\n",
    "        self.model.add(Conv1D(filters=self.n_filters[1], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate=2))\n",
    "        self.model.add(MaxPooling1D(pool_size=2))\n",
    "        self.model.add(Conv1D(filters=self.n_filters[2], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate = 4))\n",
    "        self.model.add(MaxPooling1D(pool_size=2))\n",
    "        self.model.add(Conv1D(filters=self.n_filters[3], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate = 8))\n",
    "        self.model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(self.n_dense, activation='relu'))\n",
    "        self.model.add(Dense(self.dimension))\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "        self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=0)\n",
    "\n",
    "        # self.plotTraining()\n",
    "        self.predictions = self.model.predict(self.test_X)\n",
    "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
    "        self.compute_errors(self.distance_function)\n",
    "\n",
    "\n",
    "    def compute_Errors_RMSE(self):\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
    "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
    "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
    "   \n",
    "\n",
    "    def plot(self):\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            data = self.df[self.df.columns[i]].iloc[:200]\n",
    "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
    "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
    "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
    "            ax.legend()\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    def compute_errors(self, distance_function):\n",
    "        if distance_function == 'mahalanobis':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
    "        elif distance_function == 'euclidean':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.euclidean(error,mean)\n",
    "\n",
    "    def get_roc_auc(self, plot=True, verbose=True):\n",
    "        # get the predicted errors of the anomaly points\n",
    "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
    "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
    "        if len(true_anomaly_predicted_errors) == 0:\n",
    "            return np.nan\n",
    "        # sort them \n",
    "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
    "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
    "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
    "                # now iterate thru the predicted errors from small to big\n",
    "        # for each value look how much other points have equal or bigger error\n",
    "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "        TPR = [] # tp/p\n",
    "        p = len(true_anomaly_predicted_errors)\n",
    "        Thresholds = []\n",
    "        for predictederror in true_anomaly_predicted_errors_extended:\n",
    "            threshold = predictederror\n",
    "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
    "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
    "            \n",
    "            fpr =fp/len(self.errors)\n",
    "            FPR.append(fpr)\n",
    "            TPR.append(tp/p)\n",
    "            if verbose:\n",
    "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.axis([0, 1, 0, 1])\n",
    "            plt.plot(FPR,TPR)\n",
    "            plt.show() \n",
    "\n",
    "        # This is the AUC\n",
    "        from sklearn.metrics import auc\n",
    "        print('AUC: ' ,auc(FPR,TPR)        )\n",
    "        return auc(FPR,TPR)\n",
    "\n",
    "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
    "# kernelsizes = [2,3,4,6,8,16]\n",
    "# dense = [18,36,72,144]\n",
    "\n",
    "# best_auc = [0,0]\n",
    "# histories = []\n",
    "# for f in filters:\n",
    "#     for k in kernelsizes:\n",
    "#         for d in dense:\n",
    "\n",
    "#             cnn = WaveNet_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,f,k,d)\n",
    "#             hist = cnn.fit()\n",
    "#             histories.append(((f,k,d), hist))\n",
    "#             # cnn.plot()\n",
    "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#             if best_auc[1] < auc:\n",
    "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#                 best_auc = [(f,k,d),auc]\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "# print(best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aq1_t3wttetJ"
   },
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecn1JaLvtgls"
   },
   "source": [
    "### Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "2tTJITJCtjOH",
    "outputId": "e529d60f-e485-413b-f4b9-065345d7d77f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9387544125063035\n",
      "Time:  11\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "import glob\n",
    "\n",
    "cnn = WaveNet_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8,8],2,18, 'mahalanobis')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iIvSJywNFNOb",
    "outputId": "daf75bed-3bb3-4307-c855-797953924521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6460911020273663\n",
      "Time:  149\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "import glob\n",
    "\n",
    "cnn = WaveNet_AnomalyDetection.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,20,0.3,[8,8,8,8],2,18, 'mahalanobis')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3J68348ktjyz"
   },
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "BI7URuMQtlNa",
    "outputId": "f7b46bff-2a77-4392-b515-1d1d7d29021b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7364923276421009\n",
      "Time:  12\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "import glob\n",
    "\n",
    "cnn = WaveNet_AnomalyDetection.from_DataFrame(df_synthetic,30,5,20,0.3,[8,8,8,8],2,18, 'euclidean')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dBR3tPzaFdPO",
    "outputId": "3291c421-b933-40ed-8e46-a0c4d97a8d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5178404704368567\n",
      "Time:  150\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "import glob\n",
    "\n",
    "cnn = WaveNet_AnomalyDetection.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,20,0.3,[8,8,8,8],2,18, 'euclidean')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LuYUXOTxDD9h"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sx6_hBnUDFKy"
   },
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np \n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from numpy.random import seed\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "seed(42)\n",
    "from keras import regularizers\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    \n",
    "class LSTM_AnomalyDetection_ML:\n",
    "    @classmethod\n",
    "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, distance_function) -> 'LSTM_AnomalyDetection_ML':\n",
    "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, distance_function)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, distance_function) -> 'LSTM_AnomalyDetection_ML':\n",
    "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
    "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, distance_function)\n",
    "     \n",
    "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, distance_function):\n",
    "\n",
    "        self.dimension = dimension\n",
    "        self.n_epochs = n_epochs\n",
    "        self.window_width = window_width\n",
    "        self.distance_function = distance_function\n",
    "\n",
    "        self.n_filters = n_filters\n",
    "\n",
    "        self.df = df\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
    "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
    "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
    "\n",
    "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
    "        self.values = df_sensors\n",
    "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
    "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
    "\n",
    "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
    "        # self.dataframe.columns = ['t', 't+1']\n",
    "\n",
    "        self.train_size = int(len(self.values) * train_rate)  \n",
    "\n",
    "\n",
    "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back),:self.dimension]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
    "        return numpy.array(dataX), numpy.array(dataY)\n",
    "    \n",
    "    def getWindowedVectors(self, X):\n",
    "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
    "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
    "            vectors[i] = X[i:i+self.window_width]\n",
    "        return vectors\n",
    "\n",
    "    def __build_sets(self):\n",
    "\n",
    "        X = self.dataframe.iloc[:,:-1].values\n",
    "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
    "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
    "\n",
    "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
    "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
    "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
    "\n",
    "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
    "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
    "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
    "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
    "\n",
    "    def standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
    "        X = self.scalar.transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "    def inverse_standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        X = self.scalar.inverse_transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "\n",
    "    def model_persistence(self, x):\n",
    "        return x\n",
    "        \n",
    "    def create_persistence(self):\n",
    "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
    "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
    "\n",
    "    def fit(self):\n",
    "        self.create_persistence()\n",
    "        self.standardize_dataframe()\n",
    "        self.__build_sets()\n",
    "                \n",
    "        self.compute_anomalyScores()\n",
    "        self.inverse_standardize_dataframe()\n",
    "\n",
    "\n",
    "    def plotTraining(self):\n",
    "        history_dict = self.history.history\n",
    "        loss_values = history_dict['loss'][1:]\n",
    "        val_loss_values = history_dict['val_loss'][1:]\n",
    "        self.n_epochs = range(2, self.n_epochs + 1)\n",
    "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
    "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def compute_anomalyScores(self):\n",
    "\n",
    "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
    "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
    "\n",
    "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "        self.model = Sequential()\n",
    "\n",
    "        import datetime\n",
    "        startTime = datetime.datetime.now()\n",
    "\n",
    "        self.train_X = numpy.reshape(self.train_X, (-1, self.window_width, self.dimension))\n",
    "        self.test_X = numpy.reshape(self.test_X, (-1, self.window_width, self.dimension))\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(LSTM(self.n_filters[0], batch_input_shape=(1, self.window_width, self.dimension), stateful=True, return_sequences=True))\n",
    "        self.model.add(LSTM(self.n_filters[1], batch_input_shape=(1, self.window_width, self.dimension), stateful=True))\n",
    "        self.model.add(Dense(self.dimension))\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "        for i in range(self.n_epochs):\n",
    "            print('Epoch',i, '/',self.n_epochs)\n",
    "            self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, batch_size=1, verbose=1, shuffle=False)\n",
    "            self.model.reset_states()\n",
    "        # self.history =self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=2)\n",
    "        \n",
    "        # self.plotTraining()\n",
    "        self.predictions = self.model.predict(self.test_X, batch_size = 1)\n",
    "\n",
    "        endTime = datetime.datetime.now()\n",
    "        diff = endTime - startTime\n",
    "        print('Train and Test time: ',diff.seconds)\n",
    "\n",
    "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
    "        self.compute_errors(self.distance_function)\n",
    "\n",
    "    def compute_Errors_RMSE(self):\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
    "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
    "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
    "   \n",
    "    def compute_errors(self, distance_function):\n",
    "        if distance_function == 'mahalanobis':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
    "        elif distance_function == 'euclidean':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.euclidean(error,mean)\n",
    "\n",
    "    def plot(self):\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            data = self.df[self.df.columns[i]].iloc[:200]\n",
    "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
    "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
    "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
    "            ax.legend()\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    def get_roc_auc(self, plot=True, verbose=True):\n",
    "\n",
    "        # get the predicted errors of the anomaly points\n",
    "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
    "        # get the predicted errors of the anomaly points\n",
    "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
    "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
    "        if len(true_anomaly_predicted_errors) == 0:\n",
    "            return np.nan\n",
    "        # sort them \n",
    "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
    "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
    "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
    "                # now iterate thru the predicted errors from small to big\n",
    "        # for each value look how much other points have equal or bigger error\n",
    "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "        TPR = [] # tp/p\n",
    "        p = len(true_anomaly_predicted_errors)\n",
    "        Thresholds = []\n",
    "        for predictederror in true_anomaly_predicted_errors_extended:\n",
    "            threshold = predictederror\n",
    "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
    "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
    "            \n",
    "            fpr =fp/len(self.errors)\n",
    "            FPR.append(fpr)\n",
    "            TPR.append(tp/p)\n",
    "            if verbose:\n",
    "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.axis([0, 1, 0, 1])\n",
    "            plt.plot(FPR,TPR)\n",
    "            plt.show() \n",
    "\n",
    "        # This is the AUC\n",
    "        from sklearn.metrics import auc\n",
    "        print('AUC: ' ,auc(FPR,TPR)        )\n",
    "        return auc(FPR,TPR)\n",
    "\n",
    "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
    "# kernelsizes = [2,3,4,6,8,16]\n",
    "# dense = [18,36,72,144]\n",
    "\n",
    "# best_auc = [0,0]\n",
    "# histories = []\n",
    "# for f in filters:\n",
    "#     for k in kernelsizes:\n",
    "#         for d in dense:\n",
    "\n",
    "#             cnn = LSTM_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,f)\n",
    "#             cnn.fit()\n",
    "#             # cnn.plot()\n",
    "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#             if best_auc[1] < auc:\n",
    "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#                 best_auc = [(f,k,d),auc]\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "# print(best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TAo7V5sypBzq"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9MpTT1JpDNm"
   },
   "source": [
    "### Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "ujhYTewnpFMN",
    "outputId": "de23c657-1189-46db-be16-01579d0e0b60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 1\n",
      "Epoch 1/1\n",
      "868/868 [==============================] - 89s 103ms/step - loss: 0.9879\n",
      "Train and Test time:  162\n",
      "AUC:  0.9329551185073122\n",
      "Time:  162.393739\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "import glob\n",
    "\n",
    "cnn = LSTM_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,[8,8,8,8], 'mahalanobis')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "dDX6Z4QNGWFI",
    "outputId": "76a95dc9-1198-4063-d0d5-874455fcf42d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 1\n",
      "Epoch 1/1\n",
      "28514/28514 [==============================] - 2549s 89ms/step - loss: 1.5927\n",
      "Train and Test time:  4672\n",
      "AUC:  0.4045405865553603\n",
      "Time:  4673.839763\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "import glob\n",
    "\n",
    "cnn = LSTM_AnomalyDetection_ML.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,1,0.3,[8,8,8,8], 'mahalanobis')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FddjuzQJpF5K"
   },
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "Ti-La97vpG9U",
    "outputId": "a719c669-919b-47df-abea-264d4627ffcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 1\n",
      "Epoch 1/1\n",
      "868/868 [==============================] - 89s 102ms/step - loss: 0.9829\n",
      "Train and Test time:  164\n",
      "AUC:  0.7309739932281537\n",
      "Time:  164.446388\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "import glob\n",
    "\n",
    "cnn = LSTM_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,[8,8,8,8], 'euclidean')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGpQmmBvGfQd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 1\n",
      "Epoch 1/1\n",
      "28514/28514 [==============================] - 2573s 90ms/step - loss: 1.5887\n",
      "Train and Test time:  4605\n",
      "AUC:  0.487959079996234\n",
      "Time:  4607.232518\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "import glob\n",
    "\n",
    "cnn = LSTM_AnomalyDetection_ML.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,1,0.3,[8,8,8,8], 'euclidean')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4muiAAUdp1w"
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EPaetWYdqxB"
   },
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np \n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from numpy.random import seed\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "seed(42)\n",
    "from keras import regularizers\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    \n",
    "class GRU_AnomalyDetection_ML:\n",
    "    @classmethod\n",
    "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, n_filters, distance_function) -> 'LSTM_AnomalyDetection_ML':\n",
    "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, n_filters, distance_function)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, n_filters, distance_function) -> 'LSTM_AnomalyDetection_ML':\n",
    "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
    "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, n_filters, distance_function)\n",
    "     \n",
    "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, n_filters, distance_function):\n",
    "\n",
    "        self.dimension = dimension\n",
    "        self.n_epochs = n_epochs\n",
    "        self.window_width = window_width\n",
    "        self.distance_function = distance_function\n",
    "        self.n_filters = n_filters\n",
    "\n",
    "        self.df = df\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
    "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
    "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
    "\n",
    "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
    "        self.values = df_sensors\n",
    "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
    "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
    "\n",
    "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
    "        # self.dataframe.columns = ['t', 't+1']\n",
    "\n",
    "        self.train_size = int(len(self.values) * train_rate)  \n",
    "\n",
    "\n",
    "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back),:self.dimension]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
    "        return numpy.array(dataX), numpy.array(dataY)\n",
    "    \n",
    "    def getWindowedVectors(self, X):\n",
    "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
    "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
    "            vectors[i] = X[i:i+self.window_width]\n",
    "        return vectors\n",
    "\n",
    "    def __build_sets(self):\n",
    "\n",
    "        X = self.dataframe.iloc[:,:-1].values\n",
    "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
    "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
    "\n",
    "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
    "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
    "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
    "\n",
    "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
    "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
    "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
    "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
    "\n",
    "    def standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
    "        X = self.scalar.transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "    def inverse_standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        X = self.scalar.inverse_transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "\n",
    "    def model_persistence(self, x):\n",
    "        return x\n",
    "        \n",
    "    def create_persistence(self):\n",
    "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
    "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
    "\n",
    "    def fit(self):\n",
    "        self.create_persistence()\n",
    "        self.standardize_dataframe()\n",
    "        self.__build_sets()\n",
    "                \n",
    "        self.compute_anomalyScores()\n",
    "        self.inverse_standardize_dataframe()\n",
    "        # self.compute_Errors_RMSE()\n",
    "\n",
    "\n",
    "    def plotTraining(self):\n",
    "        history_dict = self.history.history\n",
    "        loss_values = history_dict['loss'][1:]\n",
    "        val_loss_values = history_dict['val_loss'][1:]\n",
    "        self.n_epochs = range(2, self.n_epochs + 1)\n",
    "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
    "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def compute_anomalyScores(self):\n",
    "\n",
    "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
    "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
    "\n",
    "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "        self.model = Sequential()\n",
    "\n",
    "        # self.model.add(Conv1D(filters=self.n_filters[0], kernel_size=self.kernel_size, activation='relu', input_shape=(self.window_width,self.dimension ),data_format='channels_first', padding='same', dilation_rate=1))\n",
    "        # self.model.add(MaxPooling1D(pool_size=2))\n",
    "        # self.model.add(Conv1D(filters=self.n_filters[1], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate=2))\n",
    "        # self.model.add(MaxPooling1D(pool_size=2))\n",
    "        # self.model.add(Conv1D(filters=self.n_filters[2], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate = 4))\n",
    "        # self.model.add(MaxPooling1D(pool_size=2))\n",
    "        # self.model.add(Conv1D(filters=self.n_filters[3], kernel_size=self.kernel_size, activation='relu',data_format='channels_first', padding='same', dilation_rate = 8))\n",
    "        # self.model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "        # self.model.add(Flatten())\n",
    "        # self.model.add(Dense(self.n_dense, activation='relu'))\n",
    "        # self.model.add(Dense(self.dimension))\n",
    "        # self.model.compile(optimizer='adam', loss='mse')\n",
    "        # self.history = self.model.fit(self.train_X, self.train_y,validation_data=(self.val_X,self.val_y), epochs=self.n_epochs, verbose=0)\n",
    "        import datetime\n",
    "        startTime = datetime.datetime.now()\n",
    "\n",
    "        self.train_X = numpy.reshape(self.train_X, (-1, self.window_width, self.dimension))\n",
    "        self.test_X = numpy.reshape(self.test_X, (-1, self.window_width, self.dimension))\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(GRU(self.n_filters[0], batch_input_shape=(1, self.window_width, self.dimension), stateful=True, return_sequences=True))\n",
    "        self.model.add(GRU(self.n_filters[1], batch_input_shape=(1, self.window_width, self.dimension), stateful=True))\n",
    "        self.model.add(Dense(self.dimension))\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "        for i in range(self.n_epochs):\n",
    "            print('Epoch',i, '/',self.n_epochs)\n",
    "            self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, batch_size=1, verbose=1, shuffle=False)\n",
    "            self.model.reset_states()\n",
    "        # self.history =self.model.fit(self.train_X, self.train_y, epochs=self.n_epochs, verbose=2)\n",
    "        \n",
    "        # self.plotTraining()\n",
    "        self.predictions = self.model.predict(self.test_X, batch_size = 1)\n",
    "\n",
    "        endTime = datetime.datetime.now()\n",
    "        diff = endTime - startTime\n",
    "        print('Train and Test time: ',diff.seconds)\n",
    "\n",
    "        self.error_vect = (self.test_y.reshape(self.predictions.shape) - self.predictions).reshape(self.test_y.shape[0],-1)\n",
    "        self.compute_errors(self.distance_function)\n",
    "\n",
    "    def compute_Errors_RMSE(self):\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
    "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
    "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
    "   \n",
    "    def compute_errors(self, distance_function):\n",
    "        if distance_function == 'mahalanobis':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
    "        elif distance_function == 'euclidean':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.euclidean(error,mean)\n",
    "\n",
    "    def plot(self):\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            data = self.df[self.df.columns[i]].iloc[:200]\n",
    "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
    "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
    "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
    "            ax.legend()\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    def get_roc_auc(self, plot=True, verbose=True):\n",
    "\n",
    "        # get the predicted errors of the anomaly points\n",
    "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
    "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
    "        if len(true_anomaly_predicted_errors) == 0:\n",
    "            return np.nan\n",
    "        # sort them \n",
    "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
    "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
    "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
    "                # now iterate thru the predicted errors from small to big\n",
    "        # for each value look how much other points have equal or bigger error\n",
    "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "        TPR = [] # tp/p\n",
    "        p = len(true_anomaly_predicted_errors)\n",
    "        Thresholds = []\n",
    "        for predictederror in true_anomaly_predicted_errors_extended:\n",
    "            threshold = predictederror\n",
    "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
    "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
    "            \n",
    "            fpr =fp/len(self.errors)\n",
    "            FPR.append(fpr)\n",
    "            TPR.append(tp/p)\n",
    "            if verbose:\n",
    "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.axis([0, 1, 0, 1])\n",
    "            plt.plot(FPR,TPR)\n",
    "            plt.show() \n",
    "\n",
    "        # This is the AUC\n",
    "        from sklearn.metrics import auc\n",
    "        print('AUC: ' ,auc(FPR,TPR)        )\n",
    "        return auc(FPR,TPR)\n",
    "\n",
    "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
    "# kernelsizes = [2,3,4,6,8,16]\n",
    "# dense = [18,36,72,144]\n",
    "\n",
    "# best_auc = [0,0]\n",
    "# histories = []\n",
    "# for f in filters:\n",
    "#     for k in kernelsizes:\n",
    "#         for d in dense:\n",
    "\n",
    "#             cnn = LSTM_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,f)\n",
    "#             cnn.fit()\n",
    "#             # cnn.plot()\n",
    "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#             if best_auc[1] < auc:\n",
    "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#                 best_auc = [(f,k,d),auc]\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "# print(best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IbbFQY-FntLl"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVfGqbxjnun8"
   },
   "source": [
    "### Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "OYXhN080nwpC",
    "outputId": "81105d2f-9283-4aa8-9ae2-fdd543cf4951"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 1\n",
      "Epoch 1/1\n",
      "868/868 [==============================] - 69s 79ms/step - loss: 0.9978\n",
      "Train and Test time:  133\n",
      "AUC:  0.9332504862762049\n",
      "Time:  133.816162\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = GRU_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,[8,8,8,8], 'mahalanobis')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EW5aA6e_Gj9_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 1\n",
      "Epoch 1/1\n",
      "28514/28514 [==============================] - 2064s 72ms/step - loss: 1.5834\n",
      "Train and Test time:  3855\n",
      "AUC:  0.5382788962465478\n",
      "Time:  3856.191389\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = GRU_AnomalyDetection_ML.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,1,0.3,[8,8,8,8], 'mahalanobis')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cwC-0roo5na"
   },
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "7pZu3QWZo6nk",
    "outputId": "63128b99-760c-4478-c3c0-0f816006d041"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoBray\\.conda\\envs\\TensorFlow_GPU_Keras\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 1\n",
      "Epoch 1/1\n",
      "868/868 [==============================] - 69s 79ms/step - loss: 0.9958\n",
      "Train and Test time:  132\n",
      "AUC:  0.7467473524962177\n",
      "Time:  132.870664\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = GRU_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3,[8,8,8,8], 'euclidean')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4s7LhygGxnu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 1\n",
      "Epoch 1/1\n",
      "28514/28514 [==============================] - 2069s 73ms/step - loss: 1.5938\n",
      "Train and Test time:  3873\n",
      "AUC:  0.49810375737509416\n",
      "Time:  3874.948258\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = GRU_AnomalyDetection_ML.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,1,0.3,[8,8,8,8], 'euclidean')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iy3Xx__Hfj2e"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "av9K33PlflOR",
    "outputId": "30230755-4ac8-469a-834a-874218419db9"
   },
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np \n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "from numpy.random import seed\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import LSTM, GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "seed(42)\n",
    "from keras import regularizers, Model\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "    \n",
    "class AutoEncoder_AnomalyDetection_ML:\n",
    "    @classmethod\n",
    "    def from_DataFrame(cls,dataframe,window_width, dimension, n_epochs, train_rate, distance_function, filters) -> 'AutoEncoder_AnomalyDetection_ML':\n",
    "    \treturn cls(dataframe, window_width, dimension, n_epochs, train_rate, distance_function, filters)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, path, index_col, window_width, dimension,n_epochs, train_rate, distance_function, filters) -> 'AutoEncoder_AnomalyDetection_ML':\n",
    "    \tdf = read_csv(path, header=0, index_col=index_col, parse_dates=True,squeeze=True)\n",
    "    \treturn cls(df, window_width, dimension, n_epochs, train_rate, distance_function, filters)\n",
    "     \n",
    "    def __init__(self,df, window_width, dimension, n_epochs, train_rate, distance_function, filters):\n",
    "        self.filters = filters\n",
    "        self.distance_function = distance_function\n",
    "        self.dimension = dimension\n",
    "        self.n_epochs = n_epochs\n",
    "        self.window_width = window_width\n",
    "        \n",
    "        self.df = df\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.df.rename(columns={'Target':'is_anomaly'}, inplace=True)\n",
    "        self.df.loc[self.df.is_anomaly == \"'Anomaly'\", 'is_anomaly'] = 1\n",
    "        self.df.loc[self.df.is_anomaly == \"'Normal'\", 'is_anomaly'] = 0\n",
    "\n",
    "        df_sensors = pd.DataFrame(self.df.iloc[:,:dimension].values)  \n",
    "        self.values = df_sensors\n",
    "        self.dataframe = concat([self.df.iloc[:,:-1].shift(1), self.df.iloc[:,:-1], self.df.iloc[:,-1]], axis=1)\n",
    "        self.dataframe.columns = np.r_[np.array(['V'+str(i)+'_t' for i in range(1,self.dimension+1)]),np.array(['V'+str(i)+'_t+1' for i in range(1,self.dimension+1)]),['is_anomaly']]\n",
    "\n",
    "        # self.dataframe = concat([self.values.shift(1), self.values], axis=1)\n",
    "        # self.dataframe.columns = ['t', 't+1']\n",
    "\n",
    "        self.train_size = int(len(self.values) * train_rate)  \n",
    "\n",
    "\n",
    "    def create_XY_lookback_dataset(self,dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back),:self.dimension]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back,:self.dimension].reshape(-1))\n",
    "        return numpy.array(dataX), numpy.array(dataY)\n",
    "    \n",
    "    def getWindowedVectors(self, X):\n",
    "        vectors = np.zeros((len(X) - self.window_width+1,self.window_width))\n",
    "        for i,_ in enumerate(X[:-self.window_width+1]):\n",
    "            vectors[i] = X[i:i+self.window_width]\n",
    "        return vectors\n",
    "\n",
    "    def __build_sets(self):\n",
    "\n",
    "        X = self.dataframe.iloc[:,:-1].values\n",
    "        self.train, self.test = X[1:self.train_size], X[self.train_size:]    \n",
    "        # print('Train.len:',len(self.train),' - Test.len:', len(self.test))\n",
    "\n",
    "        self.train_X, self.train_y = self.create_XY_lookback_dataset(self.train, self.window_width)\n",
    "        self.test_X, self.test_y = self.create_XY_lookback_dataset(self.test, self.window_width)\n",
    "        # print('TrainX.shape:',self.train_X.shape,' - TestX.shape:', self.test_X.shape,' - TrainY.shape:', self.train_y.shape,' - TestY.shape:', self.test_y.shape)\n",
    "\n",
    "        self.validationsize = int(self.train_X.shape[0] * 0.1)\n",
    "        self.val, self.test = self.test[:self.validationsize], self.test[self.validationsize:]\n",
    "        self.val_X, self.val_y= self.test_X[:self.validationsize], self.test_y[:self.validationsize]\n",
    "        self.test_X, self.test_y = self.test_X[self.validationsize:], self.test_y[self.validationsize:]\n",
    "\n",
    "    def standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        self.scalar = preprocessing.StandardScaler().fit(X)\n",
    "        X = self.scalar.transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "    def inverse_standardize_dataframe(self):\n",
    "        X = self.dataframe.values\n",
    "        X = self.scalar.inverse_transform(X)\n",
    "        self.dataframe = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "\n",
    "    def model_persistence(self, x):\n",
    "        return x\n",
    "        \n",
    "    def create_persistence(self):\n",
    "        rmse = sqrt(mean_squared_error(self.dataframe.iloc[self.train_size:,:self.dimension], self.dataframe.iloc[self.train_size:,self.dimension:-1]))\n",
    "        # print('Persistent Model RMSE: %.3f' % rmse)   \n",
    "\n",
    "    def fit(self):\n",
    "        self.create_persistence()\n",
    "        self.standardize_dataframe()\n",
    "        self.__build_sets()\n",
    "                \n",
    "        self.compute_anomalyScores()\n",
    "        self.inverse_standardize_dataframe()\n",
    "        # self.compute_Errors_RMSE()\n",
    "\n",
    "\n",
    "    def plotTraining(self):\n",
    "        history_dict = self.history.history\n",
    "        loss_values = history_dict['loss'][1:]\n",
    "        val_loss_values = history_dict['val_loss'][1:]\n",
    "        self.n_epochs = range(2, self.n_epochs + 1)\n",
    "        plt.plot(self.n_epochs, loss_values, 'bo', label='Training loss')\n",
    "        plt.plot(self.n_epochs, val_loss_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def compute_anomalyScores(self):\n",
    "\n",
    "        # self.train_X = numpy.reshape(self.train_X, (self.train_X.shape[0],self.dimension,self.train_X.shape[1]))\n",
    "        # self.test_X = numpy.reshape(self.test_X, (self.test_X.shape[0],self.dimension, self.test_X.shape[1]))\n",
    "\n",
    "        from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "        self.model = Sequential()\n",
    "\n",
    "\n",
    "        self.train_X = numpy.reshape(self.train_X, (-1, self.window_width, self.dimension))\n",
    "        self.test_X = numpy.reshape(self.test_X, (-1, self.window_width, self.dimension))\n",
    "\n",
    "        input_layer = Input(shape=( self.window_width, self.dimension))\n",
    "        encoder = Dense(self.filters[0], activation=\"relu\")(input_layer)\n",
    "        encoder = Dense(self.filters[1], activation=\"relu\")(encoder)\n",
    "        decoder = Dense(self.filters[1], activation=\"relu\")(encoder)\n",
    "        decoder = Dense(self.filters[0], activation=\"relu\")(decoder)\n",
    "        decoder = Dense(self.dimension, activation=\"linear\")(decoder)\n",
    "        self.model = Model(inputs=input_layer, outputs=decoder)\n",
    "        \n",
    "        self.model.compile(metrics=['accuracy'],\n",
    "                            loss='mean_squared_error',\n",
    "                            optimizer='adam')\n",
    "        channel_pos = 'channels_first'\n",
    "\n",
    "\n",
    "        history = self.model.fit(self.train_X, self.train_X, epochs=self.n_epochs, verbose=2)\n",
    "\n",
    "        # self.plotTraining()\n",
    "        self.predictions = self.model.predict(self.test_X, batch_size = 1)\n",
    "        self.error_vect = (self.test_X.reshape(self.predictions.shape) - self.predictions).reshape(self.test_X.shape[0],-1)\n",
    "        self.compute_errors(self.distance_function)\n",
    "\n",
    "    def compute_Errors_RMSE(self):\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(self.test_y.reshape(self.predictions.shape), self.predictions))\n",
    "        self.errors = np.absolute(self.test_y.reshape(self.predictions.shape) - np.array(self.predictions))\n",
    "        # print('Prediction Test RMS        E: %.3f' % rmse)       \n",
    "   \n",
    "\n",
    "    def plot(self):\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=3, dpi=120, figsize=(50,5))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            data = self.df[self.df.columns[i]].iloc[:200]\n",
    "            ax.plot(self.test_y[:,i], color='green',  linewidth=0.5,label='True Values')\n",
    "            ax.plot(self.predictions[:,i], color='blue',  linewidth=0.5,label='Predictions')\n",
    "            ax.plot(self.errors[:,i], color = 'red',  linewidth=0.5, label='Errors')\n",
    "            ax.legend()\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    def compute_errors(self, distance_function):\n",
    "        if distance_function == 'mahalanobis':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.mahalanobis(error,mean,inv_cov)\n",
    "        elif distance_function == 'euclidean':\n",
    "            inv_cov = scipy.linalg.inv(np.cov(self.error_vect.T))\n",
    "            mean = np.mean(self.error_vect,axis=0)\n",
    "            self.errors = np.zeros((len(self.error_vect),1))\n",
    "            for i,error in enumerate(self.error_vect):\n",
    "                self.errors[i] = distance.euclidean(error,mean)\n",
    "                \n",
    "    def get_roc_auc(self, plot=True, verbose=True):\n",
    "        # self.euclidean_errors = numpy.linalg.norm((self.test_X.reshape(self.predictions.shape) - self.predictions).reshape(self.test_X.shape[0],-1), axis=1)\n",
    "        # get the predicted errors of the anomaly points\n",
    "        indices = self.df[self.df['is_anomaly']==1].index >self.train_size + self.validationsize\n",
    "        true_anomaly_predicted_errors = self.errors[self.df[self.df['is_anomaly']==1].index[indices] - self.train_size - self.validationsize - self.window_width -1]\n",
    "        if len(true_anomaly_predicted_errors) == 0:\n",
    "            return np.nan\n",
    "        # sort them \n",
    "        true_anomaly_predicted_errors = np.sort(true_anomaly_predicted_errors,axis=0).reshape(-1)\n",
    "        true_anomaly_predicted_errors_extended = np.r_[np.linspace(0,true_anomaly_predicted_errors[0],40)[:-1],true_anomaly_predicted_errors]\n",
    "        true_anomaly_predicted_errors_extended = np.r_[true_anomaly_predicted_errors_extended, true_anomaly_predicted_errors_extended[-1] + np.mean(true_anomaly_predicted_errors_extended)]\n",
    "                # now iterate thru the predicted errors from small to big\n",
    "        # for each value look how much other points have equal or bigger error\n",
    "        FPR = [] # fp/n  https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "        TPR = [] # tp/p\n",
    "        p = len(true_anomaly_predicted_errors)\n",
    "        Thresholds = []\n",
    "        for predictederror in true_anomaly_predicted_errors_extended:\n",
    "            threshold = predictederror\n",
    "            tp = len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>= threshold])\n",
    "            fp = len(self.errors[self.errors>=threshold])-len(true_anomaly_predicted_errors[true_anomaly_predicted_errors>=threshold])\n",
    "            \n",
    "            fpr =fp/len(self.errors)\n",
    "            FPR.append(fpr)\n",
    "            TPR.append(tp/p)\n",
    "            if verbose:\n",
    "                print(\"Threshold: {0:25}  - FP: {1:4} - TP: {2:4} - FPR: {3:21} - TPR: {4:4}\".format(threshold,fp, tp, fpr, tp/p))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.axis([0, 1, 0, 1])\n",
    "            plt.plot(FPR,TPR)\n",
    "            plt.show() \n",
    "\n",
    "        # This is the AUC\n",
    "        from sklearn.metrics import auc\n",
    "        print('AUC: ' ,auc(FPR,TPR)        )\n",
    "        return auc(FPR,TPR)\n",
    "\n",
    "# filters = [[8,8,8,8], [4,4,4,4], [4,8,16], [4,8,12], [16,32,48], [128,128,128],[64,64,64],[256,256,256],[128,256,512]]\n",
    "# kernelsizes = [2,3,4,6,8,16]\n",
    "# dense = [18,36,72,144]\n",
    "\n",
    "# best_auc = [0,0]\n",
    "# histories = []\n",
    "# for f in filters:\n",
    "#     for k in kernelsizes:\n",
    "#         for d in dense:\n",
    "\n",
    "#             cnn = AutoEncoder_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3, 'euclidean')\n",
    "#             cnn.fit()\n",
    "#             # cnn.plot()\n",
    "#             auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "#             print(' auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#             if best_auc[1] < auc:\n",
    "#                 print('New best auc:', auc, ' - f:', f, ' - k:', k, ' - d:', d)\n",
    "#                 best_auc = [(f,k,d),auc]\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "# print(best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIoZnpfmnQv9"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ub1g_OkQnSuO"
   },
   "source": [
    "### Mahalanobis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "wEjE8jnhnUlD",
    "outputId": "403ba32a-0ab5-4b12-d61f-2c3fe6934617"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "from_DataFrame() missing 1 required positional argument: 'filters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-463458374b65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstartTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoEncoder_AnomalyDetection_ML\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_DataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_synthetic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mahalanobis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_roc_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: from_DataFrame() missing 1 required positional argument: 'filters'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = AutoEncoder_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3, 'mahalanobis')\n",
    "cnn.fit()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "N2GeeyCAG1kx",
    "outputId": "1739761c-042d-484b-ce8f-0d50d5294a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 6s - loss: 1.2995 - acc: 0.4083\n",
      "Epoch 2/15\n",
      " - 4s - loss: 0.8748 - acc: 0.2694\n",
      "Epoch 3/15\n",
      " - 4s - loss: 0.5807 - acc: 0.3188\n",
      "Epoch 4/15\n",
      " - 4s - loss: 0.3052 - acc: 0.4559\n",
      "Epoch 5/15\n",
      " - 4s - loss: 0.2357 - acc: 0.6114\n",
      "Epoch 6/15\n",
      " - 5s - loss: 0.2220 - acc: 0.6245\n",
      "Epoch 7/15\n",
      " - 5s - loss: 0.2183 - acc: 0.6119\n",
      "Epoch 8/15\n",
      " - 5s - loss: 0.2182 - acc: 0.6097\n",
      "Epoch 9/15\n",
      " - 5s - loss: 0.2163 - acc: 0.6035\n",
      "Epoch 10/15\n",
      " - 4s - loss: 0.2073 - acc: 0.5988\n",
      "Epoch 11/15\n",
      " - 4s - loss: 0.2065 - acc: 0.6005\n",
      "Epoch 12/15\n",
      " - 4s - loss: 0.2069 - acc: 0.6041\n",
      "Epoch 13/15\n",
      " - 4s - loss: 0.2069 - acc: 0.6018\n",
      "Epoch 14/15\n",
      " - 4s - loss: 0.2066 - acc: 0.6018\n",
      "Epoch 15/15\n",
      " - 4s - loss: 0.2069 - acc: 0.6020\n",
      "AUC:  0.9027478110092894\n",
      "Time:  150\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = AutoEncoder_AnomalyDetection_ML.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,15,0.3, 'mahalanobis',[4,2])\n",
    "cnn.fit()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "N2GeeyCAG1kx",
    "outputId": "1739761c-042d-484b-ce8f-0d50d5294a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 7s - loss: 1.6120 - acc: 0.3863\n",
      "Epoch 2/20\n",
      " - 4s - loss: 1.0141 - acc: 0.3031\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.2420 - acc: 0.6239\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.0725 - acc: 0.6977\n",
      "Epoch 5/20\n",
      " - 4s - loss: 0.0338 - acc: 0.7135\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.0207 - acc: 0.7064\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.0172 - acc: 0.7009\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.0169 - acc: 0.6941\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.0170 - acc: 0.6939\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.0163 - acc: 0.6913\n",
      "Epoch 11/20\n",
      " - 4s - loss: 0.0162 - acc: 0.6915\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.0163 - acc: 0.6928\n",
      "Epoch 13/20\n",
      " - 4s - loss: 0.0156 - acc: 0.6937\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.0164 - acc: 0.6933\n",
      "Epoch 15/20\n",
      " - 4s - loss: 0.0159 - acc: 0.6955\n",
      "Epoch 16/20\n",
      " - 4s - loss: 0.0157 - acc: 0.6996\n",
      "Epoch 17/20\n",
      " - 4s - loss: 0.0164 - acc: 0.6934\n",
      "Epoch 18/20\n",
      " - 4s - loss: 0.0182 - acc: 0.6961\n",
      "Epoch 19/20\n",
      " - 4s - loss: 0.0153 - acc: 0.7003\n",
      "Epoch 20/20\n",
      " - 4s - loss: 0.0165 - acc: 0.7031\n",
      "AUC:  0.836031650138087\n",
      "Time:  175\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = AutoEncoder_AnomalyDetection_ML.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,20,0.3, 'mahalanobis',[4,2])\n",
    "cnn.fit()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "N2GeeyCAG1kx",
    "outputId": "1739761c-042d-484b-ce8f-0d50d5294a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 5s - loss: 1.1079 - acc: 0.4384\n",
      "Epoch 2/3\n",
      " - 4s - loss: 0.4434 - acc: 0.6069\n",
      "Epoch 3/3\n",
      " - 4s - loss: 0.2398 - acc: 0.6081\n",
      "AUC:  0.9030042720625157\n",
      "Time:  70\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = AutoEncoder_AnomalyDetection_ML.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,3,0.3, 'mahalanobis',[5,3])\n",
    "cnn.fit()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNAAc9oNndlW"
   },
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "5k2hm3fFnfGE",
    "outputId": "e1925815-1fe7-4c20-b3f1-bdbf263cf17c"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = AutoEncoder_AnomalyDetection_ML.from_DataFrame(df_synthetic,30,5,1,0.3, 'euclidean')\n",
    "cnn.fit()\n",
    "# cnn.plot()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6LCAuGN0HETp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 4s - loss: 0.0904 - acc: 0.8589\n",
      "AUC:  0.7443828654594526\n",
      "Time:  45\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = AutoEncoder_AnomalyDetection_ML.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,1,0.3, 'euclidean')\n",
    "cnn.fit()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 7s - loss: 1.1634 - acc: 0.5489\n",
      "Epoch 2/3\n",
      " - 4s - loss: 0.5103 - acc: 0.6687\n",
      "Epoch 3/3\n",
      " - 5s - loss: 0.2271 - acc: 0.6514\n",
      "AUC:  0.8438622936542807\n",
      "Time:  135\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "cnn = AutoEncoder_AnomalyDetection_ML.from_file('Multivariate/NASA_Shuttle/40903.csv', None,30,3,3,0.3, 'euclidean',[5,3])\n",
    "cnn.fit()\n",
    "auc = cnn.get_roc_auc(verbose=False,plot=False)\n",
    "\n",
    "endTime = datetime.datetime.now()\n",
    "diff = endTime - startTime\n",
    "print('Time: ',diff.seconds)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MultivariateNeuralNetworks.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
